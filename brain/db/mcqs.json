[
  {
    "question": "What is the primary architectural pattern used in Angular applications?",
    "options": [
      "Monolithic architecture",
      "Component-based architecture",
      "Microservices architecture",
      "Event-driven architecture"
    ],
    "answer": "Component-based architecture",
    "explanation": "Angular applications are built using a component-based architecture, which promotes modularity, reusability, and scalability by dividing the application into reusable components.",
    "tags": ["Angular", "Architecture", "Component-Based"]
  },
  {
    "question": "What is the purpose of Angular modules (NgModules)?",
    "options": [
      "To define the UI layout of the application",
      "To organize the application into cohesive blocks of functionality",
      "To handle database connections",
      "To replace traditional APIs"
    ],
    "answer": "To organize the application into cohesive blocks of functionality",
    "explanation": "Angular modules (NgModules) help organize the application into logical blocks of functionality, grouping related components, services, and directives together.",
    "tags": ["Angular", "Modules", "NgModules"]
  },
  {
    "question": "Which module bootstraps the Angular application?",
    "options": [
      "Feature Module",
      "AppModule (Root Module)",
      "Shared Module",
      "Lazy-loaded Module"
    ],
    "answer": "AppModule (Root Module)",
    "explanation": "The AppModule, also known as the root module, is responsible for bootstrapping the Angular application and setting up its initial configuration.",
    "tags": ["Angular", "AppModule", "Bootstrapping"]
  },
  {
    "question": "What does the NgModule decorator declare in Angular?",
    "options": [
      "Only the components used in the application",
      "Metadata such as declarations, imports, and providers",
      "Only the routes for navigation",
      "Only the styles applied to the application"
    ],
    "answer": "Metadata such as declarations, imports, and providers",
    "explanation": "The NgModule decorator declares metadata about the module, including components, directives, pipes, imports, and service providers, enabling Angular to understand how to assemble the application.",
    "tags": ["Angular", "NgModule", "Metadata"]
  },
  {
    "question": "What is the role of a component in Angular?",
    "options": [
      "To define the application's business logic exclusively",
      "To encapsulate UI and behavior for specific parts of the application",
      "To manage database connections",
      "To replace traditional HTML templates"
    ],
    "answer": "To encapsulate UI and behavior for specific parts of the application",
    "explanation": "Components in Angular encapsulate both the UI (HTML template) and behavior (TypeScript class), allowing developers to build modular and reusable parts of the application.",
    "tags": ["Angular", "Components", "UI/Behavior"]
  },
  {
    "question": "Which of the following is NOT part of an Angular component?",
    "options": [
      "HTML Template",
      "TypeScript Class",
      "CSS/SCSS Styles",
      "Database Query Language"
    ],
    "answer": "Database Query Language",
    "explanation": "An Angular component consists of an HTML template, TypeScript class, and CSS/SCSS styles. Database query languages are not directly part of the component structure.",
    "tags": ["Angular", "Components", "Structure"]
  },
  {
    "question": "What is the purpose of data binding in Angular templates?",
    "options": [
      "To encrypt communication between components",
      "To synchronize data between the component and the view",
      "To manage database migrations",
      "To replace traditional APIs"
    ],
    "answer": "To synchronize data between the component and the view",
    "explanation": "Data binding in Angular templates allows synchronization between the component's logic and the view, enabling dynamic updates in the UI based on changes in the underlying data.",
    "tags": ["Angular", "Templates", "Data Binding"]
  },
  {
    "question": "Which type of data binding allows two-way synchronization between the model and the view in Angular?",
    "options": [
      "Property Binding",
      "Interpolation",
      "Two-way Binding",
      "Event Binding"
    ],
    "answer": "Two-way Binding",
    "explanation": "Two-way binding in Angular synchronizes data between the model and the view in both directions, often using the `[(ngModel)]` syntax.",
    "tags": ["Angular", "Data Binding", "Two-Way Binding"]
  },
  {
    "question": "What is the purpose of structural directives in Angular?",
    "options": [
      "To modify the appearance or behavior of elements",
      "To alter the DOM structure conditionally or iteratively",
      "To transform data for display",
      "To manage database connections"
    ],
    "answer": "To alter the DOM structure conditionally or iteratively",
    "explanation": "Structural directives like `*ngIf` and `*ngFor` modify the DOM structure by adding, removing, or iterating over elements based on conditions or data.",
    "tags": ["Angular", "Directives", "Structural Directives"]
  },
  {
    "question": "Which directive would you use to conditionally render an element in Angular?",
    "options": ["[ngClass]", "*ngIf", "[ngStyle]", "[(ngModel)]"],
    "answer": "*ngIf",
    "explanation": "The `*ngIf` directive is used to conditionally render an element in the DOM based on a given condition.",
    "tags": ["Angular", "Directives", "*ngIf"]
  },
  {
    "question": "What is the purpose of services in Angular?",
    "options": [
      "To define the UI layout of components",
      "To handle business logic and shared data between components",
      "To manage database migrations",
      "To replace traditional HTML templates"
    ],
    "answer": "To handle business logic and shared data between components",
    "explanation": "Services in Angular are used to encapsulate business logic, share data between components, and provide reusable functionality across the application.",
    "tags": ["Angular", "Services", "Business Logic"]
  },
  {
    "question": "How are services injected into components in Angular?",
    "options": [
      "Through the constructor using Dependency Injection (DI)",
      "By manually creating instances in the component",
      "Using global variables",
      "Through event listeners"
    ],
    "answer": "Through the constructor using Dependency Injection (DI)",
    "explanation": "Services are injected into components through the constructor using Angular's Dependency Injection (DI) system, ensuring loose coupling and promoting maintainability.",
    "tags": ["Angular", "Services", "Dependency Injection"]
  },
  {
    "question": "What is the purpose of pipes in Angular?",
    "options": [
      "To define the application's business logic",
      "To transform data for display in templates",
      "To manage database connections",
      "To replace traditional APIs"
    ],
    "answer": "To transform data for display in templates",
    "explanation": "Pipes in Angular are used to transform data for display in templates, such as formatting dates, converting strings to uppercase, or implementing custom transformations.",
    "tags": ["Angular", "Pipes", "Data Transformation"]
  },
  {
    "question": "Which of the following is an example of a built-in pipe in Angular?",
    "options": ["{{ value | date }}", "*ngIf", "[ngClass]", "[(ngModel)]"],
    "answer": "{{ value | date }}",
    "explanation": "The `{{ value | date }}` syntax demonstrates the use of Angular's built-in `date` pipe, which formats date values for display in templates.",
    "tags": ["Angular", "Pipes", "Built-in Pipes"]
  },
  {
    "question": "What is the purpose of routing in Angular?",
    "options": [
      "To define the application's business logic",
      "To manage navigation and views within a Single Page Application (SPA)",
      "To encrypt communication between components",
      "To replace traditional APIs"
    ],
    "answer": "To manage navigation and views within a Single Page Application (SPA)",
    "explanation": "Routing in Angular manages navigation and dynamically loads different views/components within a Single Page Application (SPA), improving user experience.",
    "tags": ["Angular", "Routing", "SPA"]
  },
  {
    "question": "Which feature of Angular routing allows loading modules/components only when needed?",
    "options": [
      "Route Guards",
      "Lazy Loading",
      "Preloading Strategy",
      "Child Routes"
    ],
    "answer": "Lazy Loading",
    "explanation": "Lazy loading in Angular routing allows modules or components to be loaded only when they are accessed, reducing initial load time and improving performance.",
    "tags": ["Angular", "Routing", "Lazy Loading"]
  },
  {
    "question": "What is the role of route guards in Angular?",
    "options": [
      "To enhance the appearance of components",
      "To control access to routes based on conditions (e.g., authentication)",
      "To manage database connections securely",
      "To replace traditional APIs"
    ],
    "answer": "To control access to routes based on conditions (e.g., authentication)",
    "explanation": "Route guards in Angular control access to routes based on specific conditions, such as requiring authentication before accessing certain pages.",
    "tags": ["Angular", "Routing", "Route Guards"]
  },
  {
    "question": "What is the purpose of Dependency Injection (DI) in Angular?",
    "options": [
      "To encrypt sensitive data",
      "To provide components with required dependencies without hardcoding them",
      "To manage database migrations",
      "To replace traditional APIs"
    ],
    "answer": "To provide components with required dependencies without hardcoding them",
    "explanation": "Dependency Injection (DI) in Angular ensures that components and services receive their dependencies dynamically, promoting loose coupling and better maintainability.",
    "tags": ["Angular", "Dependency Injection", "DI"]
  },
  {
    "question": "Where are providers specified in Angular to make services available?",
    "options": [
      "In the component's constructor",
      "In the NgModule's `providers` array",
      "In the HTML template",
      "In the database configuration"
    ],
    "answer": "In the NgModule's `providers` array",
    "explanation": "Providers in Angular are specified in the NgModule's `providers` array or at the component level to make services available for injection via the DI system.",
    "tags": ["Angular", "Services", "Providers"]
  },
  {
    "question": "What is the role of Angular CLI in application development?",
    "options": [
      "To manage database connections securely",
      "To automate tasks like scaffolding, building, testing, and deployment",
      "To replace traditional APIs",
      "To focus exclusively on backend development"
    ],
    "answer": "To automate tasks like scaffolding, building, testing, and deployment",
    "explanation": "Angular CLI simplifies development by automating tasks such as generating components, services, and modules, as well as building, testing, and deploying the application.",
    "tags": ["Angular", "Angular CLI", "Automation"]
  },
  {
    "question": "Which of the following best describes the flow of an Angular application after bootstrapping?",
    "options": [
      "The browser loads all components simultaneously",
      "The Router loads components based on the URL and updates the view",
      "The application relies solely on server-side rendering",
      "The browser replaces the need for routing"
    ],
    "answer": "The Router loads components based on the URL and updates the view",
    "explanation": "After bootstrapping, the Angular Router determines which components to load based on the current URL and updates the view accordingly, enabling navigation within a Single Page Application (SPA).",
    "tags": ["Angular", "Routing", "Flow"]
  },
  {
    "question": "What is the purpose of lazy loading in Angular?",
    "options": [
      "To load all modules at application startup",
      "To load modules/components only when they are needed, improving performance",
      "To encrypt communication between components",
      "To replace traditional APIs"
    ],
    "answer": "To load modules/components only when they are needed, improving performance",
    "explanation": "Lazy loading in Angular defers the loading of modules or components until they are actually needed, reducing the initial load time and enhancing application performance.",
    "tags": ["Angular", "Routing", "Lazy Loading"]
  },
  {
    "question": "Which of the following is true about Angular's architecture?",
    "options": [
      "It eliminates the need for templates entirely",
      "It promotes modularity through components, services, and modules",
      "It focuses exclusively on backend development",
      "It replaces the need for dependency injection"
    ],
    "answer": "It promotes modularity through components, services, and modules",
    "explanation": "Angular's architecture emphasizes modularity by organizing the application into components, services, and modules, making it easier to scale and maintain.",
    "tags": ["Angular", "Architecture", "Modularity"]
  },
  {
    "question": "What is the role of the `selector` property in an Angular component?",
    "options": [
      "To define the component's template",
      "To specify the CSS styles applied to the component",
      "To declare the name used to insert the component into the DOM",
      "To manage database connections"
    ],
    "answer": "To declare the name used to insert the component into the DOM",
    "explanation": "The `selector` property in an Angular component specifies the name used to include the component in the DOM, enabling its usage in templates.",
    "tags": ["Angular", "Components", "Selector"]
  },
  {
    "question": "Which of the following is true about attribute directives in Angular?",
    "options": [
      "They modify the DOM structure directly",
      "They alter the appearance or behavior of elements",
      "They replace the need for templates",
      "They manage database connections securely"
    ],
    "answer": "They alter the appearance or behavior of elements",
    "explanation": "Attribute directives in Angular, such as `[ngClass]` or `[ngStyle]`, modify the appearance or behavior of elements without changing the DOM structure.",
    "tags": ["Angular", "Directives", "Attribute Directives"]
  },
  {
    "question": "What is Angular primarily used for?",
    "options": [
      "Building back-end server applications",
      "Developing dynamic, modern front-end web applications",
      "Managing databases in cloud environments",
      "Encrypting communication between services"
    ],
    "answer": "Developing dynamic, modern front-end web applications",
    "explanation": "Angular is a TypeScript-based front-end framework developed by Google, designed for building dynamic and modern web applications.",
    "tags": ["Angular", "Front-End Framework", "Definition"]
  },
  {
    "question": "Which programming language does Angular use?",
    "options": ["JavaScript", "Python", "TypeScript", "Java"],
    "answer": "TypeScript",
    "explanation": "Angular uses TypeScript, a superset of JavaScript that provides static typing and better tooling for large-scale applications.",
    "tags": ["Angular", "TypeScript", "Language"]
  },
  {
    "question": "What architecture does Angular adopt?",
    "options": [
      "MVC (Model-View-Controller)",
      "Component-based architecture",
      "Microservices architecture",
      "Event-driven architecture"
    ],
    "answer": "Component-based architecture",
    "explanation": "Angular adopts a component-based architecture, which is more modular and scalable compared to AngularJS's MVC architecture.",
    "tags": ["Angular", "Architecture", "Component-Based"]
  },
  {
    "question": "How does Angular's data flow differ from AngularJS?",
    "options": [
      "AngularJS uses unidirectional data flow, while Angular uses two-way data binding.",
      "Both Angular and AngularJS use two-way data binding exclusively.",
      "Angular uses unidirectional data flow with Zone.js and change detection, improving performance over AngularJS's two-way data binding.",
      "Angular eliminates the need for data binding entirely."
    ],
    "answer": "Angular uses unidirectional data flow with Zone.js and change detection, improving performance over AngularJS's two-way data binding.",
    "explanation": "Angular employs a unidirectional data flow using Zone.js and change detection, which enhances performance compared to AngularJS's two-way data binding mechanism.",
    "tags": ["Angular", "Data Flow", "Performance"]
  },
  {
    "question": "Which templating syntax is used in Angular?",
    "options": [
      "AngularJS directives like `ng-bind` and `ng-model`",
      "Angular-specific syntax like `*ngIf` and `*ngFor`",
      "React JSX syntax",
      "Vue.js templating syntax"
    ],
    "answer": "Angular-specific syntax like `*ngIf` and `*ngFor`",
    "explanation": "Angular uses its own templating syntax, such as `*ngIf` for conditional rendering and `*ngFor` for iterating over lists, providing better modularity and encapsulation.",
    "tags": ["Angular", "Templating", "Syntax"]
  },
  {
    "question": "What is Dependency Injection (DI) in Angular?",
    "options": [
      "A mechanism for encrypting sensitive data",
      "A system for managing database connections",
      "A way to provide components with dependencies without hardcoding them",
      "A protocol for real-time communication"
    ],
    "answer": "A way to provide components with dependencies without hardcoding them",
    "explanation": "Dependency Injection (DI) in Angular allows components to receive dependencies dynamically, promoting loose coupling and better maintainability.",
    "tags": ["Angular", "Dependency Injection", "DI"]
  },
  {
    "question": "Which of the following best describes Angular CLI?",
    "options": [
      "A library for encrypting data in Angular applications",
      "A command-line interface tool for scaffolding, testing, and building Angular applications",
      "A database management tool for Angular applications",
      "A protocol for secure communication"
    ],
    "answer": "A command-line interface tool for scaffolding, testing, and building Angular applications",
    "explanation": "Angular CLI is a powerful tool that simplifies development tasks like project creation, testing, and building Angular applications.",
    "tags": ["Angular", "Angular CLI", "Tooling"]
  },
  {
    "question": "What is Angular primarily used for?",
    "options": [
      "Building back-end server applications",
      "Developing dynamic, modern front-end web applications",
      "Managing databases in cloud environments",
      "Encrypting communication between services"
    ],
    "answer": "Developing dynamic, modern front-end web applications",
    "explanation": "Angular is a TypeScript-based front-end framework developed by Google, designed for building dynamic and modern web applications.",
    "tags": ["Angular", "Front-End Framework", "Definition"]
  },
  {
    "question": "Which programming language does Angular use?",
    "options": ["JavaScript", "Python", "TypeScript", "Java"],
    "answer": "TypeScript",
    "explanation": "Angular uses TypeScript, a superset of JavaScript that provides static typing and better tooling for large-scale applications.",
    "tags": ["Angular", "TypeScript", "Language"]
  },
  {
    "question": "What architecture does Angular adopt?",
    "options": [
      "MVC (Model-View-Controller)",
      "Component-based architecture",
      "Microservices architecture",
      "Event-driven architecture"
    ],
    "answer": "Component-based architecture",
    "explanation": "Angular adopts a component-based architecture, which is more modular and scalable compared to AngularJS's MVC architecture.",
    "tags": ["Angular", "Architecture", "Component-Based"]
  },
  {
    "question": "How does Angular's data flow differ from AngularJS?",
    "options": [
      "AngularJS uses unidirectional data flow, while Angular uses two-way data binding.",
      "Both Angular and AngularJS use two-way data binding exclusively.",
      "Angular uses unidirectional data flow with Zone.js and change detection, improving performance over AngularJS's two-way data binding.",
      "Angular eliminates the need for data binding entirely."
    ],
    "answer": "Angular uses unidirectional data flow with Zone.js and change detection, improving performance over AngularJS's two-way data binding.",
    "explanation": "Angular employs a unidirectional data flow using Zone.js and change detection, which enhances performance compared to AngularJS's two-way data binding mechanism.",
    "tags": ["Angular", "Data Flow", "Performance"]
  },
  {
    "question": "Which templating syntax is used in Angular?",
    "options": [
      "AngularJS directives like `ng-bind` and `ng-model`",
      "Angular-specific syntax like `*ngIf` and `*ngFor`",
      "React JSX syntax",
      "Vue.js templating syntax"
    ],
    "answer": "Angular-specific syntax like `*ngIf` and `*ngFor`",
    "explanation": "Angular uses its own templating syntax, such as `*ngIf` for conditional rendering and `*ngFor` for iterating over lists, providing better modularity and encapsulation.",
    "tags": ["Angular", "Templating", "Syntax"]
  },
  {
    "question": "What is Dependency Injection (DI) in Angular?",
    "options": [
      "A mechanism for encrypting sensitive data",
      "A system for managing database connections",
      "A way to provide components with dependencies without hardcoding them",
      "A protocol for real-time communication"
    ],
    "answer": "A way to provide components with dependencies without hardcoding them",
    "explanation": "Dependency Injection (DI) in Angular allows components to receive dependencies dynamically, promoting loose coupling and better maintainability.",
    "tags": ["Angular", "Dependency Injection", "DI"]
  },
  {
    "question": "Which of the following best describes Angular CLI?",
    "options": [
      "A library for encrypting data in Angular applications",
      "A command-line interface tool for scaffolding, testing, and building Angular applications",
      "A database management tool for Angular applications",
      "A protocol for secure communication"
    ],
    "answer": "A command-line interface tool for scaffolding, testing, and building Angular applications",
    "explanation": "Angular CLI is a powerful tool that simplifies development tasks like project creation, testing, and building Angular applications.",
    "tags": ["Angular", "Angular CLI", "Tooling"]
  },
  {
    "question": "How does Angular's mobile support compare to AngularJS?",
    "options": [
      "AngularJS is optimized for mobile development, while Angular lacks mobile support.",
      "Angular is designed with mobile-first considerations, whereas AngularJS is not optimized for mobile development.",
      "Both Angular and AngularJS are equally optimized for mobile development.",
      "Mobile support is irrelevant to both frameworks."
    ],
    "answer": "Angular is designed with mobile-first considerations, whereas AngularJS is not optimized for mobile development.",
    "explanation": "Angular was designed with mobile-first considerations, making it more suitable for mobile development compared to AngularJS, which did not prioritize mobile optimization.",
    "tags": ["Angular", "Mobile Support", "Comparison"]
  },
  {
    "question": "Which statement is true about backward compatibility between Angular and AngularJS?",
    "options": [
      "AngularJS applications can run seamlessly on Angular with no changes.",
      "Angular and AngularJS are completely incompatible due to their architectural differences.",
      "Angular provides tools to ensure full backward compatibility with AngularJS.",
      "Backward compatibility is only relevant for backend frameworks."
    ],
    "answer": "Angular and AngularJS are completely incompatible due to their architectural differences.",
    "explanation": "Angular and AngularJS are fundamentally different frameworks, and there is no direct backward compatibility between them. Migrating from AngularJS to Angular often requires rewriting parts of the application.",
    "tags": ["Angular", "Backward Compatibility", "Comparison"]
  },
  {
    "question": "What advantage does Angular's hierarchical DI system offer over AngularJS's DI?",
    "options": [
      "It simplifies the application structure unnecessarily.",
      "It provides a more robust and flexible dependency injection mechanism.",
      "It eliminates the need for dependency injection entirely.",
      "It focuses exclusively on backend development."
    ],
    "answer": "It provides a more robust and flexible dependency injection mechanism.",
    "explanation": "Angular's hierarchical DI system offers a more robust and flexible way to inject dependencies compared to AngularJS's less sophisticated DI approach.",
    "tags": ["Angular", "Dependency Injection", "Hierarchical DI"]
  },
  {
    "question": "Which of the following is a key difference in performance between Angular and AngularJS?",
    "options": [
      "AngularJS performs better in complex applications due to its two-way data binding.",
      "Angular improves performance through unidirectional data flow and efficient change detection mechanisms.",
      "Both frameworks have identical performance characteristics.",
      "Performance improvements are only relevant for backend frameworks."
    ],
    "answer": "Angular improves performance through unidirectional data flow and efficient change detection mechanisms.",
    "explanation": "Angular's unidirectional data flow and use of Zone.js for change detection significantly improve performance, especially in complex applications, compared to AngularJS's two-way data binding.",
    "tags": ["Angular", "Performance", "Change Detection"]
  },
  {
    "question": "Why was Angular rewritten from scratch instead of continuing with AngularJS?",
    "options": [
      "To address limitations and scalability issues in AngularJS.",
      "Because AngularJS was too performant for modern applications.",
      "To eliminate the need for front-end frameworks.",
      "To focus exclusively on backend development."
    ],
    "answer": "To address limitations and scalability issues in AngularJS.",
    "explanation": "Angular was rewritten from scratch to overcome the limitations of AngularJS, such as poor scalability, performance bottlenecks, and lack of modern features.",
    "tags": ["Angular", "AngularJS", "Rewrite", "Scalability"]
  },
  {
    "question": "Which of the following is true about AngularJS's architecture?",
    "options": [
      "It uses a component-based architecture similar to Angular.",
      "It follows the MVC (Model-View-Controller) architecture.",
      "It eliminates the need for templates entirely.",
      "It focuses exclusively on backend development."
    ],
    "answer": "It follows the MVC (Model-View-Controller) architecture.",
    "explanation": "AngularJS adheres to the MVC (Model-View-Controller) architecture, whereas Angular uses a component-based architecture.",
    "tags": ["AngularJS", "Architecture", "MVC"]
  },
  {
    "question": "What is the role of Zone.js in Angular?",
    "options": [
      "To manage database connections securely.",
      "To handle encryption and decryption of sensitive data.",
      "To track asynchronous operations and trigger change detection efficiently.",
      "To replace traditional APIs with event-driven architectures."
    ],
    "answer": "To track asynchronous operations and trigger change detection efficiently.",
    "explanation": "Zone.js in Angular tracks asynchronous operations and ensures efficient change detection, contributing to the framework's improved performance.",
    "tags": ["Angular", "Zone.js", "Change Detection"]
  },
  {
    "question": "Which of the following best describes Angular's approach to templating?",
    "options": [
      "Angular relies solely on third-party libraries for templating.",
      "Angular uses its own templating syntax, including directives like `*ngIf` and `*ngFor`.",
      "Angular continues to use AngularJS's templating syntax for backward compatibility.",
      "Templating is irrelevant to Angular's architecture."
    ],
    "answer": "Angular uses its own templating syntax, including directives like `*ngIf` and `*ngFor`.",
    "explanation": "Angular introduces its own templating syntax, leveraging directives like `*ngIf` and `*ngFor` for better modularity and encapsulation.",
    "tags": ["Angular", "Templating", "Directives"]
  },
  {
    "question": "What is the primary benefit of Angular's component-based architecture?",
    "options": [
      "It simplifies the application structure unnecessarily.",
      "It promotes modularity and reusability, making the application more scalable.",
      "It eliminates the need for HTML templates.",
      "It focuses exclusively on backend development."
    ],
    "answer": "It promotes modularity and reusability, making the application more scalable.",
    "explanation": "Angular's component-based architecture encourages modularity and reusability, enabling developers to build scalable and maintainable applications.",
    "tags": ["Angular", "Component-Based Architecture", "Modularity"]
  },
  {
    "question": "Which of the following statements about AngularJS's two-way data binding is true?",
    "options": [
      "It improves performance in complex applications.",
      "It can lead to performance bottlenecks in large-scale applications due to heavy DOM updates.",
      "It eliminates the need for templates entirely.",
      "Two-way data binding is irrelevant to front-end frameworks."
    ],
    "answer": "It can lead to performance bottlenecks in large-scale applications due to heavy DOM updates.",
    "explanation": "AngularJS's two-way data binding can cause performance issues in complex applications because it involves constant synchronization between the model and view, leading to heavy DOM updates.",
    "tags": ["AngularJS", "Two-Way Data Binding", "Performance"]
  },
  {
    "question": "What does Angular CLI help developers do?",
    "options": [
      "Manage database migrations automatically.",
      "Scaffold, test, and build Angular applications with standardized tools.",
      "Replace traditional APIs with WebSocket-based communication.",
      "Focus exclusively on backend development."
    ],
    "answer": "Scaffold, test, and build Angular applications with standardized tools.",
    "explanation": "Angular CLI provides tools for generating components, running tests, and building Angular applications, ensuring consistency and speeding up development.",
    "tags": ["Angular", "Angular CLI", "Tooling"]
  },
  {
    "question": "Which of the following is true about Angular's change detection mechanism?",
    "options": [
      "It relies on two-way data binding, similar to AngularJS.",
      "It uses unidirectional data flow and Zone.js for efficient change detection.",
      "Change detection is unnecessary in Angular due to its simpler architecture.",
      "It focuses exclusively on backend state management."
    ],
    "answer": "It uses unidirectional data flow and Zone.js for efficient change detection.",
    "explanation": "Angular's change detection mechanism leverages unidirectional data flow and Zone.js to efficiently track and update changes in the application.",
    "tags": ["Angular", "Change Detection", "Zone.js"]
  },
  {
    "question": "What is the main disadvantage of AngularJS's two-way data binding?",
    "options": [
      "It simplifies the application structure too much.",
      "It can degrade performance in complex applications due to frequent DOM updates.",
      "It eliminates the need for templates entirely.",
      "Two-way data binding is irrelevant to modern front-end development."
    ],
    "answer": "It can degrade performance in complex applications due to frequent DOM updates.",
    "explanation": "AngularJS's two-way data binding synchronizes the model and view constantly, which can slow down performance in large-scale applications with many bindings.",
    "tags": ["AngularJS", "Two-Way Data Binding", "Performance"]
  },
  {
    "question": "Which of the following is a feature introduced in Angular but not available in AngularJS?",
    "options": [
      "MVC architecture",
      "Hierarchical Dependency Injection",
      "HTML templates",
      "Support for RESTful APIs"
    ],
    "answer": "Hierarchical Dependency Injection",
    "explanation": "Angular introduces a hierarchical Dependency Injection system, offering greater flexibility and robustness compared to AngularJS's simpler DI mechanism.",
    "tags": ["Angular", "AngularJS", "Dependency Injection", "Comparison"]
  },
  {
    "question": "Why is TypeScript preferred in Angular over plain JavaScript used in AngularJS?",
    "options": [
      "TypeScript eliminates the need for HTML templates.",
      "TypeScript provides static typing and better tooling, enhancing developer productivity.",
      "TypeScript is easier to learn than JavaScript.",
      "TypeScript replaces the need for front-end frameworks."
    ],
    "answer": "TypeScript provides static typing and better tooling, enhancing developer productivity.",
    "explanation": "TypeScript, being a statically typed superset of JavaScript, offers better tooling, compile-time checks, and improved maintainability, making it the preferred choice for Angular.",
    "tags": ["Angular", "TypeScript", "Static Typing"]
  },
  {
    "question": "Which of the following is true about Angular's mobile-first design philosophy?",
    "options": [
      "AngularJS also follows a mobile-first design philosophy.",
      "Angular is optimized for mobile-first development, unlike AngularJS.",
      "Mobile-first design is irrelevant to front-end frameworks.",
      "Angular eliminates the need for responsive design."
    ],
    "answer": "Angular is optimized for mobile-first development, unlike AngularJS.",
    "explanation": "Angular was designed with mobile-first considerations, ensuring better performance and responsiveness on mobile devices compared to AngularJS.",
    "tags": ["Angular", "Mobile-First", "Optimization"]
  },
  {
    "question": "What is the purpose of Angular's *ngIf directive?",
    "options": [
      "To iterate over lists in the template.",
      "To conditionally render elements in the template.",
      "To define routes in the application.",
      "To manage database connections securely."
    ],
    "answer": "To conditionally render elements in the template.",
    "explanation": "The *ngIf directive in Angular is used to conditionally render elements in the HTML template based on a given condition.",
    "tags": ["Angular", "Directives", "*ngIf"]
  },
  {
    "question": "What is Podman primarily used for?",
    "options": [
      "Managing databases",
      "Running, building, and managing containers without a daemon",
      "Encrypting communication between services",
      "Handling frontend state management"
    ],
    "answer": "Running, building, and managing containers without a daemon",
    "explanation": "Podman is a container management tool that allows users to run, build, and manage containers without requiring a central daemon, making it more secure and efficient.",
    "tags": ["Podman", "Container Management", "Daemonless"]
  },
  {
    "question": "Which of the following is a key feature of Podman compared to Docker?",
    "options": [
      "Support for only root users",
      "Daemonless architecture",
      "Lack of support for pods",
      "Incompatibility with Docker commands"
    ],
    "answer": "Daemonless architecture",
    "explanation": "Unlike Docker, Podman uses a daemonless architecture, where each container runs as a child process, enhancing security and reducing resource overhead.",
    "tags": ["Podman", "Daemonless", "Comparison"]
  },
  {
    "question": "What does the `podman --version` command do?",
    "options": [
      "Checks the version of the Nginx container",
      "Displays the installed version of Podman",
      "Pulls an image from a registry",
      "Runs a container in detached mode"
    ],
    "answer": "Displays the installed version of Podman",
    "explanation": "The `podman --version` command displays the currently installed version of Podman, ensuring you're using the correct version for your workflow.",
    "tags": ["Podman", "Commands", "Version Check"]
  },
  {
    "question": "Which command pulls an image from a container registry in Podman?",
    "options": [
      "podman pull nginx",
      "podman push nginx",
      "podman build nginx",
      "podman stop nginx"
    ],
    "answer": "podman pull nginx",
    "explanation": "The `podman pull nginx` command retrieves the Nginx image from a container registry, such as Docker Hub, making it available for local use.",
    "tags": ["Podman", "Commands", "Image Management"]
  },
  {
    "question": "What does the `-d` flag in `podman run -d --name my-nginx -p 8080:80 nginx` do?",
    "options": [
      "Runs the container in interactive mode",
      "Runs the container in detached mode",
      "Deletes the container after execution",
      "Debugs the container's processes"
    ],
    "answer": "Runs the container in detached mode",
    "explanation": "The `-d` flag in Podman ensures the container runs in the background (detached mode), allowing continuous operation without tying up the terminal.",
    "tags": ["Podman", "Commands", "Detached Mode"]
  },
  {
    "question": "Which command lists all running containers in Podman?",
    "options": ["podman pod ps", "podman ps", "podman images", "podman rm"],
    "answer": "podman ps",
    "explanation": "The `podman ps` command lists all currently running containers, providing details like container ID, name, and status.",
    "tags": ["Podman", "Commands", "Container Listing"]
  },
  {
    "question": "How do you stop and remove a container named `my-nginx` in Podman?",
    "options": [
      "podman stop my-nginx && podman rm my-nginx",
      "podman kill my-nginx",
      "podman delete my-nginx",
      "podman pause my-nginx"
    ],
    "answer": "podman stop my-nginx && podman rm my-nginx",
    "explanation": "To stop and remove a container in Podman, use `podman stop my-nginx` to halt the container and `podman rm my-nginx` to remove it.",
    "tags": ["Podman", "Commands", "Stopping/Removing Containers"]
  },
  {
    "question": "What is the purpose of a Pod in Podman?",
    "options": [
      "A single container running in isolation",
      "A group of containers sharing networking and storage resources",
      "A database management system",
      "A protocol for encrypting communication"
    ],
    "answer": "A group of containers sharing networking and storage resources",
    "explanation": "A Pod in Podman is a collection of containers that share the same network namespace, storage, and other resources, similar to Kubernetes Pods.",
    "tags": ["Podman", "Pods", "Shared Resources"]
  },
  {
    "question": "Which command creates a Pod in Podman?",
    "options": [
      "podman create-pod",
      "podman pod create",
      "podman run-pod",
      "podman start-pod"
    ],
    "answer": "podman pod create",
    "explanation": "The `podman pod create` command creates a new Pod, which can host multiple containers sharing resources.",
    "tags": ["Podman", "Commands", "Pod Creation"]
  },
  {
    "question": "What does the `--pod` flag in Podman do?",
    "options": [
      "Creates a new Pod",
      "Specifies the Pod in which a container should run",
      "Lists all Pods",
      "Deletes a Pod"
    ],
    "answer": "Specifies the Pod in which a container should run",
    "explanation": "The `--pod` flag in Podman specifies the Pod in which a container should be started, enabling shared networking and storage among containers.",
    "tags": ["Podman", "Flags", "Pod Specification"]
  },
  {
    "question": "Which command builds a custom image in Podman?",
    "options": [
      "podman pull",
      "podman push",
      "podman build -t myapp .",
      "podman rm"
    ],
    "answer": "podman build -t myapp .",
    "explanation": "The `podman build -t myapp .` command builds a custom image from a Dockerfile or other build context, tagging it as `myapp` for easy reference.",
    "tags": ["Podman", "Commands", "Image Building"]
  },
  {
    "question": "How do you push an image to a container registry in Podman?",
    "options": [
      "podman pull myapp docker.io/username/myapp",
      "podman push myapp docker.io/username/myapp",
      "podman build -t myapp docker.io/username/myapp",
      "podman rm myapp"
    ],
    "answer": "podman push myapp docker.io/username/myapp",
    "explanation": "The `podman push myapp docker.io/username/myapp` command uploads the locally built `myapp` image to the specified container registry.",
    "tags": ["Podman", "Commands", "Image Pushing"]
  },
  {
    "question": "What is the main advantage of Podman's rootless mode?",
    "options": [
      "It simplifies the container build process",
      "It enhances security by running containers without root privileges",
      "It eliminates the need for networking",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It enhances security by running containers without root privileges",
    "explanation": "Podman's rootless mode allows containers to run as non-root users, improving security and reducing the risk of privilege escalation.",
    "tags": ["Podman", "Rootless Mode", "Security"]
  },
  {
    "question": "Which of the following best describes the relationship between Podman and Kubernetes?",
    "options": [
      "Podman replaces Kubernetes entirely",
      "Podman is better suited for Kubernetes environments due to its pod support",
      "There is no relationship; both serve different purposes",
      "Kubernetes eliminates the need for Podman"
    ],
    "answer": "Podman is better suited for Kubernetes environments due to its pod support",
    "explanation": "Podman's support for pods makes it more compatible with Kubernetes environments, allowing developers to test pod-based architectures locally.",
    "tags": ["Podman", "Kubernetes", "Pod Support"]
  },
  {
    "question": "What does the `podman pod ps` command display?",
    "options": [
      "All running containers",
      "All created Pods and their details",
      "All pulled images",
      "All deleted containers"
    ],
    "answer": "All created Pods and their details",
    "explanation": "The `podman pod ps` command lists all created Pods along with their IDs, names, and statuses, helping manage pod-based workflows.",
    "tags": ["Podman", "Commands", "Pod Listing"]
  },
  {
    "question": "Which of the following is true about Podman's compatibility with Docker commands?",
    "options": [
      "Podman supports only a subset of Docker commands",
      "Podman fully supports Docker commands and images",
      "Podman requires rewriting all Docker commands",
      "Podman focuses exclusively on frontend development"
    ],
    "answer": "Podman fully supports Docker commands and images",
    "explanation": "Podman is designed to be Docker-compatible, supporting most Docker commands and images while offering additional features like rootless mode and daemonless operation.",
    "tags": ["Podman", "Docker Compatibility", "Commands"]
  },
  {
    "question": "What is the role of the `-p` flag in `podman run -d --name my-nginx -p 8080:80 nginx`?",
    "options": [
      "Specifies the container's environment variables",
      "Maps port 8080 on the host to port 80 in the container",
      "Defines the container's storage volume",
      "Sets the container's CPU limits"
    ],
    "answer": "Maps port 8080 on the host to port 80 in the container",
    "explanation": "The `-p` flag in Podman maps a port on the host machine (e.g., 8080) to a port inside the container (e.g., 80), enabling external access to the containerized application.",
    "tags": ["Podman", "Commands", "Port Mapping"]
  },
  {
    "question": "Which of the following is a benefit of Podman's daemonless architecture?",
    "options": [
      "Increased complexity in container management",
      "Improved security and reduced resource overhead",
      "Elimination of the need for networking",
      "Focus exclusively on frontend development"
    ],
    "answer": "Improved security and reduced resource overhead",
    "explanation": "Podman's daemonless architecture improves security by avoiding a central daemon and reduces resource overhead by managing containers directly as child processes.",
    "tags": ["Podman", "Daemonless Architecture", "Benefits"]
  },
  {
    "question": "What is the purpose of the `podman ps --pod` command?",
    "options": [
      "Lists all Pods",
      "Lists containers within a specific Pod",
      "Pulls an image from a registry",
      "Removes all stopped containers"
    ],
    "answer": "Lists containers within a specific Pod",
    "explanation": "The `podman ps --pod` command lists all containers running within a specific Pod, helping monitor and manage pod-based workflows.",
    "tags": ["Podman", "Commands", "Pod Containers"]
  },
  {
    "question": "Which of the following is true about Podman's support for pods?",
    "options": [
      "Podman does not support pods",
      "Podman supports pods, allowing multiple containers to share resources",
      "Pods in Podman are incompatible with Kubernetes",
      "Podman replaces the need for pods entirely"
    ],
    "answer": "Podman supports pods, allowing multiple containers to share resources",
    "explanation": "Podman supports pods, enabling multiple containers to share networking, storage, and other resources, aligning well with Kubernetes-style architectures.",
    "tags": ["Podman", "Pods", "Resource Sharing"]
  },
  {
    "question": "What is the main difference between Podman and Docker?",
    "options": [
      "Podman requires a daemon, while Docker does not",
      "Podman runs containers as non-root users by default, enhancing security",
      "Podman cannot pull Docker images",
      "There is no difference; both serve the same purpose"
    ],
    "answer": "Podman runs containers as non-root users by default, enhancing security",
    "explanation": "One of the main differences is that Podman runs containers as non-root users by default, improving security compared to Docker's traditional root-based approach.",
    "tags": ["Podman", "Docker", "Comparison", "Security"]
  },
  {
    "question": "Which command starts a container inside a specific Pod?",
    "options": [
      "podman start --pod mypod",
      "podman run --pod mypod --name web nginx",
      "podman pod run mypod",
      "podman attach mypod"
    ],
    "answer": "podman run --pod mypod --name web nginx",
    "explanation": "The `podman run --pod mypod --name web nginx` command starts a container named `web` inside the specified Pod (`mypod`), ensuring shared resources among containers.",
    "tags": ["Podman", "Commands", "Pod Container Management"]
  },
  {
    "question": "What is the role of the `--name` flag in Podman?",
    "options": [
      "Defines the container's name for easier reference",
      "Specifies the container's network interface",
      "Sets the container's CPU limits",
      "Manages database connections"
    ],
    "answer": "Defines the container's name for easier reference",
    "explanation": "The `--name` flag in Podman assigns a human-readable name to the container, making it easier to reference during management tasks.",
    "tags": ["Podman", "Flags", "Container Naming"]
  },
  {
    "question": "Which of the following is true about Podman's rootless mode?",
    "options": [
      "It increases the risk of privilege escalation",
      "It allows containers to run without root privileges, improving security",
      "It eliminates the need for containerization",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It allows containers to run without root privileges, improving security",
    "explanation": "Podman's rootless mode enables containers to run as non-root users, reducing the risk of privilege escalation and enhancing overall system security.",
    "tags": ["Podman", "Rootless Mode", "Security"]
  },
  {
    "question": "What is the purpose of the `podman build` command?",
    "options": [
      "Pulls an image from a registry",
      "Builds a custom image from a Dockerfile or build context",
      "Lists all running containers",
      "Removes all stopped containers"
    ],
    "answer": "Builds a custom image from a Dockerfile or build context",
    "explanation": "The `podman build` command builds a custom image based on a Dockerfile or other build context, preparing it for deployment or further use.",
    "tags": ["Podman", "Commands", "Image Building"]
  },
  {
    "question": "Which of the following is a real-world use case for Podman's pod support?",
    "options": [
      "Running a single container in isolation",
      "Creating a group of containers (e.g., web server + database) sharing resources",
      "Managing database migrations",
      "Replacing traditional APIs"
    ],
    "answer": "Creating a group of containers (e.g., web server + database) sharing resources",
    "explanation": "Podman's pod support allows creating groups of containers (e.g., a web server and database) that share resources like networking and storage, mimicking Kubernetes Pods.",
    "tags": ["Podman", "Pods", "Real-World Use Case"]
  },
  {
    "question": "What is Domain-Driven Design (DDD)?",
    "options": [
      "A software development approach that focuses on database design",
      "An approach to software development that emphasizes understanding and modeling the business domain",
      "A design pattern for building user interfaces",
      "A protocol for encrypting communication between services"
    ],
    "answer": "An approach to software development that emphasizes understanding and modeling the business domain",
    "explanation": "Domain-Driven Design (DDD) is a software development methodology that focuses on deeply understanding the business domain and modeling it accurately in software.",
    "tags": ["DDD", "Definition", "Business Domain"]
  },
  {
    "question": "What does the term 'Domain' refer to in DDD?",
    "options": [
      "The core problem space or business area being addressed by the software",
      "The technology stack used for development",
      "The physical infrastructure where the application runs",
      "The encryption mechanism for secure data transfer"
    ],
    "answer": "The core problem space or business area being addressed by the software",
    "explanation": "In DDD, the 'Domain' refers to the core problem space or business area, such as an e-commerce platform or a logistics system.",
    "tags": ["DDD", "Domain", "Problem Space"]
  },
  {
    "question": "What is a Bounded Context in DDD?",
    "options": [
      "A specific part of the domain with its own model and rules",
      "A database table containing all entities",
      "A network boundary for microservices",
      "A protocol for real-time communication"
    ],
    "answer": "A specific part of the domain with its own model and rules",
    "explanation": "A Bounded Context in DDD defines a specific part of the domain with its own model, language, and rules, ensuring clarity and separation of concerns.",
    "tags": ["DDD", "Bounded Context", "Separation of Concerns"]
  },
  {
    "question": "Which of the following best describes an Entity in DDD?",
    "options": [
      "An object with a unique identity that persists over time (e.g., Customer)",
      "An object defined solely by its attributes (e.g., Address)",
      "A cluster of objects treated as a single unit (e.g., Order with OrderItems)",
      "A shared language used by developers and domain experts"
    ],
    "answer": "An object with a unique identity that persists over time (e.g., Customer)",
    "explanation": "An Entity in DDD is an object with a unique identity that persists over time and can be tracked across different operations, such as a 'Customer' in an e-commerce system.",
    "tags": ["DDD", "Entities", "Identity"]
  },
  {
    "question": "What is a Value Object in DDD?",
    "options": [
      "An object with a unique identity that persists over time",
      "An object defined by its attributes and has no independent identity (e.g., Address)",
      "A collection of related objects treated as a single unit",
      "A repository for accessing domain objects"
    ],
    "answer": "An object defined by its attributes and has no independent identity (e.g., Address)",
    "explanation": "A Value Object in DDD is an object defined by its attributes and lacks a unique identity, such as 'Address' or 'Money'.",
    "tags": ["DDD", "Value Objects", "Attributes"]
  },
  {
    "question": "What is an Aggregate in DDD?",
    "options": [
      "A single object with a unique identity",
      "A collection of related objects treated as a single unit with one Aggregate Root",
      "A database query result set",
      "A protocol for real-time communication"
    ],
    "answer": "A collection of related objects treated as a single unit with one Aggregate Root",
    "explanation": "An Aggregate in DDD is a cluster of related objects treated as a single unit, with one Aggregate Root responsible for maintaining consistency within the group.",
    "tags": ["DDD", "Aggregates", "Aggregate Root"]
  },
  {
    "question": "What is the role of a Repository in DDD?",
    "options": [
      "To define the business logic of the application",
      "To provide a pattern for accessing domain objects (e.g., fetching Orders from a database)",
      "To manage network communication between microservices",
      "To replace traditional APIs"
    ],
    "answer": "To provide a pattern for accessing domain objects (e.g., fetching Orders from a database)",
    "explanation": "A Repository in DDD provides a pattern for accessing and persisting domain objects, abstracting away the underlying storage mechanism.",
    "tags": ["DDD", "Repositories", "Data Access"]
  },
  {
    "question": "What are Domain Events in DDD?",
    "options": [
      "Events that capture significant occurrences in the business domain (e.g., OrderPlaced)",
      "Database migration scripts",
      "Frontend events triggered by user actions",
      "Protocols for securing communication"
    ],
    "answer": "Events that capture significant occurrences in the business domain (e.g., OrderPlaced)",
    "explanation": "Domain Events in DDD represent significant occurrences in the business domain, such as 'OrderPlaced' or 'OrderShipped', enabling event-driven architectures.",
    "tags": ["DDD", "Domain Events", "Event-Driven"]
  },
  {
    "question": "What is Ubiquitous Language in DDD?",
    "options": [
      "A programming language used exclusively in DDD",
      "A shared language between developers and domain experts to ensure clarity",
      "A database query language",
      "A protocol for real-time communication"
    ],
    "answer": "A shared language between developers and domain experts to ensure clarity",
    "explanation": "Ubiquitous Language in DDD is a shared language between developers and domain experts, ensuring everyone uses the same terms and concepts when discussing the system.",
    "tags": ["DDD", "Ubiquitous Language", "Collaboration"]
  },
  {
    "question": "Which of the following is a Bounded Context in an e-commerce system?",
    "options": [
      "The entire e-commerce platform",
      "The Ordering context (handling orders, payments)",
      "The customer's personal information",
      "The encryption mechanism for secure transactions"
    ],
    "answer": "The Ordering context (handling orders, payments)",
    "explanation": "A Bounded Context in DDD is a specific part of the domain with its own model and rules. In an e-commerce system, 'Ordering' could be a Bounded Context handling orders and payments.",
    "tags": ["DDD", "Bounded Context", "E-commerce Example"]
  },
  {
    "question": "What is the purpose of an Aggregate Root in DDD?",
    "options": [
      "To define the encryption algorithm",
      "To act as the entry point for operations within an Aggregate",
      "To store static assets like images",
      "To replace traditional APIs"
    ],
    "answer": "To act as the entry point for operations within an Aggregate",
    "explanation": "The Aggregate Root in DDD acts as the entry point for operations within an Aggregate, ensuring consistency and encapsulating business logic.",
    "tags": ["DDD", "Aggregate Root", "Consistency"]
  },
  {
    "question": "Which of the following best describes the relationship between Entities and Aggregates in DDD?",
    "options": [
      "Entities are always aggregates themselves",
      "Aggregates consist of one or more entities and value objects",
      "There is no relationship; both serve different purposes",
      "Aggregates replace the need for entities"
    ],
    "answer": "Aggregates consist of one or more entities and value objects",
    "explanation": "An Aggregate in DDD may consist of one or more Entities and Value Objects, grouped together under an Aggregate Root to maintain consistency.",
    "tags": ["DDD", "Entities", "Aggregates", "Relationship"]
  },
  {
    "question": "What is the main advantage of using DDD in complex systems?",
    "options": [
      "It simplifies the system architecture unnecessarily",
      "It ensures alignment between software and business needs through deep domain understanding",
      "It eliminates the need for databases",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It ensures alignment between software and business needs through deep domain understanding",
    "explanation": "DDD's primary advantage is its ability to align software with business needs by deeply understanding and modeling the domain, ensuring maintainability and scalability.",
    "tags": ["DDD", "Advantages", "Alignment"]
  },
  {
    "question": "Which of the following is true about Value Objects in DDD?",
    "options": [
      "They have a unique identity and persist over time",
      "They are defined by their attributes and lack independent identity (e.g., Address, Money)",
      "They replace the need for Entities",
      "They focus exclusively on frontend state management"
    ],
    "answer": "They are defined by their attributes and lack independent identity (e.g., Address, Money)",
    "explanation": "Value Objects in DDD are defined by their attributes and do not have a unique identity, making them suitable for representing concepts like 'Address' or 'Money'.",
    "tags": ["DDD", "Value Objects", "Attributes"]
  },
  {
    "question": "What happens when an Aggregate Root enforces consistency within its boundaries?",
    "options": [
      "It allows any object inside the aggregate to be modified independently",
      "It ensures that changes within the aggregate maintain data integrity",
      "It eliminates the need for repositories",
      "It replaces the need for domain events"
    ],
    "answer": "It ensures that changes within the aggregate maintain data integrity",
    "explanation": "An Aggregate Root enforces consistency within its boundaries, ensuring that changes made to objects within the aggregate maintain data integrity and avoid conflicts.",
    "tags": ["DDD", "Aggregate Root", "Consistency"]
  },
  {
    "question": "Which of the following is a real-world example of a Domain Event in DDD?",
    "options": [
      "OrderPlaced",
      "Database migration script",
      "User interface update",
      "Network packet transmission"
    ],
    "answer": "OrderPlaced",
    "explanation": "A Domain Event like 'OrderPlaced' captures significant occurrences in the business domain, enabling event-driven interactions and triggering downstream processes.",
    "tags": ["DDD", "Domain Events", "Real-World Example"]
  },
  {
    "question": "What is the role of Ubiquitous Language in DDD?",
    "options": [
      "To create a shared understanding between developers and domain experts",
      "To manage database connections",
      "To replace traditional APIs",
      "To simplify frontend development"
    ],
    "answer": "To create a shared understanding between developers and domain experts",
    "explanation": "Ubiquitous Language in DDD fosters collaboration by creating a shared vocabulary between developers and domain experts, reducing misunderstandings.",
    "tags": ["DDD", "Ubiquitous Language", "Collaboration"]
  },
  {
    "question": "Which of the following is a Bounded Context in a shipping logistics system?",
    "options": [
      "The entire logistics platform",
      "The Shipping context (logistics and delivery)",
      "The encryption mechanism for secure transactions",
      "The frontend framework for UI rendering"
    ],
    "answer": "The Shipping context (logistics and delivery)",
    "explanation": "A Bounded Context in DDD isolates a specific part of the domain, such as 'Shipping' in a logistics system, which handles logistics and delivery.",
    "tags": ["DDD", "Bounded Context", "Logistics Example"]
  },
  {
    "question": "What is the purpose of a Repository in DDD?",
    "options": [
      "To define the encryption algorithm",
      "To provide a pattern for accessing and persisting domain objects",
      "To replace the need for domain models",
      "To manage frontend state"
    ],
    "answer": "To provide a pattern for accessing and persisting domain objects",
    "explanation": "A Repository in DDD abstracts the persistence layer, providing a clean interface for accessing and persisting domain objects like 'Orders' or 'Customers'.",
    "tags": ["DDD", "Repositories", "Persistence"]
  },
  {
    "question": "Which of the following is true about Entities in DDD?",
    "options": [
      "They are immutable and cannot be updated",
      "They have a unique identity and can persist over time (e.g., Customer, Product)",
      "They replace the need for Value Objects",
      "They focus exclusively on frontend development"
    ],
    "answer": "They have a unique identity and can persist over time (e.g., Customer, Product)",
    "explanation": "Entities in DDD have a unique identity and can persist over time, making them suitable for representing objects like 'Customer' or 'Product' in a domain model.",
    "tags": ["DDD", "Entities", "Identity"]
  },
  {
    "question": "What is the main challenge of implementing DDD in large systems?",
    "options": [
      "Simplified system architecture",
      "Increased complexity due to multiple bounded contexts and domain models",
      "Elimination of the need for testing",
      "Focus exclusively on backend development"
    ],
    "answer": "Increased complexity due to multiple bounded contexts and domain models",
    "explanation": "Implementing DDD in large systems introduces complexity due to the need to manage multiple bounded contexts, domain models, and their interactions effectively.",
    "tags": ["DDD", "Challenges", "Complexity"]
  },
  {
    "question": "Which of the following is a benefit of separating domains into Bounded Contexts?",
    "options": [
      "It increases coupling between different parts of the system",
      "It reduces complexity by isolating different parts of the domain",
      "It eliminates the need for domain experts",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It reduces complexity by isolating different parts of the domain",
    "explanation": "Separating domains into Bounded Contexts reduces complexity by isolating different parts of the domain, ensuring each context has its own model and rules.",
    "tags": ["DDD", "Bounded Context", "Complexity Reduction"]
  },
  {
    "question": "What is the role of Domain Events in DDD?",
    "options": [
      "To define the structure of database tables",
      "To capture significant occurrences in the business domain (e.g., OrderPlaced, PaymentProcessed)",
      "To manage frontend state transitions",
      "To replace traditional APIs"
    ],
    "answer": "To capture significant occurrences in the business domain (e.g., OrderPlaced, PaymentProcessed)",
    "explanation": "Domain Events in DDD capture important occurrences in the business domain, enabling event-driven architectures and triggering downstream processes.",
    "tags": ["DDD", "Domain Events", "Event-Driven"]
  },
  {
    "question": "Which of the following is true about Aggregate Roots in DDD?",
    "options": [
      "They are always Value Objects",
      "They act as the entry point for operations within an Aggregate",
      "They replace the need for Bounded Contexts",
      "They focus exclusively on frontend development"
    ],
    "answer": "They act as the entry point for operations within an Aggregate",
    "explanation": "An Aggregate Root in DDD serves as the entry point for operations within an Aggregate, ensuring consistency and encapsulating business logic.",
    "tags": ["DDD", "Aggregate Root", "Operations"]
  },
  {
    "question": "What is the purpose of Ubiquitous Language in DDD?",
    "options": [
      "To define the encryption algorithm",
      "To create a shared understanding between developers and domain experts",
      "To replace traditional APIs",
      "To simplify frontend development"
    ],
    "answer": "To create a shared understanding between developers and domain experts",
    "explanation": "Ubiquitous Language in DDD ensures clear communication between developers and domain experts by defining a common vocabulary for the domain.",
    "tags": ["DDD", "Ubiquitous Language", "Shared Understanding"]
  },
  {
    "question": "What is the primary purpose of Gherkin in software development?",
    "options": [
      "To write test scenarios in plain, human-readable language",
      "To encrypt sensitive data during testing",
      "To manage database migrations",
      "To replace traditional APIs"
    ],
    "answer": "To write test scenarios in plain, human-readable language",
    "explanation": "Gherkin is a simple, natural language syntax used to write test scenarios in Behavior-Driven Development (BDD), making it easier for non-technical stakeholders to understand requirements.",
    "tags": ["Gherkin", "BDD", "Natural Language"]
  },
  {
    "question": "Which structure does Gherkin use to define test scenarios?",
    "options": [
      "Setup-Act-Assert",
      "Arrange-Act-Assert",
      "Given-When-Then",
      "Request-Response-Validation"
    ],
    "answer": "Given-When-Then",
    "explanation": "Gherkin uses the Given-When-Then structure to define test scenarios, where `Given` sets up the context, `When` defines the action, and `Then` specifies the expected outcome.",
    "tags": ["Gherkin", "Structure", "Given-When-Then"]
  },
  {
    "question": "What is the role of `.feature` files in Gherkin?",
    "options": [
      "To store step definitions written in code",
      "To define test scenarios using Gherkin syntax",
      "To manage database connections",
      "To generate test reports"
    ],
    "answer": "To define test scenarios using Gherkin syntax",
    "explanation": ".feature files contain test scenarios written in Gherkin syntax, describing the behavior of an application in a human-readable format.",
    "tags": ["Gherkin", "Feature Files", "Test Scenarios"]
  },
  {
    "question": "Which keyword is used in Gherkin to describe a specific test case or scenario?",
    "options": ["Feature", "Scenario", "Given", "When"],
    "answer": "Scenario",
    "explanation": "The `Scenario` keyword in Gherkin is used to describe a specific test case or behavior that needs to be validated.",
    "tags": ["Gherkin", "Keywords", "Scenarios"]
  },
  {
    "question": "What is the main advantage of using Cucumber with Gherkin?",
    "options": [
      "It eliminates the need for automated tests",
      "It automates functional tests based on Gherkin scenarios",
      "It simplifies frontend development",
      "It replaces traditional databases"
    ],
    "answer": "It automates functional tests based on Gherkin scenarios",
    "explanation": "Cucumber parses Gherkin `.feature` files and executes automated functional tests based on the defined scenarios, improving collaboration between technical and non-technical teams.",
    "tags": ["Cucumber", "Automation", "Functional Testing"]
  },
  {
    "question": "Which of the following is true about the `Given` keyword in Gherkin?",
    "options": [
      "It defines the action being performed in the test",
      "It sets up the initial context or state for the test",
      "It specifies the expected outcome of the test",
      "It manages database connections"
    ],
    "answer": "It sets up the initial context or state for the test",
    "explanation": "The `Given` keyword in Gherkin is used to set up the initial context or state before performing actions or validations in a test scenario.",
    "tags": ["Gherkin", "Keywords", "Given"]
  },
  {
    "question": "What is the purpose of step definitions in Cucumber?",
    "options": [
      "To store feature files in a structured format",
      "To implement the logic for each step in a Gherkin scenario",
      "To generate test reports automatically",
      "To manage frontend state"
    ],
    "answer": "To implement the logic for each step in a Gherkin scenario",
    "explanation": "Step definitions are the code implementation of each step in a Gherkin scenario, bridging the gap between plain text descriptions and actual test execution.",
    "tags": ["Cucumber", "Step Definitions", "Implementation"]
  },
  {
    "question": "Which of the following best describes the relationship between Gherkin and Cucumber?",
    "options": [
      "Gherkin eliminates the need for Cucumber",
      "Gherkin provides the syntax for writing scenarios, while Cucumber executes them",
      "There is no relationship; both serve different purposes",
      "Cucumber replaces the need for traditional testing frameworks"
    ],
    "answer": "Gherkin provides the syntax for writing scenarios, while Cucumber executes them",
    "explanation": "Gherkin is the language used to write test scenarios in `.feature` files, while Cucumber parses these files and executes the corresponding step definitions to automate tests.",
    "tags": ["Gherkin", "Cucumber", "Relationship"]
  },
  {
    "question": "Which of the following is a benefit of using Gherkin and Cucumber in BDD?",
    "options": [
      "It makes test cases readable by non-technical stakeholders",
      "It increases the complexity of test cases",
      "It eliminates the need for manual testing entirely",
      "It focuses exclusively on backend development"
    ],
    "answer": "It makes test cases readable by non-technical stakeholders",
    "explanation": "One of the key benefits of Gherkin and Cucumber is that they allow test cases to be written in plain language, making them understandable to business analysts, testers, and developers alike.",
    "tags": ["Gherkin", "Cucumber", "BDD", "Benefits"]
  },
  {
    "question": "What is the role of the `@Then` annotation in Cucumber step definitions?",
    "options": [
      "To define the setup for a test scenario",
      "To specify the expected outcome of a test scenario",
      "To manage database connections",
      "To replace traditional APIs"
    ],
    "answer": "To specify the expected outcome of a test scenario",
    "explanation": "The `@Then` annotation in Cucumber is used to define the expected outcome or assertion for a test scenario after performing the given actions.",
    "tags": ["Cucumber", "Annotations", "Then"]
  },
  {
    "question": "Which of the following is true about Master-Master Replication?",
    "options": [
      "It simplifies failover mechanisms",
      "It allows multiple writable masters, improving write scalability",
      "It eliminates the need for sharding",
      "It focuses exclusively on frontend hosting"
    ],
    "answer": "It allows multiple writable masters, improving write scalability",
    "explanation": "Master-Master Replication enables multiple writable masters, which can improve write scalability and support multi-region setups for global applications.",
    "tags": ["Database Replication", "Master-Master", "Write Scalability"]
  },
  {
    "question": "What is the purpose of the `TestRunner` class in Cucumber (Java)?",
    "options": [
      "To define step definitions for Gherkin scenarios",
      "To execute all test scenarios defined in `.feature` files",
      "To manage database connections",
      "To replace traditional APIs"
    ],
    "answer": "To execute all test scenarios defined in `.feature` files",
    "explanation": "The `TestRunner` class in Cucumber (Java) integrates with JUnit or other testing frameworks to execute all test scenarios defined in `.feature` files and generate test reports.",
    "tags": ["Cucumber", "TestRunner", "Execution"]
  },
  {
    "question": "Which of the following is true about reusing step definitions in Cucumber?",
    "options": [
      "Step definitions cannot be reused across scenarios",
      "Step definitions can be reused across multiple scenarios to avoid duplication",
      "Reusing step definitions increases the complexity of tests unnecessarily",
      "Step definitions focus exclusively on frontend state management"
    ],
    "answer": "Step definitions can be reused across multiple scenarios to avoid duplication",
    "explanation": "Cucumber allows step definitions to be reused across multiple scenarios, reducing redundancy and promoting maintainable test code.",
    "tags": ["Cucumber", "Step Definitions", "Reusability"]
  },
  {
    "question": "What is the role of the `glue` option in Cucumber's `@CucumberOptions` annotation?",
    "options": [
      "To specify the location of `.feature` files",
      "To define the location of step definition classes",
      "To manage database connections",
      "To replace traditional APIs"
    ],
    "answer": "To define the location of step definition classes",
    "explanation": "The `glue` option in Cucumber's `@CucumberOptions` annotation specifies the package or directory containing the step definition classes.",
    "tags": ["Cucumber", "Annotations", "Glue"]
  },
  {
    "question": "Which of the following is a common use case for Gherkin and Cucumber?",
    "options": [
      "Automating functional tests for web applications",
      "Managing database migrations",
      "Encrypting communication between services",
      "Replacing RESTful APIs"
    ],
    "answer": "Automating functional tests for web applications",
    "explanation": "Gherkin and Cucumber are commonly used to automate functional tests for web applications, ensuring that the application behaves as expected from a user perspective.",
    "tags": ["Gherkin", "Cucumber", "Use Cases", "Functional Testing"]
  },
  {
    "question": "What is the main challenge when implementing Gherkin-based testing?",
    "options": [
      "Writing test scenarios in plain English",
      "Mapping Gherkin steps to actual code logic",
      "Generating test reports automatically",
      "Replacing traditional testing frameworks"
    ],
    "answer": "Mapping Gherkin steps to actual code logic",
    "explanation": "A key challenge in Gherkin-based testing is mapping the plain-text steps in `.feature` files to their corresponding step definitions in code, ensuring accurate test execution.",
    "tags": ["Gherkin", "Cucumber", "Challenges", "Step Mapping"]
  },
  {
    "question": "Which of the following is true about Gherkin's support for multiple languages?",
    "options": [
      "Gherkin supports only English",
      "Gherkin supports multiple languages, enabling global team collaboration",
      "Gherkin eliminates the need for translation in international teams",
      "Gherkin focuses exclusively on IoT devices"
    ],
    "answer": "Gherkin supports multiple languages, enabling global team collaboration",
    "explanation": "Gherkin supports multiple languages, allowing teams worldwide to write test scenarios in their native language and fostering better collaboration.",
    "tags": ["Gherkin", "Languages", "Global Collaboration"]
  },
  {
    "question": "What happens when a Gherkin scenario fails during Cucumber execution?",
    "options": [
      "The test run continues to the next scenario",
      "The entire test suite stops immediately",
      "The failed scenario is ignored and not reported",
      "The test suite replaces the need for manual testing"
    ],
    "answer": "The test run continues to the next scenario",
    "explanation": "If a Gherkin scenario fails during Cucumber execution, the test run typically continues to the next scenario, providing detailed reports for analysis and debugging.",
    "tags": ["Cucumber", "Execution", "Failure Handling"]
  },
  {
    "question": "Which of the following is true about the `And` and `But` keywords in Gherkin?",
    "options": [
      "They replace the need for `Given`, `When`, and `Then`",
      "They are synonyms for `Given`, `When`, or `Then` and improve readability",
      "They manage database connections",
      "They focus exclusively on frontend development"
    ],
    "answer": "They are synonyms for `Given`, `When`, or `Then` and improve readability",
    "explanation": "The `And` and `But` keywords in Gherkin act as synonyms for `Given`, `When`, or `Then`, enhancing the readability and flow of test scenarios.",
    "tags": ["Gherkin", "Keywords", "And/But"]
  },
  {
    "question": "What is the purpose of the `features` option in Cucumber's `@CucumberOptions` annotation?",
    "options": [
      "To specify the location of step definition classes",
      "To define the location of `.feature` files containing test scenarios",
      "To manage database connections",
      "To replace traditional APIs"
    ],
    "answer": "To define the location of `.feature` files containing test scenarios",
    "explanation": "The `features` option in Cucumber's `@CucumberOptions` annotation specifies the directory or file path containing the `.feature` files with test scenarios.",
    "tags": ["Cucumber", "Annotations", "Features"]
  },
  {
    "question": "Which of the following best describes the difference between Gherkin and Cucumber?",
    "options": [
      "Gherkin is a testing framework, while Cucumber is a language",
      "Gherkin is the language for writing scenarios, while Cucumber is the tool for executing them",
      "There is no difference; both serve the same purpose",
      "Cucumber eliminates the need for Gherkin"
    ],
    "answer": "Gherkin is the language for writing scenarios, while Cucumber is the tool for executing them",
    "explanation": "Gherkin is the language used to write test scenarios in `.feature` files, while Cucumber is the tool that parses these files and executes the corresponding step definitions.",
    "tags": ["Gherkin", "Cucumber", "Comparison"]
  },
  {
    "question": "What is the main advantage of using Cucumber over traditional testing frameworks?",
    "options": [
      "Cucumber requires no coding knowledge",
      "Cucumber bridges the gap between technical and non-technical teams through natural language",
      "Cucumber eliminates the need for test reports",
      "Cucumber focuses exclusively on frontend testing"
    ],
    "answer": "Cucumber bridges the gap between technical and non-technical teams through natural language",
    "explanation": "Cucumber improves collaboration by allowing test scenarios to be written in natural language, making them accessible to business stakeholders, testers, and developers.",
    "tags": ["Cucumber", "Advantages", "Collaboration"]
  },
  {
    "question": "Which of the following is true about the `Background` section in Gherkin?",
    "options": [
      "It defines steps that are executed before every scenario in a feature file",
      "It replaces the need for `Given` steps in scenarios",
      "It is used exclusively for backend testing",
      "It eliminates the need for test automation"
    ],
    "answer": "It defines steps that are executed before every scenario in a feature file",
    "explanation": "The `Background` section in Gherkin specifies steps that are executed before every scenario in a feature file, setting up a common context or state.",
    "tags": ["Gherkin", "Background", "Test Setup"]
  },
  {
    "question": "What is the role of the `hooks` in Cucumber?",
    "options": [
      "To define environment variables",
      "To execute code before or after scenarios, features, or steps",
      "To manage database connections",
      "To replace traditional APIs"
    ],
    "answer": "To execute code before or after scenarios, features, or steps",
    "explanation": "Cucumber hooks allow you to execute code at specific points in the test lifecycle, such as before or after scenarios, features, or individual steps.",
    "tags": ["Cucumber", "Hooks", "Lifecycle Management"]
  },
  {
    "question": "Which of the following is a benefit of using Cucumber for BDD?",
    "options": [
      "It simplifies the process of writing unit tests",
      "It encourages collaboration between developers, testers, and business stakeholders",
      "It eliminates the need for manual testing entirely",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It encourages collaboration between developers, testers, and business stakeholders",
    "explanation": "Cucumber promotes collaboration by enabling business stakeholders, testers, and developers to work together on defining and validating application behavior through Gherkin scenarios.",
    "tags": ["Cucumber", "BDD", "Collaboration"]
  },
  {
    "question": "What is the purpose of the `@Before` hook in Cucumber?",
    "options": [
      "To define the test scenario itself",
      "To execute setup code before a scenario runs",
      "To manage database migrations",
      "To replace traditional APIs"
    ],
    "answer": "To execute setup code before a scenario runs",
    "explanation": "The `@Before` hook in Cucumber is used to execute setup code, such as initializing test data or starting services, before a scenario begins.",
    "tags": ["Cucumber", "Hooks", "Before Hook"]
  },
  {
    "question": "Which of the following is true about Gherkin's `Scenario Outline` feature?",
    "options": [
      "It allows defining multiple scenarios with varying parameters",
      "It eliminates the need for step definitions",
      "It focuses exclusively on frontend state management",
      "It replaces traditional APIs"
    ],
    "answer": "It allows defining multiple scenarios with varying parameters",
    "explanation": "Gherkin's `Scenario Outline` feature allows you to define multiple scenarios with varying parameters using placeholders and example tables, reducing redundancy.",
    "tags": ["Gherkin", "Scenario Outline", "Parameterization"]
  },
  {
    "question": "What is database sharding primarily used for?",
    "options": [
      "To encrypt communication between clients and servers",
      "To split large datasets across multiple databases for horizontal scaling",
      "To create multiple copies of a database for fault tolerance",
      "To simplify database management"
    ],
    "answer": "To split large datasets across multiple databases for horizontal scaling",
    "explanation": "Database sharding is a horizontal scaling technique that divides large datasets into smaller, more manageable pieces called shards, improving performance and scalability.",
    "tags": ["Database Sharding", "Horizontal Scaling", "Performance"]
  },
  {
    "question": "Which of the following best describes the challenge of implementing sharding?",
    "options": [
      "Sharding reduces query performance significantly",
      "Cross-shard queries require additional handling and complexity",
      "Sharding eliminates the need for replication",
      "Sharding simplifies data routing logic"
    ],
    "answer": "Cross-shard queries require additional handling and complexity",
    "explanation": "One of the main challenges of sharding is managing cross-shard queries, as they require additional logic to combine results from multiple shards.",
    "tags": ["Database Sharding", "Challenges", "Cross-Shard Queries"]
  },
  {
    "question": "What is the purpose of database replication?",
    "options": [
      "To reduce the size of individual databases",
      "To create multiple copies of a database for high availability and read scaling",
      "To replace traditional APIs with event-driven architectures",
      "To focus exclusively on frontend development"
    ],
    "answer": "To create multiple copies of a database for high availability and read scaling",
    "explanation": "Database replication creates copies of a database to improve fault tolerance, high availability, and read performance by distributing read loads across replicas.",
    "tags": ["Database Replication", "Definition", "High Availability"]
  },
  {
    "question": "Which type of replication involves one primary database handling writes while replicas handle reads?",
    "options": [
      "Master-Slave Replication",
      "Master-Master Replication",
      "Log-Based Replication",
      "Shard-Based Replication"
    ],
    "answer": "Master-Slave Replication",
    "explanation": "In Master-Slave Replication, the master database handles all write operations, while slave replicas handle read operations, improving read performance and fault tolerance.",
    "tags": ["Database Replication", "Master-Slave", "Read Scaling"]
  },
  {
    "question": "What is the main advantage of using Master-Master Replication over Master-Slave Replication?",
    "options": [
      "Improved write scalability due to multiple writable masters",
      "Simplified failover handling",
      "Reduced complexity in application logic",
      "Elimination of the need for sharding"
    ],
    "answer": "Improved write scalability due to multiple writable masters",
    "explanation": "Master-Master Replication allows multiple databases to handle both read and write operations, improving write scalability and supporting multi-region setups.",
    "tags": ["Database Replication", "Master-Master", "Write Scalability"]
  },
  {
    "question": "Which replication strategy records changes in logs and sends them to replicas?",
    "options": [
      "Master-Slave Replication",
      "Master-Master Replication",
      "Log-Based Replication",
      "Shard-Based Replication"
    ],
    "answer": "Log-Based Replication",
    "explanation": "Log-Based Replication records changes in logs (e.g., binlogs in MySQL) and replicates these changes to replicas, ensuring consistency across copies.",
    "tags": ["Database Replication", "Log-Based", "Consistency"]
  },
  {
    "question": "What is the role of `getUserShard(userId)` in the sharding example?",
    "options": [
      "It determines which shard to query based on user ID",
      "It encrypts sensitive data",
      "It manages database migrations",
      "It replaces the need for replication"
    ],
    "answer": "It determines which shard to query based on user ID",
    "explanation": "The `getUserShard(userId)` function determines the appropriate shard to query based on the user ID, enabling efficient data retrieval in a sharded database architecture.",
    "tags": ["Database Sharding", "Routing Logic", "Node.js"]
  },
  {
    "question": "Which of the following is a benefit of combining sharding and replication?",
    "options": [
      "It simplifies the system architecture significantly",
      "It improves both scalability and high availability",
      "It eliminates the need for load balancers",
      "It focuses exclusively on frontend state management"
    ],
    "answer": "It improves both scalability and high availability",
    "explanation": "Combining sharding and replication improves scalability by distributing data across shards and ensures high availability by creating redundant copies of each shard's data.",
    "tags": [
      "Database Sharding",
      "Replication",
      "Scalability",
      "High Availability"
    ]
  },
  {
    "question": "What is the main challenge of using Master-Slave Replication?",
    "options": [
      "It increases write performance exponentially",
      "It introduces data lag due to replication delays",
      "It eliminates the need for sharding",
      "It simplifies failover mechanisms"
    ],
    "answer": "It introduces data lag due to replication delays",
    "explanation": "A common challenge in Master-Slave Replication is data lag, where there may be a delay in propagating changes from the master to the slaves.",
    "tags": ["Database Replication", "Master-Slave", "Data Lag"]
  },
  {
    "question": "Which of the following best describes the relationship between sharding and replication?",
    "options": [
      "Sharding and replication are mutually exclusive techniques",
      "Sharding splits data horizontally, while replication creates redundant copies for availability",
      "Replication eliminates the need for sharding",
      "Sharding replaces traditional databases entirely"
    ],
    "answer": "Sharding splits data horizontally, while replication creates redundant copies for availability",
    "explanation": "Sharding distributes data horizontally across multiple databases, while replication creates redundant copies of data to ensure high availability and fault tolerance.",
    "tags": ["Database Sharding", "Replication", "Comparison"]
  },
  {
    "question": "What is the role of read replicas in a database system?",
    "options": [
      "To handle all write operations",
      "To offload read operations from the master database",
      "To store static assets like images and files",
      "To replace the need for caching strategies"
    ],
    "answer": "To offload read operations from the master database",
    "explanation": "Read replicas are used to offload read operations from the master database, improving read performance and reducing the load on the primary database.",
    "tags": ["Database Replication", "Read Replicas", "Performance"]
  },
  {
    "question": "Which of the following is true about data rebalancing in sharded databases?",
    "options": [
      "Data rebalancing is unnecessary in sharded databases",
      "Data rebalancing is required when shards become unbalanced due to uneven data distribution",
      "Data rebalancing eliminates the need for replication",
      "Data rebalancing simplifies database encryption"
    ],
    "answer": "Data rebalancing is required when shards become unbalanced due to uneven data distribution",
    "explanation": "Data rebalancing is necessary in sharded databases to redistribute data evenly across shards when the distribution becomes unbalanced.",
    "tags": ["Database Sharding", "Data Rebalancing", "Scalability"]
  },
  {
    "question": "What is the purpose of using Knex.js in the sharding example?",
    "options": [
      "To manage database connections and execute queries",
      "To encrypt communication between services",
      "To replace traditional REST APIs",
      "To simplify frontend development"
    ],
    "answer": "To manage database connections and execute queries",
    "explanation": "Knex.js is used to manage database connections and execute queries in the sharding example, allowing dynamic routing to different shards based on the user ID.",
    "tags": ["Knex.js", "Database Sharding", "Query Execution"]
  },
  {
    "question": "Which of the following is a key difference between sharding and replication?",
    "options": [
      "Sharding creates multiple copies of data, while replication splits data horizontally",
      "Sharding splits data horizontally across databases, while replication creates redundant copies for availability",
      "There is no difference; both serve the same purpose",
      "Replication focuses exclusively on frontend development"
    ],
    "answer": "Sharding splits data horizontally across databases, while replication creates redundant copies for availability",
    "explanation": "Sharding distributes data horizontally across multiple databases to improve scalability, while replication creates redundant copies of data to enhance availability and fault tolerance.",
    "tags": ["Database Sharding", "Replication", "Comparison"]
  },
  {
    "question": "What is the main disadvantage of Master-Slave Replication?",
    "options": [
      "It increases write performance unnecessarily",
      "It introduces complexity in failover mechanisms",
      "It eliminates the need for load balancers",
      "It focuses exclusively on IoT devices"
    ],
    "answer": "It introduces complexity in failover mechanisms",
    "explanation": "Master-Slave Replication requires complex failover mechanisms to switch to a replica in case the master fails, adding operational overhead.",
    "tags": ["Database Replication", "Master-Slave", "Failover"]
  },
  {
    "question": "Which of the following is true about Log-Based Replication?",
    "options": [
      "It records changes in logs and replicates them to replicas",
      "It eliminates the need for a master database",
      "It focuses exclusively on frontend state management",
      "It simplifies database encryption"
    ],
    "answer": "It records changes in logs and replicates them to replicas",
    "explanation": "Log-Based Replication records changes in logs (e.g., binlogs in MySQL or WAL in PostgreSQL) and replicates these changes to replicas, ensuring consistency across copies.",
    "tags": ["Database Replication", "Log-Based", "Consistency"]
  },
  {
    "question": "What is the role of the `createUser(name)` function in the replication example?",
    "options": [
      "To fetch data from read replicas",
      "To insert data into the master database",
      "To manage database migrations",
      "To replace traditional APIs"
    ],
    "answer": "To insert data into the master database",
    "explanation": "The `createUser(name)` function inserts data into the master database, which is then replicated to read replicas for improved availability and performance.",
    "tags": ["Database Replication", "Master-Slave", "Write Operations"]
  },
  {
    "question": "Which of the following is a benefit of Master-Master Replication?",
    "options": [
      "It simplifies data routing logic",
      "It improves write scalability by allowing multiple writable masters",
      "It eliminates the need for sharding",
      "It focuses exclusively on frontend hosting"
    ],
    "answer": "It improves write scalability by allowing multiple writable masters",
    "explanation": "Master-Master Replication allows multiple writable masters, improving write scalability and supporting multi-region setups for global applications.",
    "tags": ["Database Replication", "Master-Master", "Write Scalability"]
  },
  {
    "question": "What is the main challenge of implementing Master-Master Replication?",
    "options": [
      "It reduces write performance significantly",
      "It introduces conflict resolution issues when multiple masters receive simultaneous writes",
      "It eliminates the need for read replicas",
      "It simplifies database encryption"
    ],
    "answer": "It introduces conflict resolution issues when multiple masters receive simultaneous writes",
    "explanation": "A key challenge in Master-Master Replication is resolving conflicts that arise when multiple masters receive simultaneous write operations.",
    "tags": ["Database Replication", "Master-Master", "Conflict Resolution"]
  },
  {
    "question": "Which of the following is true about database sharding?",
    "options": [
      "Sharding reduces the need for replication",
      "Sharding improves query performance by distributing data across multiple databases",
      "Sharding eliminates the need for load balancers",
      "Sharding focuses exclusively on frontend development"
    ],
    "answer": "Sharding improves query performance by distributing data across multiple databases",
    "explanation": "Database sharding enhances query performance by splitting data horizontally across multiple databases, reducing the load on any single database instance.",
    "tags": ["Database Sharding", "Performance", "Horizontal Scaling"]
  },
  {
    "question": "What is a Distributed System?",
    "options": [
      "A system where all components run on a single server",
      "A system consisting of multiple independent nodes working together as a single system",
      "A system that focuses exclusively on frontend development",
      "A system that eliminates the need for databases"
    ],
    "answer": "A system consisting of multiple independent nodes working together as a single system",
    "explanation": "A Distributed System comprises multiple independent nodes (servers) that collaborate to function as a unified system, improving scalability, availability, and fault tolerance.",
    "tags": ["Distributed Systems", "Definition", "Scalability"]
  },
  {
    "question": "Which of the following is an advantage of Distributed Systems?",
    "options": [
      "Simplified codebase",
      "High availability and fault tolerance",
      "Reduced performance due to network latency",
      "Elimination of APIs"
    ],
    "answer": "High availability and fault tolerance",
    "explanation": "Distributed Systems enhance high availability and fault tolerance by distributing workloads across multiple nodes, ensuring the system remains operational even if some nodes fail.",
    "tags": ["Distributed Systems", "Advantages", "Fault Tolerance"]
  },
  {
    "question": "What is the primary purpose of an API Gateway in a Distributed System?",
    "options": [
      "To store data persistently",
      "To act as a central entry point for routing requests to microservices",
      "To replace the need for Docker containers",
      "To manage frontend state"
    ],
    "answer": "To act as a central entry point for routing requests to microservices",
    "explanation": "An API Gateway serves as the central entry point in a Distributed System, routing client requests to the appropriate microservices and simplifying communication.",
    "tags": ["API Gateway", "Distributed Systems", "Routing"]
  },
  {
    "question": "What does CQRS stand for?",
    "options": [
      "Command Query Responsibility Segregation",
      "Centralized Query Response System",
      "Cloud Query Resource Service",
      "Continuous Query Resolution Strategy"
    ],
    "answer": "Command Query Responsibility Segregation",
    "explanation": "CQRS stands for Command Query Responsibility Segregation, a pattern that separates read and write operations into distinct models to improve scalability and performance.",
    "tags": ["CQRS", "Definition", "Pattern"]
  },
  {
    "question": "Which of the following best describes the benefits of using CQRS?",
    "options": [
      "Optimized read/write performance and separate scalability strategies",
      "Increased complexity without any performance improvements",
      "Focus exclusively on database management",
      "Replacement of traditional APIs"
    ],
    "answer": "Optimized read/write performance and separate scalability strategies",
    "explanation": "CQRS optimizes read and write performance by separating them into different models, allowing independent scaling strategies for each operation.",
    "tags": ["CQRS", "Benefits", "Performance"]
  },
  {
    "question": "What is the role of the Command Service in CQRS?",
    "options": [
      "To handle read operations and fetch data",
      "To handle write operations (create/update/delete)",
      "To store static assets",
      "To replace the need for databases"
    ],
    "answer": "To handle write operations (create/update/delete)",
    "explanation": "In CQRS, the Command Service handles write operations such as creating, updating, or deleting data, while the Query Service focuses on reading data.",
    "tags": ["CQRS", "Command Service", "Write Operations"]
  },
  {
    "question": "What is Event Sourcing?",
    "options": [
      "A system that stores only the current state of data",
      "A technique that stores all events (actions) in an event log for state reconstruction",
      "A protocol for encrypting communication between services",
      "A tool for managing frontend state"
    ],
    "answer": "A technique that stores all events (actions) in an event log for state reconstruction",
    "explanation": "Event Sourcing involves storing all events (actions) in an event log, enabling the reconstruction of past states and providing a complete history of changes.",
    "tags": ["Event Sourcing", "Definition", "State Reconstruction"]
  },
  {
    "question": "Which of the following is a benefit of using Event Sourcing?",
    "options": [
      "Full history tracking and easy audit logs",
      "Elimination of APIs",
      "Simplified database queries",
      "Focus exclusively on frontend development"
    ],
    "answer": "Full history tracking and easy audit logs",
    "explanation": "Event Sourcing provides full history tracking, making it easier to audit logs and debug issues by replaying events to reconstruct past states.",
    "tags": ["Event Sourcing", "Benefits", "Audit Logs"]
  },
  {
    "question": "What is the main challenge when implementing Event Sourcing?",
    "options": [
      "It simplifies state management too much",
      "It requires event replay to reconstruct the current state",
      "It eliminates the need for distributed systems",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It requires event replay to reconstruct the current state",
    "explanation": "One of the challenges of Event Sourcing is that the current state must be reconstructed by replaying all events from the event log, which can be computationally expensive.",
    "tags": ["Event Sourcing", "Challenges", "State Reconstruction"]
  },
  {
    "question": "How do CQRS and Event Sourcing complement each other?",
    "options": [
      "CQRS handles reads, while Event Sourcing handles writes",
      "Event Sourcing eliminates the need for CQRS",
      "CQRS replaces the need for databases in Event Sourcing",
      "There is no relationship between CQRS and Event Sourcing"
    ],
    "answer": "CQRS handles reads, while Event Sourcing handles writes",
    "explanation": "CQRS and Event Sourcing often work together: CQRS separates read and write operations, while Event Sourcing stores all write actions as events for state reconstruction.",
    "tags": ["CQRS", "Event Sourcing", "Integration"]
  },
  {
    "question": "Which of the following is true about combining CQRS and Event Sourcing?",
    "options": [
      "It simplifies the system architecture significantly",
      "It allows writes to store events, and reads to fetch projected state",
      "It eliminates the need for APIs",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It allows writes to store events, and reads to fetch projected state",
    "explanation": "When combining CQRS and Event Sourcing, writes store events in an event log, and reads fetch the projected state, enabling efficient and scalable handling of both operations.",
    "tags": ["CQRS", "Event Sourcing", "Combination"]
  },
  {
    "question": "What is the role of the Query Service in CQRS?",
    "options": [
      "To handle write operations (create/update/delete)",
      "To handle read operations and fetch data",
      "To manage database migrations",
      "To replace traditional firewalls"
    ],
    "answer": "To handle read operations and fetch data",
    "explanation": "In CQRS, the Query Service is responsible for handling read operations, fetching data efficiently without affecting the write model.",
    "tags": ["CQRS", "Query Service", "Read Operations"]
  },
  {
    "question": "Which of the following is a key characteristic of Distributed Systems?",
    "options": [
      "All components are tightly coupled",
      "Components run independently and communicate via APIs or messaging",
      "They focus exclusively on frontend hosting",
      "They eliminate the need for load balancers"
    ],
    "answer": "Components run independently and communicate via APIs or messaging",
    "explanation": "Distributed Systems consist of independent components that communicate through APIs, messaging systems, or other mechanisms, ensuring scalability and fault tolerance.",
    "tags": ["Distributed Systems", "Characteristics", "Communication"]
  },
  {
    "question": "What is the purpose of horizontal scaling in Distributed Systems?",
    "options": [
      "To add more servers to handle increased load",
      "To increase the complexity of the system unnecessarily",
      "To replace the need for databases",
      "To simplify frontend development"
    ],
    "answer": "To add more servers to handle increased load",
    "explanation": "Horizontal scaling in Distributed Systems involves adding more servers to distribute the workload, improving performance and availability under higher loads.",
    "tags": ["Distributed Systems", "Horizontal Scaling", "Performance"]
  },
  {
    "question": "Which of the following is true about Event Logs in Event Sourcing?",
    "options": [
      "They store only the current state of data",
      "They store all events (actions) for state reconstruction",
      "They replace the need for RESTful APIs",
      "They focus exclusively on frontend state management"
    ],
    "answer": "They store all events (actions) for state reconstruction",
    "explanation": "In Event Sourcing, event logs store all events (actions) that have occurred, enabling state reconstruction and providing a complete history of changes.",
    "tags": ["Event Sourcing", "Event Logs", "State Reconstruction"]
  },
  {
    "question": "What is the main disadvantage of CQRS?",
    "options": [
      "It simplifies the system architecture too much",
      "It introduces additional complexity in system design",
      "It eliminates the need for APIs",
      "It focuses exclusively on IoT devices"
    ],
    "answer": "It introduces additional complexity in system design",
    "explanation": "While CQRS offers many advantages, it also introduces complexity in system design, especially when combined with Event Sourcing, requiring careful planning and implementation.",
    "tags": ["CQRS", "Disadvantages", "Complexity"]
  },
  {
    "question": "Which of the following is a common use case for combining CQRS and Event Sourcing?",
    "options": [
      "Static website hosting",
      "Large-scale enterprise applications with complex business logic",
      "Database encryption",
      "Replacing traditional firewalls"
    ],
    "answer": "Large-scale enterprise applications with complex business logic",
    "explanation": "CQRS and Event Sourcing are commonly used in large-scale enterprise applications to handle complex business logic, provide full history tracking, and optimize read/write performance.",
    "tags": ["CQRS", "Event Sourcing", "Use Cases"]
  },
  {
    "question": "What is the role of Event Replay in Event Sourcing?",
    "options": [
      "To encrypt sensitive data",
      "To reconstruct the current state by replaying stored events",
      "To replace the need for microservices",
      "To simplify frontend development"
    ],
    "answer": "To reconstruct the current state by replaying stored events",
    "explanation": "Event Replay in Event Sourcing involves reconstructing the current state of the system by replaying all stored events in chronological order.",
    "tags": ["Event Sourcing", "Event Replay", "State Reconstruction"]
  },
  {
    "question": "Which of the following is true about fault tolerance in Distributed Systems?",
    "options": [
      "It ensures the system remains operational even if some nodes fail",
      "It increases the complexity of monolithic applications",
      "It eliminates the need for APIs",
      "It focuses exclusively on frontend state management"
    ],
    "answer": "It ensures the system remains operational even if some nodes fail",
    "explanation": "Fault tolerance in Distributed Systems ensures that the system continues to operate reliably even when some nodes or components fail, improving overall availability.",
    "tags": ["Distributed Systems", "Fault Tolerance", "Availability"]
  },
  {
    "question": "What is the main goal of separating read and write models in CQRS?",
    "options": [
      "To increase the complexity of the system unnecessarily",
      "To optimize performance by allowing independent scaling of read and write operations",
      "To replace the need for databases",
      "To simplify frontend development"
    ],
    "answer": "To optimize performance by allowing independent scaling of read and write operations",
    "explanation": "Separating read and write models in CQRS enables optimized performance by allowing each model to scale independently based on its specific requirements.",
    "tags": ["CQRS", "Read/Write Separation", "Performance"]
  },
  {
    "question": "Which of the following is a challenge in designing Distributed Systems?",
    "options": [
      "Simplified debugging and monitoring",
      "Network failures and consistency issues",
      "Reduced performance due to tight coupling",
      "Elimination of APIs"
    ],
    "answer": "Network failures and consistency issues",
    "explanation": "Designing Distributed Systems introduces challenges like handling network failures, maintaining consistency, and managing communication between nodes.",
    "tags": ["Distributed Systems", "Challenges", "Consistency"]
  },
  {
    "question": "What is the role of the `addEvent` function in Event Sourcing?",
    "options": [
      "To encrypt communication between services",
      "To store new events in the event log",
      "To replace traditional databases",
      "To simplify frontend development"
    ],
    "answer": "To store new events in the event log",
    "explanation": "The `addEvent` function in Event Sourcing is responsible for storing new events in the event log, preserving the history of all actions in the system.",
    "tags": ["Event Sourcing", "addEvent", "Event Log"]
  },
  {
    "question": "Which of the following best describes the relationship between CQRS and Microservices?",
    "options": [
      "Microservices eliminate the need for CQRS",
      "CQRS is a pattern that aligns well with Microservices for improved scalability",
      "There is no relationship; both serve different purposes",
      "CQRS focuses exclusively on frontend development"
    ],
    "answer": "CQRS is a pattern that aligns well with Microservices for improved scalability",
    "explanation": "CQRS complements Microservices by separating read and write operations, enabling better scalability and fault tolerance in distributed environments.",
    "tags": ["CQRS", "Microservices", "Relationship"]
  },
  {
    "question": "What is the main advantage of using Event Sourcing in Distributed Systems?",
    "options": [
      "It simplifies the system architecture",
      "It provides full history tracking and supports event-driven architectures",
      "It eliminates the need for APIs",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It provides full history tracking and supports event-driven architectures",
    "explanation": "Event Sourcing provides full history tracking by storing all events, making it ideal for event-driven architectures in Distributed Systems.",
    "tags": ["Event Sourcing", "Advantages", "History Tracking"]
  },
  {
    "question": "Which of the following is true about the combination of CQRS and Event Sourcing?",
    "options": [
      "It simplifies the system by combining read and write operations",
      "It allows writes to store events, and reads to fetch projected state",
      "It eliminates the need for distributed systems",
      "It focuses exclusively on static file hosting"
    ],
    "answer": "It allows writes to store events, and reads to fetch projected state",
    "explanation": "In CQRS + Event Sourcing, writes store events in the event log, while reads fetch the projected state, enabling efficient and scalable handling of both operations.",
    "tags": ["CQRS", "Event Sourcing", "Combination"]
  },
  {
    "question": "What is scalability in the context of system design?",
    "options": [
      "The ability of a system to handle increased load efficiently",
      "The process of encrypting communication between services",
      "The practice of writing monolithic applications",
      "The focus on frontend development"
    ],
    "answer": "The ability of a system to handle increased load efficiently",
    "explanation": "Scalability refers to a system's ability to handle an increasing amount of work by adding resources, ensuring efficient performance under higher loads.",
    "tags": ["Scalability", "System Design", "Definition"]
  },
  {
    "question": "Which architecture choice is best suited for startups or MVPs?",
    "options": [
      "Monolithic Architecture",
      "Microservices Architecture",
      "Serverless Architecture",
      "Event-Driven Architecture"
    ],
    "answer": "Monolithic Architecture",
    "explanation": "Monolithic architecture is ideal for startups or MVPs due to its simplicity, faster development, and easier deployment compared to microservices.",
    "tags": ["Monolithic", "MVP", "Startups"]
  },
  {
    "question": "What is the main disadvantage of Monolithic Architecture?",
    "options": [
      "Easier debugging and monitoring",
      "Scalability bottlenecks as the system grows",
      "Faster deployment times",
      "Simplified database management"
    ],
    "answer": "Scalability bottlenecks as the system grows",
    "explanation": "Monolithic systems can face scalability challenges when the application grows, as all components are tightly coupled and must scale together.",
    "tags": ["Monolithic", "Disadvantages", "Scalability"]
  },
  {
    "question": "Which of the following is true about Microservices Architecture?",
    "options": [
      "It combines all components into a single unified application",
      "It divides the system into independent services that communicate via APIs",
      "It eliminates the need for databases",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It divides the system into independent services that communicate via APIs",
    "explanation": "Microservices architecture splits the system into smaller, independent services that communicate with each other through APIs, enabling scalable and resilient systems.",
    "tags": ["Microservices", "Architecture", "Definition"]
  },
  {
    "question": "What is the role of an API Gateway in Microservices Architecture?",
    "options": [
      "To store data persistently across services",
      "To manage encryption and security certificates",
      "To act as a central entry point for handling client requests",
      "To replace traditional databases"
    ],
    "answer": "To act as a central entry point for handling client requests",
    "explanation": "An API Gateway serves as the central entry point for client requests, routing them to the appropriate microservices and simplifying communication.",
    "tags": ["API Gateway", "Microservices", "Routing"]
  },
  {
    "question": "Which of the following tools is commonly used as an API Gateway in Microservices?",
    "options": ["Kong", "MongoDB", "Redis", "Docker"],
    "answer": "Kong",
    "explanation": "Kong is a popular API Gateway tool used in microservices to route requests, enforce rate limiting, and manage authentication.",
    "tags": ["API Gateway", "Kong", "Tools"]
  },
  {
    "question": "What is the main advantage of using separate databases per service in Microservices?",
    "options": [
      "It simplifies the monolithic application structure",
      "It allows independent scaling and reduces coupling between services",
      "It increases the complexity of the system unnecessarily",
      "It replaces the need for API Gateways"
    ],
    "answer": "It allows independent scaling and reduces coupling between services",
    "explanation": "Using separate databases per service in microservices reduces coupling and enables each service to scale independently based on its specific needs.",
    "tags": ["Microservices", "Database Decoupling", "Scalability"]
  },
  {
    "question": "Which of the following is a challenge when transitioning from Monolith to Microservices?",
    "options": [
      "Simplified debugging and monitoring",
      "Complex communication and coordination between services",
      "Reduced development time",
      "Elimination of the need for CI/CD pipelines"
    ],
    "answer": "Complex communication and coordination between services",
    "explanation": "Transitioning to microservices introduces complexities in communication, coordination, and synchronization between independent services, requiring tools like Kafka or RabbitMQ.",
    "tags": ["Microservices", "Transition", "Challenges"]
  },
  {
    "question": "What is the purpose of asynchronous communication in Microservices?",
    "options": [
      "To ensure synchronous execution of tasks",
      "To enable non-blocking communication between services",
      "To replace traditional HTTP APIs",
      "To simplify frontend state management"
    ],
    "answer": "To enable non-blocking communication between services",
    "explanation": "Asynchronous communication in microservices allows non-blocking interactions, improving performance and reliability through tools like Kafka or RabbitMQ.",
    "tags": ["Microservices", "Asynchronous Communication", "Performance"]
  },
  {
    "question": "Which messaging system is commonly used for event-driven interactions in Microservices?",
    "options": ["Kafka", "Express.js", "MySQL", "Nginx"],
    "answer": "Kafka",
    "explanation": "Kafka is a widely used messaging system for event-driven interactions in microservices, enabling reliable and scalable communication between services.",
    "tags": ["Microservices", "Kafka", "Messaging System"]
  },
  {
    "question": "What is the primary benefit of deploying microservices independently?",
    "options": [
      "Increased complexity in deployment",
      "Ability to update and scale individual services without affecting others",
      "Centralized control over all services",
      "Focus exclusively on frontend development"
    ],
    "answer": "Ability to update and scale individual services without affecting others",
    "explanation": "Independent deployment of microservices allows teams to update, deploy, and scale specific services without impacting the entire system, enhancing agility and maintainability.",
    "tags": ["Microservices", "Deployment", "Independence"]
  },
  {
    "question": "Which of the following is true about Monolithic Architecture?",
    "options": [
      "It is designed for large-scale, distributed systems",
      "It is easier to develop and deploy initially but harder to scale",
      "It eliminates the need for APIs",
      "It focuses exclusively on backend development"
    ],
    "answer": "It is easier to develop and deploy initially but harder to scale",
    "explanation": "Monolithic architecture is simpler to develop and deploy at the start but becomes challenging to scale and maintain as the application grows.",
    "tags": ["Monolithic", "Development", "Scalability"]
  },
  {
    "question": "What is the role of Service Discovery in Microservices Architecture?",
    "options": [
      "To encrypt communication between services",
      "To help services locate and communicate with each other dynamically",
      "To replace the need for databases",
      "To simplify frontend development"
    ],
    "answer": "To help services locate and communicate with each other dynamically",
    "explanation": "Service Discovery ensures that services in a microservices architecture can find and communicate with each other dynamically, especially in cloud environments.",
    "tags": ["Microservices", "Service Discovery", "Communication"]
  },
  {
    "question": "Which of the following is a key characteristic of Microservices?",
    "options": [
      "Tight coupling between components",
      "Independent deployment and scaling of services",
      "Single unified codebase",
      "Focus on static website hosting"
    ],
    "answer": "Independent deployment and scaling of services",
    "explanation": "Microservices are characterized by their independence, allowing each service to be deployed, scaled, and maintained separately from others.",
    "tags": ["Microservices", "Characteristics", "Independence"]
  },
  {
    "question": "Which tool is commonly used for orchestrating microservices containers?",
    "options": ["Docker", "Kubernetes", "Redis", "MongoDB"],
    "answer": "Kubernetes",
    "explanation": "Kubernetes is a powerful container orchestration tool used to manage and scale microservices containers in production environments.",
    "tags": ["Microservices", "Kubernetes", "Container Orchestration"]
  },
  {
    "question": "What is the main advantage of using an Event-Driven approach in Microservices?",
    "options": [
      "It ensures synchronous execution of tasks",
      "It simplifies database management",
      "It enables decoupled, scalable communication between services",
      "It replaces the need for APIs"
    ],
    "answer": "It enables decoupled, scalable communication between services",
    "explanation": "An Event-Driven approach in microservices decouples services, allowing them to communicate asynchronously and independently, improving scalability and fault tolerance.",
    "tags": ["Microservices", "Event-Driven", "Decoupling"]
  },
  {
    "question": "Which of the following is true about Monolithic Architecture?",
    "options": [
      "It supports independent scaling of different components",
      "It is easier to debug and monitor due to its unified structure",
      "It eliminates the need for APIs",
      "It focuses exclusively on IoT devices"
    ],
    "answer": "It is easier to debug and monitor due to its unified structure",
    "explanation": "Monolithic architecture is easier to debug and monitor because all components are part of a single application, reducing complexity in early stages.",
    "tags": ["Monolithic", "Debugging", "Monitoring"]
  },
  {
    "question": "What is the role of Docker in designing scalable systems?",
    "options": [
      "To manage database migrations",
      "To containerize applications for consistent deployment",
      "To replace the need for microservices",
      "To simplify frontend development"
    ],
    "answer": "To containerize applications for consistent deployment",
    "explanation": "Docker containerizes applications, ensuring they run consistently across different environments and simplifying deployment processes.",
    "tags": ["Docker", "Containerization", "Deployment"]
  },
  {
    "question": "Which of the following is a common use case for Microservices Architecture?",
    "options": [
      "Small-scale applications with minimal traffic",
      "Large-scale, high-traffic enterprise applications",
      "Static website hosting",
      "Replacing traditional firewalls"
    ],
    "answer": "Large-scale, high-traffic enterprise applications",
    "explanation": "Microservices architecture is well-suited for large-scale, high-traffic applications where independent scaling and resilience are critical.",
    "tags": ["Microservices", "Use Cases", "Enterprise Applications"]
  },
  {
    "question": "What is the purpose of Database Decoupling in Microservices?",
    "options": [
      "To increase the complexity of the system",
      "To allow each service to have its own database, reducing dependencies",
      "To replace the need for API Gateways",
      "To simplify frontend state management"
    ],
    "answer": "To allow each service to have its own database, reducing dependencies",
    "explanation": "Database decoupling in microservices ensures that each service has its own database, reducing dependencies and enabling independent scaling and evolution.",
    "tags": ["Microservices", "Database Decoupling", "Dependencies"]
  },
  {
    "question": "Which of the following best describes the relationship between Monolithic and Microservices Architectures?",
    "options": [
      "Monolithic architecture evolves into microservices as the system grows",
      "There is no relationship; both serve different purposes",
      "Microservices eliminate the need for monolithic applications entirely",
      "Monolithic architecture focuses exclusively on frontend development"
    ],
    "answer": "Monolithic architecture evolves into microservices as the system grows",
    "explanation": "Many systems start as monoliths and transition to microservices as they grow, addressing scalability and maintainability challenges.",
    "tags": ["Monolithic", "Microservices", "Comparison"]
  },
  {
    "question": "What is the role of CI/CD Pipelines in designing scalable systems?",
    "options": [
      "To manually test and deploy applications",
      "To automate testing, building, and deployment processes",
      "To replace traditional databases",
      "To simplify frontend development"
    ],
    "answer": "To automate testing, building, and deployment processes",
    "explanation": "CI/CD pipelines automate testing, building, and deployment, ensuring faster and more reliable delivery of scalable systems.",
    "tags": ["CI/CD", "Automation", "Scalability"]
  },
  {
    "question": "What is the primary purpose of the Publish-Subscribe (Pub/Sub) pattern?",
    "options": [
      "To send messages directly between two services",
      "To allow publishers to send messages to channels/topics without knowing the subscribers",
      "To store data persistently in a database",
      "To replace traditional REST APIs"
    ],
    "answer": "To allow publishers to send messages to channels/topics without knowing the subscribers",
    "explanation": "In the Pub/Sub pattern, publishers send messages to channels or topics, and subscribers receive them in real-time, decoupling the sender and receiver.",
    "tags": ["Pub/Sub", "Redis", "MQTT", "Kafka"]
  },
  {
    "question": "Which library is commonly used for implementing Pub/Sub with Redis in Node.js?",
    "options": ["mqtt", "redis", "kafkajs", "express"],
    "answer": "redis",
    "explanation": "The `redis` library is used to interact with Redis for Pub/Sub functionality, allowing publishers and subscribers to communicate via channels.",
    "tags": ["Redis", "Pub/Sub", "Node.js"]
  },
  {
    "question": "What does the `publish` method do in Redis Pub/Sub?",
    "options": [
      "It subscribes to a channel",
      "It sends a message to a specific channel",
      "It encrypts communication between publisher and subscriber",
      "It replaces the need for a database"
    ],
    "answer": "It sends a message to a specific channel",
    "explanation": "The `publish` method in Redis Pub/Sub sends a message to a specified channel, which can then be received by any subscribers listening to that channel.",
    "tags": ["Redis", "Pub/Sub", "Publish Method"]
  },
  {
    "question": "Which protocol is MQTT primarily used for?",
    "options": [
      "Real-time chat applications",
      "IoT devices and lightweight messaging",
      "Big data processing",
      "Database replication"
    ],
    "answer": "IoT devices and lightweight messaging",
    "explanation": "MQTT is a lightweight messaging protocol designed for IoT devices, offering low power consumption and efficient communication over unreliable networks.",
    "tags": ["MQTT", "IoT", "Lightweight Messaging"]
  },
  {
    "question": "What is the role of the Mosquitto broker in MQTT?",
    "options": [
      "It acts as the central hub for publishing and subscribing",
      "It manages database connections",
      "It encrypts messages between publisher and subscriber",
      "It replaces the need for Redis"
    ],
    "answer": "It acts as the central hub for publishing and subscribing",
    "explanation": "The Mosquitto broker serves as the central hub in MQTT, managing the distribution of messages between publishers and subscribers.",
    "tags": ["MQTT", "Mosquitto", "Broker"]
  },
  {
    "question": "Which of the following best describes the difference between Redis Pub/Sub and Kafka?",
    "options": [
      "Redis Pub/Sub is persistent, while Kafka is in-memory",
      "Redis Pub/Sub is in-memory and lightweight, while Kafka is persistent and scalable",
      "There is no difference; both serve the same purpose",
      "Kafka eliminates the need for a broker"
    ],
    "answer": "Redis Pub/Sub is in-memory and lightweight, while Kafka is persistent and scalable",
    "explanation": "Redis Pub/Sub provides fast, in-memory messaging but lacks persistence. Kafka, on the other hand, offers persistent, scalable messaging for enterprise-grade applications.",
    "tags": ["Redis", "Kafka", "Comparison"]
  },
  {
    "question": "What is the main advantage of using Kafka over Redis Pub/Sub?",
    "options": [
      "Kafka supports only in-memory storage",
      "Kafka provides high-throughput, persistent messaging",
      "Redis Pub/Sub offers better scalability than Kafka",
      "Kafka focuses exclusively on frontend development"
    ],
    "answer": "Kafka provides high-throughput, persistent messaging",
    "explanation": "Kafka is designed for high-throughput, persistent messaging, making it ideal for large-scale event streaming and data pipelines.",
    "tags": ["Kafka", "Persistence", "Scalability"]
  },
  {
    "question": "Which method is used to subscribe to a topic in MQTT?",
    "options": ["subscribe()", "connect()", "publish()", "disconnect()"],
    "answer": "subscribe()",
    "explanation": "The `subscribe()` method in MQTT allows a client to listen for messages on a specific topic, enabling real-time communication.",
    "tags": ["MQTT", "Subscription", "Topics"]
  },
  {
    "question": "What is the role of the `groupId` in Kafka consumers?",
    "options": [
      "It defines the encryption algorithm",
      "It specifies the group to which the consumer belongs for load balancing",
      "It replaces the need for Redis",
      "It manages database migrations"
    ],
    "answer": "It specifies the group to which the consumer belongs for load balancing",
    "explanation": "In Kafka, the `groupId` identifies the consumer group, enabling load balancing and ensuring that each message is consumed by only one member of the group.",
    "tags": ["Kafka", "Consumer Groups", "Load Balancing"]
  },
  {
    "question": "Which of the following is true about Redis Pub/Sub?",
    "options": [
      "Messages are stored persistently in Redis",
      "Redis Pub/Sub provides lightweight, in-memory messaging",
      "Redis Pub/Sub eliminates the need for a broker",
      "Redis Pub/Sub focuses exclusively on IoT devices"
    ],
    "answer": "Redis Pub/Sub provides lightweight, in-memory messaging",
    "explanation": "Redis Pub/Sub offers lightweight, in-memory messaging, making it suitable for real-time applications like chat systems and notifications.",
    "tags": ["Redis", "Pub/Sub", "In-Memory Messaging"]
  },
  {
    "question": "What is the purpose of the `fromBeginning: true` option in Kafka consumers?",
    "options": [
      "It ensures messages are delivered instantly",
      "It allows consumers to read messages from the earliest available offset",
      "It replaces the need for Redis Pub/Sub",
      "It simplifies frontend development"
    ],
    "answer": "It allows consumers to read messages from the earliest available offset",
    "explanation": "The `fromBeginning: true` option in Kafka ensures that consumers start reading messages from the earliest available offset, allowing access to historical data.",
    "tags": ["Kafka", "Consumers", "Message Offsets"]
  },
  {
    "question": "Which of the following is a common use case for Redis Pub/Sub?",
    "options": [
      "Large-scale big data processing",
      "Real-time notifications and chat systems",
      "IoT device communication",
      "Persistent message storage"
    ],
    "answer": "Real-time notifications and chat systems",
    "explanation": "Redis Pub/Sub is commonly used for real-time applications such as notifications, chat systems, and live updates due to its lightweight and fast nature.",
    "tags": ["Redis", "Pub/Sub", "Use Cases"]
  },
  {
    "question": "What does the `eachMessage` event handler do in Kafka consumers?",
    "options": [
      "It processes each message received from a topic",
      "It encrypts communication between producer and consumer",
      "It replaces the need for Redis Pub/Sub",
      "It simplifies database management"
    ],
    "answer": "It processes each message received from a topic",
    "explanation": "The `eachMessage` event handler in Kafka consumers processes each message received from a subscribed topic, enabling real-time message handling.",
    "tags": ["Kafka", "Consumers", "Message Handling"]
  },
  {
    "question": "Which of the following is true about MQTT?",
    "options": [
      "It is designed for IoT devices and lightweight messaging",
      "It uses HTTP/2 for communication",
      "It eliminates the need for a broker",
      "It focuses exclusively on database replication"
    ],
    "answer": "It is designed for IoT devices and lightweight messaging",
    "explanation": "MQTT is specifically designed for IoT devices and lightweight messaging, offering efficient communication over unreliable networks.",
    "tags": ["MQTT", "IoT", "Lightweight Messaging"]
  },
  {
    "question": "What is the role of the `client.publish()` method in MQTT?",
    "options": [
      "It sends a message to a specific topic",
      "It subscribes to a topic",
      "It manages database connections",
      "It replaces the need for WebSockets"
    ],
    "answer": "It sends a message to a specific topic",
    "explanation": "The `client.publish()` method in MQTT sends a message to a specific topic, enabling real-time communication with subscribers.",
    "tags": ["MQTT", "Publishing", "Topics"]
  },
  {
    "question": "Which of the following is a key feature of Kafka?",
    "options": [
      "Low-latency, in-memory messaging",
      "Persistent, high-throughput event streaming",
      "Encrypted communication between clients",
      "Focus on frontend state management"
    ],
    "answer": "Persistent, high-throughput event streaming",
    "explanation": "Kafka is known for its ability to handle persistent, high-throughput event streaming, making it ideal for big data and enterprise-grade applications.",
    "tags": ["Kafka", "Persistence", "Event Streaming"]
  },
  {
    "question": "What is the main disadvantage of Redis Pub/Sub compared to Kafka?",
    "options": [
      "Redis Pub/Sub is too complex to set up",
      "Redis Pub/Sub lacks persistence and durability",
      "Kafka is less secure than Redis Pub/Sub",
      "Redis Pub/Sub cannot handle real-time messaging"
    ],
    "answer": "Redis Pub/Sub lacks persistence and durability",
    "explanation": "While Redis Pub/Sub is fast and lightweight, it lacks persistence and durability, meaning messages are lost if the connection is interrupted.",
    "tags": ["Redis", "Kafka", "Comparison"]
  },
  {
    "question": "Which of the following is true about the Mosquitto broker?",
    "options": [
      "It acts as the central hub for MQTT communication",
      "It eliminates the need for publishers and subscribers",
      "It focuses exclusively on Redis integration",
      "It replaces traditional databases"
    ],
    "answer": "It acts as the central hub for MQTT communication",
    "explanation": "The Mosquitto broker serves as the central hub for MQTT communication, routing messages between publishers and subscribers.",
    "tags": ["MQTT", "Mosquitto", "Broker"]
  },
  {
    "question": "What is the role of the `message.value.toString()` method in Kafka consumers?",
    "options": [
      "It decrypts sensitive data",
      "It converts the message payload to a string format",
      "It manages database connections",
      "It replaces the need for Redis Pub/Sub"
    ],
    "answer": "It converts the message payload to a string format",
    "explanation": "In Kafka consumers, the `message.value.toString()` method converts the binary message payload into a human-readable string format.",
    "tags": ["Kafka", "Consumers", "Message Handling"]
  },
  {
    "question": "Which of the following is a benefit of using Kafka over Redis Pub/Sub?",
    "options": [
      "Kafka provides faster, in-memory messaging",
      "Kafka offers persistent, scalable messaging for large datasets",
      "Redis Pub/Sub eliminates the need for a broker",
      "Redis Pub/Sub focuses exclusively on IoT devices"
    ],
    "answer": "Kafka offers persistent, scalable messaging for large datasets",
    "explanation": "Kafka's persistence and scalability make it better suited for large datasets and enterprise-grade applications compared to Redis Pub/Sub.",
    "tags": ["Kafka", "Redis", "Comparison"]
  },
  {
    "question": "What is the purpose of the `client.on('message', callback)` event in MQTT?",
    "options": [
      "It triggers when a new message is received on a subscribed topic",
      "It sends a message to a specific topic",
      "It manages database connections",
      "It replaces the need for WebSockets"
    ],
    "answer": "It triggers when a new message is received on a subscribed topic",
    "explanation": "The `client.on('message', callback)` event in MQTT triggers whenever a new message is received on a subscribed topic, enabling real-time message handling.",
    "tags": ["MQTT", "Message Handling", "Subscribers"]
  },
  {
    "question": "Which of the following best describes the difference between Redis Pub/Sub and MQTT?",
    "options": [
      "Redis Pub/Sub requires a broker, while MQTT does not",
      "Redis Pub/Sub is in-memory and lightweight, while MQTT is designed for IoT devices",
      "MQTT eliminates the need for publishers and subscribers",
      "Redis Pub/Sub focuses exclusively on database replication"
    ],
    "answer": "Redis Pub/Sub is in-memory and lightweight, while MQTT is designed for IoT devices",
    "explanation": "Redis Pub/Sub is an in-memory, lightweight solution for real-time messaging, whereas MQTT is specifically designed for IoT devices and lightweight messaging over unreliable networks.",
    "tags": ["Redis", "MQTT", "Comparison"]
  },
  {
    "question": "What is the main advantage of using MQTT for IoT devices?",
    "options": [
      "It supports persistent message storage",
      "It offers low power consumption and efficient communication",
      "It eliminates the need for a broker",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It offers low power consumption and efficient communication",
    "explanation": "MQTT is optimized for low power consumption and efficient communication, making it ideal for resource-constrained IoT devices.",
    "tags": ["MQTT", "IoT", "Efficiency"]
  },
  {
    "question": "Which of the following is true about Kafka's consumer groups?",
    "options": [
      "Each consumer group receives all messages from a topic",
      "A consumer group ensures messages are distributed among its members",
      "Kafka eliminates the need for consumer groups",
      "Consumer groups focus exclusively on frontend state management"
    ],
    "answer": "A consumer group ensures messages are distributed among its members",
    "explanation": "In Kafka, a consumer group distributes messages among its members, ensuring load balancing and fault tolerance for message consumption.",
    "tags": ["Kafka", "Consumer Groups", "Load Balancing"]
  },
  {
    "question": "What is the purpose of the `client.subscribe()` method in MQTT?",
    "options": [
      "It sends a message to a specific topic",
      "It listens for messages on a specific topic",
      "It manages database connections",
      "It replaces the need for WebSockets"
    ],
    "answer": "It listens for messages on a specific topic",
    "explanation": "The `client.subscribe()` method in MQTT allows a client to listen for messages on a specific topic, enabling targeted communication.",
    "tags": ["MQTT", "Subscription", "Topics"]
  },
  {
    "question": "Which of the following is true about Kafka's partitioning mechanism?",
    "options": [
      "Partitions increase latency in message delivery",
      "Partitions enable parallelism and scalability in Kafka",
      "Kafka eliminates the need for partitions",
      "Partitions focus exclusively on frontend development"
    ],
    "answer": "Partitions enable parallelism and scalability in Kafka",
    "explanation": "Kafka's partitioning mechanism divides topics into partitions, enabling parallelism and scalability for high-throughput messaging.",
    "tags": ["Kafka", "Partitioning", "Scalability"]
  },
  {
    "question": "What is the primary purpose of WebSockets in web development?",
    "options": [
      "To serve static files",
      "To provide real-time, bidirectional communication between client and server",
      "To encrypt communication between services",
      "To replace traditional APIs"
    ],
    "answer": "To provide real-time, bidirectional communication between client and server",
    "explanation": "WebSockets enable real-time, bidirectional communication, allowing both the client and server to send messages at any time without requiring a new HTTP request.",
    "tags": ["WebSockets", "Socket.io", "Real-Time Communication"]
  },
  {
    "question": "Which library simplifies WebSocket implementation in Node.js applications?",
    "options": ["Express.js", "Socket.io", "Nginx", "MongoDB"],
    "answer": "Socket.io",
    "explanation": "Socket.io is a popular library that simplifies the implementation of WebSockets, providing features like automatic reconnection, fallback mechanisms, and broadcasting.",
    "tags": ["Socket.io", "WebSockets", "Node.js"]
  },
  {
    "question": "What does the `io.on('connection', callback)` event do in Socket.io?",
    "options": [
      "It listens for incoming HTTP requests",
      "It triggers when a client connects to the WebSocket server",
      "It manages database connections",
      "It handles file uploads"
    ],
    "answer": "It triggers when a client connects to the WebSocket server",
    "explanation": "The `io.on('connection', callback)` event in Socket.io is triggered whenever a client establishes a connection to the WebSocket server.",
    "tags": ["Socket.io", "Connection Event", "WebSockets"]
  },
  {
    "question": "Which method is used to broadcast a message to all connected clients in Socket.io?",
    "options": ["socket.send()", "io.emit()", "socket.write()", "io.listen()"],
    "answer": "io.emit()",
    "explanation": "The `io.emit()` method in Socket.io broadcasts a message to all connected clients, including the sender, enabling real-time updates across multiple users.",
    "tags": ["Socket.io", "Broadcasting", "Emit Method"]
  },
  {
    "question": "What happens when a client disconnects from a Socket.io server?",
    "options": [
      "The server automatically restarts",
      "The `disconnect` event is triggered on the server",
      "The server sends an email notification",
      "Nothing; the server ignores disconnections"
    ],
    "answer": "The `disconnect` event is triggered on the server",
    "explanation": "When a client disconnects, the `disconnect` event is triggered on the server, allowing you to handle cleanup or logging tasks.",
    "tags": ["Socket.io", "Disconnect Event", "WebSockets"]
  },
  {
    "question": "Which of the following best describes the relationship between Express.js and Socket.io?",
    "options": [
      "Socket.io replaces the need for Express.js",
      "Socket.io integrates with Express.js to add WebSocket functionality",
      "There is no relationship; both serve different purposes",
      "Express.js eliminates the need for WebSockets"
    ],
    "answer": "Socket.io integrates with Express.js to add WebSocket functionality",
    "explanation": "Socket.io can be integrated with Express.js to add WebSocket functionality, enabling real-time communication alongside traditional HTTP routes.",
    "tags": ["Socket.io", "Express.js", "Integration"]
  },
  {
    "question": "What is the role of the `socket.id` property in Socket.io?",
    "options": [
      "It stores the encryption key for secure communication",
      "It uniquely identifies each connected client",
      "It specifies the port number for the WebSocket server",
      "It manages database connections"
    ],
    "answer": "It uniquely identifies each connected client",
    "explanation": "The `socket.id` property in Socket.io uniquely identifies each connected client, allowing the server to track and communicate with individual clients.",
    "tags": ["Socket.io", "Client Identification", "socket.id"]
  },
  {
    "question": "How do you emit a message from the client to the server in Socket.io?",
    "options": [
      "socket.send('message')",
      "socket.emit('message', data)",
      "io.broadcast('message', data)",
      "server.listen('message', data)"
    ],
    "answer": "socket.emit('message', data)",
    "explanation": "On the client side, you use `socket.emit('event', data)` to send a message to the server, where 'event' is the event name and 'data' is the payload.",
    "tags": ["Socket.io", "Client-Side", "Emit Method"]
  },
  {
    "question": "Which of the following is true about Socket.io's `io.emit()` method?",
    "options": [
      "It sends a message only to the sender",
      "It broadcasts a message to all connected clients, including the sender",
      "It encrypts all WebSocket communications",
      "It replaces traditional HTTP requests entirely"
    ],
    "answer": "It broadcasts a message to all connected clients, including the sender",
    "explanation": "The `io.emit()` method in Socket.io broadcasts a message to all connected clients, including the sender, making it ideal for real-time updates like chat applications.",
    "tags": ["Socket.io", "Broadcasting", "Emit Method"]
  },
  {
    "question": "What is the purpose of the `socket.on('event', callback)` method in Socket.io?",
    "options": [
      "To define environment variables",
      "To listen for events sent by the client or server",
      "To manage database migrations",
      "To optimize image loading"
    ],
    "answer": "To listen for events sent by the client or server",
    "explanation": "The `socket.on('event', callback)` method in Socket.io listens for specific events sent by the client or server, enabling real-time interaction.",
    "tags": ["Socket.io", "Event Handling", "socket.on"]
  },
  {
    "question": "Which of the following is a common use case for WebSockets with Socket.io?",
    "options": [
      "Static website hosting",
      "Real-time chat applications",
      "Database encryption",
      "Frontend state management"
    ],
    "answer": "Real-time chat applications",
    "explanation": "WebSockets with Socket.io are widely used for real-time applications like chat apps, live updates, and multiplayer games, ensuring low-latency communication.",
    "tags": ["WebSockets", "Socket.io", "Use Cases"]
  },
  {
    "question": "What is the role of the `http.createServer(app)` function in the given example?",
    "options": [
      "It creates a WebSocket server directly",
      "It initializes an HTTP server that Socket.io attaches to",
      "It manages database connections",
      "It replaces the need for Nginx"
    ],
    "answer": "It initializes an HTTP server that Socket.io attaches to",
    "explanation": "In the example, `http.createServer(app)` initializes an HTTP server, which Socket.io uses as its transport layer for WebSocket communication.",
    "tags": ["Socket.io", "HTTP Server", "Initialization"]
  },
  {
    "question": "Which of the following is true about Socket.io's fallback mechanisms?",
    "options": [
      "Socket.io only supports WebSockets and has no fallback",
      "Socket.io falls back to long polling if WebSockets are not supported",
      "Socket.io replaces the need for HTTP entirely",
      "Socket.io focuses exclusively on frontend development"
    ],
    "answer": "Socket.io falls back to long polling if WebSockets are not supported",
    "explanation": "Socket.io provides fallback mechanisms like long polling for environments where native WebSockets are not supported, ensuring compatibility.",
    "tags": ["Socket.io", "Fallback Mechanisms", "Compatibility"]
  },
  {
    "question": "What is the main advantage of using WebSockets over traditional HTTP requests?",
    "options": [
      "WebSockets eliminate the need for databases",
      "WebSockets allow real-time, bidirectional communication",
      "WebSockets simplify static file hosting",
      "WebSockets focus exclusively on backend development"
    ],
    "answer": "WebSockets allow real-time, bidirectional communication",
    "explanation": "Unlike traditional HTTP requests, WebSockets enable real-time, bidirectional communication, reducing latency and improving performance for interactive applications.",
    "tags": ["WebSockets", "Advantages", "Real-Time Communication"]
  },
  {
    "question": "Which of the following is true about Socket.io rooms?",
    "options": [
      "Rooms allow grouping of clients for targeted communication",
      "Rooms replace the need for namespaces",
      "Rooms increase latency for large-scale applications",
      "Rooms focus exclusively on frontend state management"
    ],
    "answer": "Rooms allow grouping of clients for targeted communication",
    "explanation": "Socket.io rooms allow you to group clients into specific categories, enabling targeted communication within those groups.",
    "tags": ["Socket.io", "Rooms", "Group Communication"]
  },
  {
    "question": "How do you listen for incoming messages on the client side in Socket.io?",
    "options": [
      "socket.send('message')",
      "socket.on('message', callback)",
      "io.emit('message', data)",
      "server.listen('message', data)"
    ],
    "answer": "socket.on('message', callback)",
    "explanation": "On the client side, you use `socket.on('event', callback)` to listen for events emitted by the server, such as incoming messages.",
    "tags": ["Socket.io", "Client-Side", "Event Listening"]
  },
  {
    "question": "Which of the following best describes the difference between WebSockets and RESTful APIs?",
    "options": [
      "WebSockets provide real-time communication, while RESTful APIs rely on request-response cycles",
      "RESTful APIs support bidirectional communication, while WebSockets do not",
      "WebSockets eliminate the need for encryption, while RESTful APIs require SSL",
      "There is no difference; both serve the same purpose"
    ],
    "answer": "WebSockets provide real-time communication, while RESTful APIs rely on request-response cycles",
    "explanation": "WebSockets enable real-time, bidirectional communication, whereas RESTful APIs follow a request-response model, making them less suitable for low-latency applications.",
    "tags": ["WebSockets", "RESTful APIs", "Comparison"]
  },
  {
    "question": "What is the purpose of namespaces in Socket.io?",
    "options": [
      "To encrypt communication between clients and servers",
      "To separate logical components or features in a WebSocket application",
      "To manage database connections",
      "To replace traditional HTTP routing"
    ],
    "answer": "To separate logical components or features in a WebSocket application",
    "explanation": "Namespaces in Socket.io allow you to segment your WebSocket application into distinct channels, separating logical components or features for better organization.",
    "tags": ["Socket.io", "Namespaces", "Logical Segmentation"]
  },
  {
    "question": "Which of the following is true about Socket.io's `socket.disconnect()` method?",
    "options": [
      "It terminates the connection between the client and server",
      "It encrypts the WebSocket communication",
      "It increases the size of API responses",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It terminates the connection between the client and server",
    "explanation": "The `socket.disconnect()` method in Socket.io explicitly terminates the connection between the client and server, cleaning up resources and handling graceful shutdowns.",
    "tags": ["Socket.io", "Disconnection", "socket.disconnect"]
  },
  {
    "question": "What is the role of the `socket.broadcast.emit()` method in Socket.io?",
    "options": [
      "It sends a message only to the sender",
      "It broadcasts a message to all connected clients except the sender",
      "It encrypts WebSocket communication",
      "It replaces traditional HTTP requests"
    ],
    "answer": "It broadcasts a message to all connected clients except the sender",
    "explanation": "The `socket.broadcast.emit()` method in Socket.io sends a message to all connected clients except the sender, ensuring efficient communication in multi-user scenarios.",
    "tags": ["Socket.io", "Broadcasting", "broadcast.emit"]
  },
  {
    "question": "Which of the following is a benefit of using WebSockets with Socket.io?",
    "options": [
      "They reduce the need for manual testing",
      "They enable real-time communication with minimal latency",
      "They simplify database management",
      "They focus exclusively on frontend development"
    ],
    "answer": "They enable real-time communication with minimal latency",
    "explanation": "WebSockets with Socket.io allow real-time communication between clients and servers, minimizing latency and improving user experience in interactive applications.",
    "tags": ["WebSockets", "Socket.io", "Benefits"]
  },
  {
    "question": "What is the purpose of the `const socket = io('http://localhost:3000')` line in the client-side code?",
    "options": [
      "To initialize a WebSocket connection to the server",
      "To define environment variables",
      "To manage database connections",
      "To replace traditional HTTP requests"
    ],
    "answer": "To initialize a WebSocket connection to the server",
    "explanation": "The `const socket = io('http://localhost:3000')` line initializes a WebSocket connection to the server running on `http://localhost:3000`, enabling real-time communication.",
    "tags": ["Socket.io", "Client-Side", "WebSocket Connection"]
  },
  {
    "question": "Which of the following is true about Socket.io's compatibility?",
    "options": [
      "Socket.io works only with Node.js applications",
      "Socket.io supports multiple programming languages and platforms",
      "Socket.io eliminates the need for WebSockets",
      "Socket.io focuses exclusively on frontend development"
    ],
    "answer": "Socket.io supports multiple programming languages and platforms",
    "explanation": "While Socket.io is commonly used with Node.js, it also supports clients written in other languages, ensuring cross-platform compatibility.",
    "tags": ["Socket.io", "Compatibility", "Cross-Platform"]
  },
  {
    "question": "What is the role of the `socket.id` property in Socket.io?",
    "options": [
      "It uniquely identifies each connected client",
      "It defines the encryption algorithm",
      "It specifies the maximum size of API responses",
      "It manages database queries"
    ],
    "answer": "It uniquely identifies each connected client",
    "explanation": "The `socket.id` property in Socket.io uniquely identifies each connected client, allowing the server to track and communicate with individual users.",
    "tags": ["Socket.io", "Client Identification", "socket.id"]
  },
  {
    "question": "Which of the following is a common use case for WebSockets with Socket.io?",
    "options": [
      "Hosting static websites",
      "Implementing real-time notifications or updates",
      "Managing database migrations",
      "Replacing traditional firewalls"
    ],
    "answer": "Implementing real-time notifications or updates",
    "explanation": "WebSockets with Socket.io are ideal for real-time applications like notifications, live updates, and collaborative tools, ensuring instant delivery of information.",
    "tags": ["WebSockets", "Socket.io", "Use Cases"]
  },
  {
    "question": "What is the primary purpose of CI/CD pipelines in software development?",
    "options": [
      "To manually test and deploy code",
      "To automate testing, building, and deployment processes",
      "To manage database migrations exclusively",
      "To replace traditional APIs"
    ],
    "answer": "To automate testing, building, and deployment processes",
    "explanation": "CI/CD pipelines automate the processes of integrating code changes, running tests, and deploying applications, ensuring faster and more reliable delivery.",
    "tags": ["CI/CD", "Automation", "Deployment"]
  },
  {
    "question": "Which step in a CI/CD pipeline ensures that code changes are automatically tested before deployment?",
    "options": [
      "Building the Docker image",
      "Running automated tests",
      "Deploying to Kubernetes",
      "Configuring GitHub Secrets"
    ],
    "answer": "Running automated tests",
    "explanation": "Automated testing is a critical step in CI/CD pipelines, ensuring that code changes do not introduce bugs or regressions before deployment.",
    "tags": ["CI/CD", "Testing", "Automation"]
  },
  {
    "question": "What is the role of Docker in CI/CD pipelines?",
    "options": [
      "To encrypt communication between services",
      "To containerize applications for consistent environments",
      "To manage Kubernetes deployments",
      "To handle frontend state management"
    ],
    "answer": "To containerize applications for consistent environments",
    "explanation": "Docker containers ensure that applications run consistently across different environments by packaging all dependencies together.",
    "tags": ["Docker", "Containerization", "CI/CD"]
  },
  {
    "question": "Which command builds a Docker image for your application?",
    "options": [
      "docker push myapp",
      "docker build -t myapp .",
      "kubectl apply -f deployment.yaml",
      "npm start"
    ],
    "answer": "docker build -t myapp .",
    "explanation": "The `docker build -t myapp .` command builds a Docker image for your application, tagging it with the name `myapp` for easy reference.",
    "tags": ["Docker", "Build", "Commands"]
  },
  {
    "question": "What does the `replicas` field in a Kubernetes Deployment YAML file specify?",
    "options": [
      "The number of copies of the pod to run",
      "The encryption algorithm for data",
      "The maximum size of API responses",
      "The type of service being deployed"
    ],
    "answer": "The number of copies of the pod to run",
    "explanation": "The `replicas` field in a Kubernetes Deployment specifies how many copies (pods) of the application should be running at all times for scalability and redundancy.",
    "tags": ["Kubernetes", "Deployment", "Replicas"]
  },
  {
    "question": "Which Kubernetes object exposes your application to external traffic?",
    "options": ["Service", "Pod", "Secret", "ConfigMap"],
    "answer": "Service",
    "explanation": "A Kubernetes Service exposes your application to external traffic, enabling access through a stable IP address or DNS name.",
    "tags": ["Kubernetes", "Service", "Exposure"]
  },
  {
    "question": "What is the purpose of the `LoadBalancer` type in a Kubernetes Service?",
    "options": [
      "To expose the service externally via a cloud load balancer",
      "To encrypt sensitive data",
      "To manage database connections",
      "To replace Docker containers"
    ],
    "answer": "To expose the service externally via a cloud load balancer",
    "explanation": "The `LoadBalancer` type in a Kubernetes Service creates an external load balancer in the cloud provider's infrastructure, making the service accessible globally.",
    "tags": ["Kubernetes", "Service", "LoadBalancer"]
  },
  {
    "question": "Which GitHub Actions event triggers a workflow when code is pushed to the `main` branch?",
    "options": ["on: pull_request", "on: push", "on: release", "on: schedule"],
    "answer": "on: push",
    "explanation": "The `on: push` event in GitHub Actions triggers a workflow whenever code is pushed to the specified branch, such as `main`.",
    "tags": ["GitHub Actions", "Triggers", "CI/CD"]
  },
  {
    "question": "What is the role of `kubectl apply` in Kubernetes deployments?",
    "options": [
      "To delete existing pods",
      "To create or update resources from YAML files",
      "To restart the entire cluster",
      "To manage database queries"
    ],
    "answer": "To create or update resources from YAML files",
    "explanation": "The `kubectl apply` command creates or updates Kubernetes resources (e.g., Deployments, Services) based on the provided YAML configuration files.",
    "tags": ["Kubernetes", "kubectl", "Deployment"]
  },
  {
    "question": "Which of the following best describes the relationship between Docker and Kubernetes?",
    "options": [
      "Kubernetes eliminates the need for Docker",
      "Docker containers are deployed and managed by Kubernetes",
      "There is no relationship; both serve different purposes",
      "Docker manages Kubernetes clusters"
    ],
    "answer": "Docker containers are deployed and managed by Kubernetes",
    "explanation": "Docker containers are used to package applications, while Kubernetes manages their deployment, scaling, and availability across a cluster.",
    "tags": ["Docker", "Kubernetes", "Relationship"]
  },
  {
    "question": "What is the purpose of the `containerPort` field in a Kubernetes Deployment YAML file?",
    "options": [
      "To define the port exposed by the container",
      "To specify the encryption algorithm",
      "To configure environment variables",
      "To manage rate limiting"
    ],
    "answer": "To define the port exposed by the container",
    "explanation": "The `containerPort` field in a Kubernetes Deployment specifies the port that the container exposes for incoming traffic.",
    "tags": ["Kubernetes", "Deployment", "Ports"]
  },
  {
    "question": "Which GitHub Actions step logs you into Docker Hub during a CI/CD pipeline?",
    "options": [
      "uses: docker/login-action@v2",
      "run: echo \"${{ secrets.DOCKER_PASSWORD }}\" | docker login",
      "uses: kubectl/setup@v1",
      "run: npm install"
    ],
    "answer": "run: echo \"${{ secrets.DOCKER_PASSWORD }}\" | docker login",
    "explanation": "In GitHub Actions, you can log into Docker Hub using the `echo \"${{ secrets.DOCKER_PASSWORD }}\" | docker login` command, leveraging secrets for secure authentication.",
    "tags": ["GitHub Actions", "Docker", "Authentication"]
  },
  {
    "question": "What is the main advantage of using GitHub Actions for CI/CD pipelines?",
    "options": [
      "It simplifies manual testing",
      "It automates the entire build, test, and deployment process",
      "It replaces the need for Docker",
      "It focuses exclusively on backend development"
    ],
    "answer": "It automates the entire build, test, and deployment process",
    "explanation": "GitHub Actions automates the CI/CD pipeline, handling tasks like building Docker images, running tests, and deploying to platforms like Kubernetes.",
    "tags": ["GitHub Actions", "CI/CD", "Automation"]
  },
  {
    "question": "Which of the following is true about deploying to Kubernetes using GitHub Actions?",
    "options": [
      "GitHub Actions directly manages Kubernetes nodes",
      "You must use `kubectl apply` to deploy resources",
      "Kubernetes eliminates the need for Docker",
      "GitHub Actions replaces Kubernetes entirely"
    ],
    "answer": "You must use `kubectl apply` to deploy resources",
    "explanation": "To deploy to Kubernetes in a GitHub Actions pipeline, you use `kubectl apply` to create or update resources defined in YAML files.",
    "tags": ["Kubernetes", "GitHub Actions", "Deployment"]
  },
  {
    "question": "What is the role of `deployment.yaml` in Kubernetes?",
    "options": [
      "To store secrets securely",
      "To define the structure of the CI/CD pipeline",
      "To specify how the application should be deployed and scaled",
      "To manage frontend state"
    ],
    "answer": "To specify how the application should be deployed and scaled",
    "explanation": "The `deployment.yaml` file in Kubernetes defines the desired state of the application, including the number of replicas, container specifications, and scaling policies.",
    "tags": ["Kubernetes", "Deployment", "YAML"]
  },
  {
    "question": "Which of the following is a benefit of using Docker in CI/CD pipelines?",
    "options": [
      "It simplifies manual server configuration",
      "It ensures consistent environments across development, testing, and production",
      "It eliminates the need for Kubernetes",
      "It focuses exclusively on frontend hosting"
    ],
    "answer": "It ensures consistent environments across development, testing, and production",
    "explanation": "Docker containers provide consistent environments, ensuring that applications behave identically across different stages of the CI/CD pipeline.",
    "tags": ["Docker", "CI/CD", "Consistency"]
  },
  {
    "question": "What is the purpose of the `service.yaml` file in Kubernetes?",
    "options": [
      "To define the application's business logic",
      "To expose the application to external traffic",
      "To manage database connections",
      "To replace traditional firewalls"
    ],
    "answer": "To expose the application to external traffic",
    "explanation": "The `service.yaml` file in Kubernetes defines how to expose the application to external traffic, often using types like `LoadBalancer` or `ClusterIP`.",
    "tags": ["Kubernetes", "Service", "Exposure"]
  },
  {
    "question": "Which of the following best describes the difference between `Deployment` and `Service` in Kubernetes?",
    "options": [
      "Deployment handles scaling and deployment, while Service exposes the app to external traffic",
      "There is no difference; both serve the same purpose",
      "Service manages container images, while Deployment handles network traffic",
      "Deployment focuses on frontend hosting, while Service manages backend databases"
    ],
    "answer": "Deployment handles scaling and deployment, while Service exposes the app to external traffic",
    "explanation": "A Kubernetes Deployment manages the scaling and deployment of containers, while a Service exposes the application to external or internal traffic.",
    "tags": ["Kubernetes", "Deployment", "Service", "Comparison"]
  },
  {
    "question": "What is the role of `secrets` in GitHub Actions workflows?",
    "options": [
      "To store sensitive information securely, like Docker credentials",
      "To define environment variables for local development",
      "To manage Kubernetes nodes",
      "To replace Docker containers"
    ],
    "answer": "To store sensitive information securely, like Docker credentials",
    "explanation": "GitHub Actions secrets securely store sensitive information, such as Docker Hub credentials or API keys, which can be accessed within workflows.",
    "tags": ["GitHub Actions", "Secrets", "Security"]
  },
  {
    "question": "Which of the following is true about continuous deployment (CD)?",
    "options": [
      "CD automates the deployment of applications after successful tests",
      "CD focuses exclusively on manual testing",
      "CD eliminates the need for Docker",
      "CD replaces traditional web servers"
    ],
    "answer": "CD automates the deployment of applications after successful tests",
    "explanation": "Continuous Deployment (CD) automates the deployment process, ensuring that applications are deployed to production after passing automated tests.",
    "tags": ["CI/CD", "Continuous Deployment", "Automation"]
  },
  {
    "question": "What is the purpose of the `needs` keyword in a GitHub Actions workflow?",
    "options": [
      "To specify the encryption algorithm",
      "To define the order of jobs in the workflow",
      "To manage database migrations",
      "To replace Kubernetes configurations"
    ],
    "answer": "To define the order of jobs in the workflow",
    "explanation": "The `needs` keyword in GitHub Actions ensures that one job depends on the successful completion of another, maintaining a logical order in the workflow.",
    "tags": ["GitHub Actions", "Workflow", "Job Dependencies"]
  },
  {
    "question": "Which of the following is a key advantage of Kubernetes over Docker alone?",
    "options": [
      "Kubernetes provides orchestration and scaling for multiple containers",
      "Docker eliminates the need for Kubernetes",
      "There is no difference; both serve the same purpose",
      "Kubernetes focuses exclusively on frontend hosting"
    ],
    "answer": "Kubernetes provides orchestration and scaling for multiple containers",
    "explanation": "While Docker containerizes applications, Kubernetes orchestrates and scales them across multiple nodes, providing features like self-healing and load balancing.",
    "tags": ["Kubernetes", "Docker", "Comparison"]
  },
  {
    "question": "What is the main goal of using `kubectl apply` in a CI/CD pipeline?",
    "options": [
      "To manually test the application",
      "To create or update Kubernetes resources from YAML files",
      "To encrypt sensitive data",
      "To replace Docker containers"
    ],
    "answer": "To create or update Kubernetes resources from YAML files",
    "explanation": "The `kubectl apply` command creates or updates Kubernetes resources (like Deployments and Services) based on the definitions in YAML files.",
    "tags": ["Kubernetes", "kubectl", "CI/CD"]
  },
  {
    "question": "Which of the following is true about CI (Continuous Integration)?",
    "options": [
      "CI automates the integration of code changes with testing",
      "CI focuses exclusively on manual deployment",
      "CI eliminates the need for Docker",
      "CI replaces traditional web hosting platforms"
    ],
    "answer": "CI automates the integration of code changes with testing",
    "explanation": "Continuous Integration (CI) automates the process of integrating code changes, running tests, and ensuring application stability before deployment.",
    "tags": ["CI/CD", "Continuous Integration", "Automation"]
  },
  {
    "question": "What is the role of `actions/checkout@v3` in a GitHub Actions workflow?",
    "options": [
      "To encrypt sensitive data",
      "To check out the repository code into the runner",
      "To manage Kubernetes nodes",
      "To replace Docker images"
    ],
    "answer": "To check out the repository code into the runner",
    "explanation": "The `actions/checkout@v3` step in GitHub Actions checks out the repository code into the runner, allowing subsequent steps to access and work with the code.",
    "tags": ["GitHub Actions", "Checkout", "Workflow"]
  },
  {
    "question": "Which of the following is a common use case for combining Docker, Kubernetes, and GitHub Actions?",
    "options": [
      "To simplify manual server setup",
      "To automate the entire CI/CD pipeline for scalable applications",
      "To focus exclusively on frontend development",
      "To eliminate the need for APIs"
    ],
    "answer": "To automate the entire CI/CD pipeline for scalable applications",
    "explanation": "Combining Docker, Kubernetes, and GitHub Actions enables automation of the entire CI/CD pipeline, ensuring consistent, scalable, and efficient deployments.",
    "tags": ["CI/CD", "Docker", "Kubernetes", "GitHub Actions"]
  },
  {
    "question": "What is the primary purpose of deploying an application?",
    "options": [
      "To make the application accessible to users",
      "To encrypt communication between services",
      "To manage database connections locally",
      "To replace traditional APIs"
    ],
    "answer": "To make the application accessible to users",
    "explanation": "Deploying an application ensures it is hosted on a server or platform, making it accessible to users over the internet.",
    "tags": ["Deployment", "AWS", "Vercel", "DigitalOcean"]
  },
  {
    "question": "Which AWS service is used to host virtual servers for deploying applications?",
    "options": ["S3", "EC2", "Lambda", "RDS"],
    "answer": "EC2",
    "explanation": "AWS EC2 provides virtual servers (instances) where you can deploy and run applications with full control over the environment.",
    "tags": ["AWS", "EC2", "Virtual Servers"]
  },
  {
    "question": "What is the role of Nginx in deploying a Node.js app on AWS EC2?",
    "options": [
      "To serve as a reverse proxy and handle incoming HTTP/HTTPS requests",
      "To encrypt data stored in S3 buckets",
      "To manage Lambda functions",
      "To configure DigitalOcean droplets"
    ],
    "answer": "To serve as a reverse proxy and handle incoming HTTP/HTTPS requests",
    "explanation": "Nginx acts as a reverse proxy in EC2 deployments, forwarding incoming HTTP/HTTPS requests to your Node.js app running on a local port.",
    "tags": ["AWS", "EC2", "Nginx", "Reverse Proxy"]
  },
  {
    "question": "Which command is used to connect to an AWS EC2 instance via SSH?",
    "options": [
      "ssh -i your-key.pem ubuntu@your-ec2-public-ip",
      "aws s3 sync ./your-static-folder s3://your-bucket-name",
      "vercel login",
      "pm2 start server.js"
    ],
    "answer": "ssh -i your-key.pem ubuntu@your-ec2-public-ip",
    "explanation": "The `ssh` command with the `.pem` key connects you to an AWS EC2 instance securely using SSH.",
    "tags": ["AWS", "EC2", "SSH"]
  },
  {
    "question": "What is the main advantage of deploying static files on AWS S3?",
    "options": [
      "It allows public hosting of files with high availability",
      "It eliminates the need for databases",
      "It simplifies backend development",
      "It focuses exclusively on rate limiting"
    ],
    "answer": "It allows public hosting of files with high availability",
    "explanation": "AWS S3 is ideal for hosting static files due to its scalability, durability, and ability to enable public access for global distribution.",
    "tags": ["AWS", "S3", "Static Files"]
  },
  {
    "question": "Which AWS service is best suited for deploying serverless functions?",
    "options": ["EC2", "S3", "Lambda", "RDS"],
    "answer": "Lambda",
    "explanation": "AWS Lambda is designed for serverless computing, allowing you to deploy and execute code without managing servers.",
    "tags": ["AWS", "Lambda", "Serverless"]
  },
  {
    "question": "What does the `vercel` CLI tool help you do?",
    "options": [
      "Deploy frontend and serverless apps effortlessly",
      "Manage AWS EC2 instances",
      "Encrypt database connections",
      "Handle Docker container orchestration"
    ],
    "answer": "Deploy frontend and serverless apps effortlessly",
    "explanation": "The `vercel` CLI tool simplifies deploying Next.js and other frontend/serverless applications, providing automatic scaling and global CDN support.",
    "tags": ["Vercel", "CLI", "Deployment"]
  },
  {
    "question": "Which of the following best describes DigitalOcean Droplets?",
    "options": [
      "Managed databases for PostgreSQL and MySQL",
      "Virtual servers similar to AWS EC2",
      "A tool for encrypting API communications",
      "A frontend framework like React or Vue"
    ],
    "answer": "Virtual servers similar to AWS EC2",
    "explanation": "DigitalOcean Droplets are virtual private servers that provide a simpler alternative to AWS EC2 for hosting and deploying applications.",
    "tags": ["DigitalOcean", "Droplets", "Virtual Servers"]
  },
  {
    "question": "What is the purpose of PM2 in deploying Node.js applications?",
    "options": [
      "To encrypt sensitive data",
      "To manage process stability and auto-restart the app",
      "To deploy apps on AWS Lambda",
      "To simplify database migrations"
    ],
    "answer": "To manage process stability and auto-restart the app",
    "explanation": "PM2 is a process manager for Node.js applications, ensuring they run continuously and automatically restart in case of crashes.",
    "tags": ["Node.js", "PM2", "Process Management"]
  },
  {
    "question": "Which of the following is true about AWS RDS?",
    "options": [
      "It is used to host managed relational databases like PostgreSQL and MySQL",
      "It replaces the need for EC2 instances",
      "It focuses exclusively on frontend development",
      "It manages DigitalOcean droplets"
    ],
    "answer": "It is used to host managed relational databases like PostgreSQL and MySQL",
    "explanation": "AWS RDS provides managed relational database services, simplifying database deployment, operations, and scaling.",
    "tags": ["AWS", "RDS", "Databases"]
  },
  {
    "question": "What is the main difference between AWS EC2 and DigitalOcean Droplets?",
    "options": [
      "There is no difference; both serve the same purpose",
      "DigitalOcean Droplets offer more advanced features than AWS EC2",
      "AWS EC2 provides greater flexibility and scalability for cloud deployments",
      "EC2 is only used for static file hosting"
    ],
    "answer": "AWS EC2 provides greater flexibility and scalability for cloud deployments",
    "explanation": "While both EC2 and Droplets are virtual servers, AWS EC2 offers more flexibility, scalability, and integration with other AWS services.",
    "tags": ["AWS", "EC2", "DigitalOcean", "Comparison"]
  },
  {
    "question": "Which of the following is true about deploying a Next.js app on Vercel?",
    "options": [
      "Vercel simplifies deployment by handling infrastructure automatically",
      "Vercel requires manual configuration of load balancers",
      "Vercel is only suitable for backend-heavy applications",
      "Vercel eliminates the need for a database"
    ],
    "answer": "Vercel simplifies deployment by handling infrastructure automatically",
    "explanation": "Vercel automates the deployment process for Next.js apps, handling infrastructure, scaling, and global CDN distribution.",
    "tags": ["Vercel", "Next.js", "Deployment"]
  },
  {
    "question": "What is the role of the `--acl public-read` flag when uploading files to AWS S3?",
    "options": [
      "To restrict access to specific IP addresses",
      "To make the uploaded files publicly accessible",
      "To encrypt the files during upload",
      "To configure rate limiting for API requests"
    ],
    "answer": "To make the uploaded files publicly accessible",
    "explanation": "The `--acl public-read` flag ensures that files uploaded to AWS S3 are publicly accessible, enabling static website hosting.",
    "tags": ["AWS", "S3", "Public Access"]
  },
  {
    "question": "Which of the following best describes the difference between AWS S3 and AWS Lambda?",
    "options": [
      "S3 stores static files, while Lambda runs serverless functions",
      "S3 encrypts data, while Lambda focuses on frontend development",
      "There is no difference; both serve the same purpose",
      "Lambda replaces the need for S3"
    ],
    "answer": "S3 stores static files, while Lambda runs serverless functions",
    "explanation": "AWS S3 is used for storing and serving static files, while AWS Lambda executes serverless functions in response to events or API requests.",
    "tags": ["AWS", "S3", "Lambda", "Comparison"]
  },
  {
    "question": "What is the main advantage of using DigitalOcean App Platform over manually setting up Droplets?",
    "options": [
      "App Platform simplifies deployment by automating infrastructure setup",
      "Droplets eliminate the need for process managers like PM2",
      "App Platform focuses exclusively on database management",
      "Droplets provide better performance for static websites"
    ],
    "answer": "App Platform simplifies deployment by automating infrastructure setup",
    "explanation": "DigitalOcean App Platform automates many aspects of deployment, including infrastructure setup, scaling, and monitoring, reducing complexity compared to manual Droplet configurations.",
    "tags": ["DigitalOcean", "App Platform", "Deployment"]
  },
  {
    "question": "Which of the following is true about Vercel's deployment capabilities?",
    "options": [
      "Vercel supports both frontend and serverless backend deployments",
      "Vercel is only suitable for static websites",
      "Vercel requires manual setup of load balancers",
      "Vercel eliminates the need for version control systems like Git"
    ],
    "answer": "Vercel supports both frontend and serverless backend deployments",
    "explanation": "Vercel is versatile, supporting deployments for both frontend applications and serverless backend functions seamlessly.",
    "tags": ["Vercel", "Deployment", "Serverless"]
  },
  {
    "question": "What is the purpose of the `vercel init` command?",
    "options": [
      "To initialize a new Vercel project with sample configurations",
      "To encrypt communication between client and server",
      "To manage DigitalOcean droplets",
      "To configure AWS EC2 instances"
    ],
    "answer": "To initialize a new Vercel project with sample configurations",
    "explanation": "The `vercel init` command creates a new Vercel project with pre-configured examples, helping you get started quickly.",
    "tags": ["Vercel", "CLI", "Initialization"]
  },
  {
    "question": "Which of the following is a benefit of using AWS RDS over self-managed databases?",
    "options": [
      "RDS eliminates the need for backups and maintenance",
      "RDS provides fully managed database services with automatic scaling",
      "Self-managed databases offer better performance than RDS",
      "RDS focuses exclusively on frontend development"
    ],
    "answer": "RDS provides fully managed database services with automatic scaling",
    "explanation": "AWS RDS simplifies database management by offering fully managed services with features like automated backups, scaling, and security patches.",
    "tags": ["AWS", "RDS", "Databases"]
  },
  {
    "question": "Which of the following is true about deploying a Node.js app on DigitalOcean Droplets?",
    "options": [
      "You must manually install dependencies and configure the server",
      "Droplets automatically handle all infrastructure and scaling needs",
      "Droplets focus exclusively on frontend hosting",
      "Droplets replace the need for a reverse proxy like Nginx"
    ],
    "answer": "You must manually install dependencies and configure the server",
    "explanation": "When deploying on DigitalOcean Droplets, you are responsible for installing dependencies, configuring the server, and setting up tools like Nginx or PM2.",
    "tags": ["DigitalOcean", "Droplets", "Manual Configuration"]
  },
  {
    "question": "What is the main advantage of deploying a static site on AWS S3?",
    "options": [
      "S3 offers high availability and low latency for static content",
      "S3 eliminates the need for a backend",
      "S3 focuses exclusively on database hosting",
      "S3 replaces traditional web servers like Nginx"
    ],
    "answer": "S3 offers high availability and low latency for static content",
    "explanation": "AWS S3 is optimized for hosting static websites, providing high availability, scalability, and low-latency access to users worldwide.",
    "tags": ["AWS", "S3", "Static Hosting"]
  },
  {
    "question": "Which of the following is true about AWS Lambda?",
    "options": [
      "Lambda runs code in response to events or API requests without managing servers",
      "Lambda is only suitable for hosting static websites",
      "Lambda requires manual setup of load balancers",
      "Lambda eliminates the need for databases"
    ],
    "answer": "Lambda runs code in response to events or API requests without managing servers",
    "explanation": "AWS Lambda is a serverless compute service that runs your code in response to triggers like API Gateway events, eliminating the need to manage servers.",
    "tags": ["AWS", "Lambda", "Serverless"]
  },
  {
    "question": "Which of the following is a common use case for DigitalOcean Managed Databases?",
    "options": [
      "Hosting static websites",
      "Managing relational databases like PostgreSQL or MySQL",
      "Encrypting communication between clients and servers",
      "Replacing traditional firewalls"
    ],
    "answer": "Managing relational databases like PostgreSQL or MySQL",
    "explanation": "DigitalOcean Managed Databases simplify the deployment and management of relational databases like PostgreSQL and MySQL, ensuring reliability and scalability.",
    "tags": ["DigitalOcean", "Managed Databases", "Use Cases"]
  },
  {
    "question": "What is the role of the `proxy_pass` directive in Nginx when deploying on AWS EC2?",
    "options": [
      "To define the encryption algorithm",
      "To forward incoming HTTP/HTTPS requests to the Node.js app",
      "To manage database connections",
      "To replace the need for AWS Lambda"
    ],
    "answer": "To forward incoming HTTP/HTTPS requests to the Node.js app",
    "explanation": "The `proxy_pass` directive in Nginx forwards incoming HTTP/HTTPS requests to your Node.js app running on a local port within the EC2 instance.",
    "tags": ["AWS", "EC2", "Nginx", "Reverse Proxy"]
  },
  {
    "question": "Which of the following best describes the relationship between AWS EC2 and Nginx?",
    "options": [
      "Nginx is used to manage EC2 instances",
      "EC2 hosts the server, while Nginx serves as a reverse proxy",
      "There is no relationship; both serve different purposes",
      "Nginx replaces the need for EC2"
    ],
    "answer": "EC2 hosts the server, while Nginx serves as a reverse proxy",
    "explanation": "In AWS EC2 deployments, Nginx acts as a reverse proxy, forwarding traffic to the application server running on the EC2 instance.",
    "tags": ["AWS", "EC2", "Nginx", "Relationship"]
  },
  {
    "question": "What is the main advantage of using Vercel over AWS EC2 for deploying Next.js apps?",
    "options": [
      "Vercel simplifies deployment with automatic scaling and CDN support",
      "Vercel requires manual server configuration",
      "EC2 offers better performance for frontend apps",
      "Vercel eliminates the need for databases"
    ],
    "answer": "Vercel simplifies deployment with automatic scaling and CDN support",
    "explanation": "Vercel automates the deployment process for Next.js apps, handling scaling, CDN distribution, and infrastructure management.",
    "tags": ["Vercel", "Next.js", "AWS", "Comparison"]
  },
  {
    "question": "Which of the following is true about deploying a database on AWS RDS?",
    "options": [
      "RDS provides managed database services with options for PostgreSQL, MySQL, etc.",
      "RDS eliminates the need for encryption",
      "RDS is only suitable for small-scale applications",
      "RDS replaces traditional web hosting platforms"
    ],
    "answer": "RDS provides managed database services with options for PostgreSQL, MySQL, etc.",
    "explanation": "AWS RDS offers managed database services, supporting popular engines like PostgreSQL, MySQL, and Aurora, while handling backups, scaling, and maintenance.",
    "tags": ["AWS", "RDS", "Databases"]
  },
  {
    "question": "What is the primary purpose of load balancing in web applications?",
    "options": [
      "To encrypt communication between client and server",
      "To distribute incoming traffic across multiple servers for improved performance and availability",
      "To store session data securely",
      "To replace traditional databases"
    ],
    "answer": "To distribute incoming traffic across multiple servers for improved performance and availability",
    "explanation": "Load balancing distributes traffic among multiple backend servers, improving performance, preventing overload on a single server, and ensuring high availability.",
    "tags": ["Load Balancing", "Nginx", "HAProxy", "Scalability"]
  },
  {
    "question": "Which tool is commonly used as both a reverse proxy and a load balancer?",
    "options": ["HAProxy", "Nginx", "Redis", "Docker"],
    "answer": "Nginx",
    "explanation": "Nginx is widely used as a reverse proxy and a load balancer, making it ideal for distributing traffic and serving static content efficiently.",
    "tags": ["Nginx", "Reverse Proxy", "Load Balancer"]
  },
  {
    "question": "What does the `upstream` directive in Nginx's configuration file define?",
    "options": [
      "The encryption algorithm for SSL termination",
      "A group of backend servers to distribute traffic among",
      "The maximum size of uploaded files",
      "The location of static assets"
    ],
    "answer": "A group of backend servers to distribute traffic among",
    "explanation": "The `upstream` directive in Nginx defines a group of backend servers that the load balancer will distribute traffic to using specified algorithms.",
    "tags": ["Nginx", "Upstream", "Configuration"]
  },
  {
    "question": "Which load balancing algorithm is used by default in HAProxy?",
    "options": ["Least connections", "Round-robin", "IP hash", "Random"],
    "answer": "Round-robin",
    "explanation": "HAProxy uses the round-robin algorithm by default, which evenly distributes requests among backend servers in a sequential order.",
    "tags": ["HAProxy", "Load Balancing", "Algorithms"]
  },
  {
    "question": "What is the role of the `balance` directive in HAProxy's configuration?",
    "options": [
      "To specify the SSL certificate",
      "To define the load balancing algorithm",
      "To configure sticky sessions",
      "To set the timeout for requests"
    ],
    "answer": "To define the load balancing algorithm",
    "explanation": "The `balance` directive in HAProxy specifies the load balancing algorithm, such as round-robin, leastconn, or IP hash, to distribute traffic effectively.",
    "tags": ["HAProxy", "Load Balancing", "Configuration"]
  },
  {
    "question": "Which of the following is true about Nginx's load balancing capabilities?",
    "options": [
      "Nginx supports only Layer 4 (TCP) load balancing",
      "Nginx can act as a reverse proxy and perform Layer 7 (HTTP) load balancing",
      "Nginx eliminates the need for backend servers",
      "Nginx focuses exclusively on database management"
    ],
    "answer": "Nginx can act as a reverse proxy and perform Layer 7 (HTTP) load balancing",
    "explanation": "Nginx is capable of acting as a reverse proxy and performing Layer 7 (HTTP) load balancing, making it versatile for web-based applications.",
    "tags": ["Nginx", "Layer 7", "Reverse Proxy"]
  },
  {
    "question": "How do you restart Nginx after modifying its configuration?",
    "options": [
      "sudo systemctl restart nginx",
      "sudo haproxy reload",
      "sudo docker-compose up",
      "sudo redis-server start"
    ],
    "answer": "sudo systemctl restart nginx",
    "explanation": "After modifying Nginx's configuration, you must restart the service using `sudo systemctl restart nginx` to apply changes.",
    "tags": ["Nginx", "Restart", "Configuration"]
  },
  {
    "question": "Which layer does HAProxy support for load balancing?",
    "options": [
      "Only Layer 4 (TCP)",
      "Both Layer 4 (TCP) and Layer 7 (HTTP)",
      "Only Layer 7 (HTTP)",
      "Neither Layer 4 nor Layer 7"
    ],
    "answer": "Both Layer 4 (TCP) and Layer 7 (HTTP)",
    "explanation": "HAProxy supports both Layer 4 (TCP) and Layer 7 (HTTP) load balancing, providing flexibility for various types of traffic.",
    "tags": ["HAProxy", "Layer Support", "Load Balancing"]
  },
  {
    "question": "What is the main advantage of HAProxy over Nginx for load balancing?",
    "options": [
      "HAProxy provides better performance for high-speed, low-latency applications",
      "HAProxy eliminates the need for SSL termination",
      "HAProxy cannot handle HTTP traffic",
      "HAProxy focuses exclusively on frontend development"
    ],
    "answer": "HAProxy provides better performance for high-speed, low-latency applications",
    "explanation": "HAProxy is optimized for high-performance load balancing, making it ideal for handling high-speed, low-latency TCP/HTTP traffic in demanding environments.",
    "tags": ["HAProxy", "Performance", "Comparison"]
  },
  {
    "question": "Which of the following is true about sticky sessions in load balancing?",
    "options": [
      "Sticky sessions ensure that all requests from a user are routed to the same backend server",
      "Sticky sessions increase the likelihood of server overload",
      "Sticky sessions eliminate the need for load balancing",
      "Sticky sessions focus exclusively on database connections"
    ],
    "answer": "Sticky sessions ensure that all requests from a user are routed to the same backend server",
    "explanation": "Sticky sessions bind a user's requests to the same backend server, ensuring consistency in stateful applications like shopping carts or authentication systems.",
    "tags": ["Load Balancing", "Sticky Sessions", "Backend Servers"]
  },
  {
    "question": "What is the purpose of the `check` keyword in HAProxy's server definitions?",
    "options": [
      "To enable health checks for backend servers",
      "To specify the encryption algorithm",
      "To define the maximum number of requests per second",
      "To configure SSL certificates"
    ],
    "answer": "To enable health checks for backend servers",
    "explanation": "The `check` keyword in HAProxy enables health checks for backend servers, ensuring that only healthy servers receive traffic.",
    "tags": ["HAProxy", "Health Checks", "Backend Servers"]
  },
  {
    "question": "Which of the following best describes the difference between Nginx and HAProxy?",
    "options": [
      "Nginx supports only Layer 4 load balancing, while HAProxy supports both Layer 4 and Layer 7",
      "Nginx can act as a reverse proxy, while HAProxy focuses exclusively on load balancing",
      "HAProxy eliminates the need for SSL termination, while Nginx requires it",
      "There is no difference; both serve the same purpose"
    ],
    "answer": "Nginx can act as a reverse proxy, while HAProxy focuses exclusively on load balancing",
    "explanation": "Nginx is versatile, acting as both a reverse proxy and a load balancer, whereas HAProxy is specialized for high-performance load balancing at Layers 4 and 7.",
    "tags": ["Nginx", "HAProxy", "Comparison"]
  },
  {
    "question": "What is the role of the `proxy_pass` directive in Nginx's configuration?",
    "options": [
      "To define the load balancing algorithm",
      "To specify the backend server group for traffic distribution",
      "To encrypt communication between client and server",
      "To manage database connections"
    ],
    "answer": "To specify the backend server group for traffic distribution",
    "explanation": "The `proxy_pass` directive in Nginx specifies the backend server group (defined in `upstream`) where traffic should be forwarded for processing.",
    "tags": ["Nginx", "proxy_pass", "Configuration"]
  },
  {
    "question": "Which of the following is true about SSL termination in load balancing?",
    "options": [
      "SSL termination decrypts traffic at the load balancer, reducing CPU usage on backend servers",
      "SSL termination increases the load on backend servers",
      "SSL termination is not supported by Nginx or HAProxy",
      "SSL termination replaces the need for firewalls"
    ],
    "answer": "SSL termination decrypts traffic at the load balancer, reducing CPU usage on backend servers",
    "explanation": "SSL termination offloads decryption tasks to the load balancer, freeing up CPU resources on backend servers and simplifying security management.",
    "tags": ["Load Balancing", "SSL Termination", "Security"]
  },
  {
    "question": "What is the main benefit of using round-robin load balancing?",
    "options": [
      "It ensures that all backend servers receive an equal share of traffic",
      "It prioritizes traffic based on server load",
      "It binds users to specific backend servers",
      "It eliminates the need for backend servers"
    ],
    "answer": "It ensures that all backend servers receive an equal share of traffic",
    "explanation": "Round-robin load balancing distributes incoming traffic evenly among backend servers, ensuring balanced resource utilization.",
    "tags": ["Load Balancing", "Round-Robin", "Algorithms"]
  },
  {
    "question": "Which of the following is true about Nginx's `upstream` block?",
    "options": [
      "It defines a group of backend servers for load balancing",
      "It configures SSL certificates for secure communication",
      "It specifies the maximum request size",
      "It manages database migrations"
    ],
    "answer": "It defines a group of backend servers for load balancing",
    "explanation": "The `upstream` block in Nginx defines a group of backend servers, allowing the load balancer to distribute traffic among them.",
    "tags": ["Nginx", "Upstream", "Load Balancing"]
  },
  {
    "question": "How do you enable sticky sessions in HAProxy?",
    "options": [
      "Using the `balance` directive",
      "Using the `cookie` directive",
      "Using the `ssl` directive",
      "Using the `upstream` block"
    ],
    "answer": "Using the `cookie` directive",
    "explanation": "In HAProxy, sticky sessions are enabled using the `cookie` directive, which associates requests with specific backend servers via cookies.",
    "tags": ["HAProxy", "Sticky Sessions", "Cookies"]
  },
  {
    "question": "Which of the following is a key feature of HAProxy?",
    "options": [
      "Built-in support for serving static files",
      "High-performance load balancing for TCP and HTTP traffic",
      "Automatic generation of API documentation",
      "Focus on frontend UI development"
    ],
    "answer": "High-performance load balancing for TCP and HTTP traffic",
    "explanation": "HAProxy is renowned for its high-performance load balancing capabilities, supporting both TCP (Layer 4) and HTTP (Layer 7) traffic efficiently.",
    "tags": ["HAProxy", "Performance", "Features"]
  },
  {
    "question": "What is the purpose of health checks in load balancing?",
    "options": [
      "To encrypt communication between client and server",
      "To monitor the status of backend servers and avoid sending traffic to unhealthy ones",
      "To increase the size of API responses",
      "To manage database connections"
    ],
    "answer": "To monitor the status of backend servers and avoid sending traffic to unhealthy ones",
    "explanation": "Health checks ensure that only healthy backend servers receive traffic, improving reliability and preventing downtime due to failed servers.",
    "tags": ["Load Balancing", "Health Checks", "Backend Servers"]
  },
  {
    "question": "Which command is used to reload HAProxy's configuration without downtime?",
    "options": [
      "sudo systemctl restart haproxy",
      "sudo systemctl reload haproxy",
      "sudo nginx -s reload",
      "sudo docker-compose up"
    ],
    "answer": "sudo systemctl reload haproxy",
    "explanation": "To reload HAProxy's configuration without stopping the service, use `sudo systemctl reload haproxy`, ensuring seamless updates during production.",
    "tags": ["HAProxy", "Reload", "Configuration"]
  },
  {
    "question": "Which of the following is true about Layer 7 (HTTP) load balancing?",
    "options": [
      "It operates at the transport layer and balances TCP traffic",
      "It inspects HTTP headers and content to make routing decisions",
      "It eliminates the need for SSL termination",
      "It focuses exclusively on database connections"
    ],
    "answer": "It inspects HTTP headers and content to make routing decisions",
    "explanation": "Layer 7 (HTTP) load balancing examines HTTP headers and content to route traffic intelligently, enabling features like URL-based routing and SSL termination.",
    "tags": ["Load Balancing", "Layer 7", "HTTP"]
  },
  {
    "question": "What is the main disadvantage of not using load balancing in high-traffic applications?",
    "options": [
      "Increased risk of server overload and downtime",
      "Improved performance due to reduced complexity",
      "Elimination of the need for backend servers",
      "Simplified configuration for SSL certificates"
    ],
    "answer": "Increased risk of server overload and downtime",
    "explanation": "Without load balancing, high-traffic applications may overwhelm a single server, leading to overload and potential downtime.",
    "tags": ["Load Balancing", "Scalability", "High Traffic"]
  },
  {
    "question": "Which load balancing algorithm is suitable for applications where each request has similar resource requirements?",
    "options": ["Round-robin", "Least connections", "IP hash", "Random"],
    "answer": "Round-robin",
    "explanation": "Round-robin is ideal for applications where each request consumes similar resources, as it evenly distributes traffic among backend servers.",
    "tags": ["Load Balancing", "Algorithms", "Round-Robin"]
  },
  {
    "question": "What is the role of the `listen` directive in Nginx's configuration?",
    "options": [
      "To specify the port where Nginx listens for incoming traffic",
      "To define the encryption algorithm for SSL termination",
      "To configure sticky sessions",
      "To manage database connections"
    ],
    "answer": "To specify the port where Nginx listens for incoming traffic",
    "explanation": "The `listen` directive in Nginx specifies the port or address where the server listens for incoming traffic, such as `listen 80;` for HTTP traffic.",
    "tags": ["Nginx", "Listen", "Configuration"]
  },
  {
    "question": "Which of the following is true about Layer 4 (TCP) load balancing?",
    "options": [
      "It operates at the application layer and inspects HTTP content",
      "It balances traffic at the transport layer without inspecting HTTP headers",
      "It eliminates the need for backend servers",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It balances traffic at the transport layer without inspecting HTTP headers",
    "explanation": "Layer 4 (TCP) load balancing operates at the transport layer, distributing traffic based on network-level information without inspecting HTTP headers or content.",
    "tags": ["Load Balancing", "Layer 4", "TCP"]
  },
  {
    "question": "What is the primary purpose of API compression?",
    "options": [
      "To encrypt data transmitted between client and server",
      "To reduce payload size for faster responses",
      "To increase database load",
      "To manage user authentication"
    ],
    "answer": "To reduce payload size for faster responses",
    "explanation": "API compression reduces the size of the response payload, leading to faster transmission times, especially beneficial on slow networks.",
    "tags": ["API Optimization", "Compression", "Performance"]
  },
  {
    "question": "Which middleware is commonly used to enable Gzip compression in Express.js?",
    "options": ["express-rate-limit", "compression", "mongoose", "body-parser"],
    "answer": "compression",
    "explanation": "The `compression` middleware in Express.js enables Gzip compression, automatically compressing outgoing responses to reduce their size.",
    "tags": ["Express.js", "Compression", "Middleware"]
  },
  {
    "question": "What is the main advantage of using pagination in APIs?",
    "options": [
      "It increases the size of API responses",
      "It prevents overloading databases with large queries",
      "It eliminates the need for caching",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It prevents overloading databases with large queries",
    "explanation": "Pagination divides large datasets into smaller chunks, preventing database overload and improving API response times by fetching only the required data.",
    "tags": ["API Optimization", "Pagination", "Database Load"]
  },
  {
    "question": "How do you calculate the number of pages needed for pagination?",
    "options": [
      "pages = totalItems / limit",
      "pages = skip * limit",
      "pages = page + limit",
      "pages = Math.ceil(totalItems / limit)"
    ],
    "answer": "pages = Math.ceil(totalItems / limit)",
    "explanation": "The total number of pages is calculated as `Math.ceil(totalItems / limit)`, ensuring all items are covered even if the last page contains fewer items than the limit.",
    "tags": ["Pagination", "Calculation", "API Optimization"]
  },
  {
    "question": "Which query parameters are typically used for implementing pagination in APIs?",
    "options": [
      "page & limit",
      "sort & filter",
      "compress & throttle",
      "encrypt & decrypt"
    ],
    "answer": "page & limit",
    "explanation": "Pagination in APIs is usually implemented using `page` (current page number) and `limit` (number of items per page) query parameters.",
    "tags": ["API Optimization", "Pagination", "Query Parameters"]
  },
  {
    "question": "What is the role of throttling in API optimization?",
    "options": [
      "To increase the speed of API responses",
      "To control the rate of incoming requests and prevent abuse",
      "To store session data securely",
      "To replace traditional databases"
    ],
    "answer": "To control the rate of incoming requests and prevent abuse",
    "explanation": "Throttling limits the number of requests a user can make within a specified time window, preventing abuse such as brute force attacks or DDoS.",
    "tags": ["API Optimization", "Throttling", "Rate Limiting"]
  },
  {
    "question": "Which library is commonly used for throttling in Express.js?",
    "options": ["compression", "mongoose", "express-rate-limit", "passport"],
    "answer": "express-rate-limit",
    "explanation": "`express-rate-limit` is a middleware library that allows you to easily implement throttling in Express.js applications, controlling request rates.",
    "tags": ["Express.js", "Throttling", "Middleware"]
  },
  {
    "question": "What happens when a user exceeds the throttling limit defined by `express-rate-limit`?",
    "options": [
      "The server sends a 200 OK response",
      "The server sends a 429 Too Many Requests error",
      "The server restarts automatically",
      "The server redirects the user to a login page"
    ],
    "answer": "The server sends a 429 Too Many Requests error",
    "explanation": "When a user exceeds the throttling limit, the server responds with a 429 status code, indicating that too many requests have been made within the allowed time frame.",
    "tags": ["Throttling", "Error Handling", "Rate Limiting"]
  },
  {
    "question": "Which method in Mongoose is used to implement pagination?",
    "options": [
      "find().skip().limit()",
      "findOneAndUpdate()",
      "aggregate()",
      "countDocuments()"
    ],
    "answer": "find().skip().limit()",
    "explanation": "In Mongoose, pagination is implemented using `find().skip().limit()`, where `skip` determines the offset and `limit` defines the number of items per page.",
    "tags": ["Mongoose", "Pagination", "MongoDB"]
  },
  {
    "question": "What does the `windowMs` option in `express-rate-limit` define?",
    "options": [
      "The maximum number of requests allowed",
      "The duration of the time window for throttling",
      "The encryption algorithm used",
      "The size of compressed responses"
    ],
    "answer": "The duration of the time window for throttling",
    "explanation": "The `windowMs` option in `express-rate-limit` specifies the duration of the time window (in milliseconds) during which the request limit applies.",
    "tags": ["Throttling", "express-rate-limit", "Configuration"]
  },
  {
    "question": "Which HTTP header indicates that the response has been compressed?",
    "options": [
      "Content-Type",
      "Cache-Control",
      "Content-Encoding",
      "Authorization"
    ],
    "answer": "Content-Encoding",
    "explanation": "The `Content-Encoding` header indicates that the response has been compressed, often set to `gzip` when using compression middleware.",
    "tags": ["Compression", "HTTP Headers", "Gzip"]
  },
  {
    "question": "What is the purpose of the `max` option in `express-rate-limit`?",
    "options": [
      "To define the maximum size of compressed responses",
      "To specify the maximum number of requests allowed per time window",
      "To set the maximum cache expiration time",
      "To increase the database connection limit"
    ],
    "answer": "To specify the maximum number of requests allowed per time window",
    "explanation": "The `max` option in `express-rate-limit` defines the maximum number of requests allowed per IP address within the specified time window.",
    "tags": ["Throttling", "express-rate-limit", "Configuration"]
  },
  {
    "question": "Which of the following best describes the relationship between compression and pagination?",
    "options": [
      "Compression and pagination both aim to reduce database load",
      "Compression reduces payload size, while pagination handles large datasets efficiently",
      "There is no relationship between compression and pagination",
      "Pagination replaces the need for compression"
    ],
    "answer": "Compression reduces payload size, while pagination handles large datasets efficiently",
    "explanation": "Compression focuses on reducing the size of API responses, while pagination ensures efficient handling of large datasets by dividing them into manageable chunks.",
    "tags": ["API Optimization", "Compression", "Pagination", "Comparison"]
  },
  {
    "question": "What is the benefit of combining compression, pagination, and throttling in API design?",
    "options": [
      "It increases the complexity of the API unnecessarily",
      "It enhances performance, scalability, and security simultaneously",
      "It eliminates the need for a database",
      "It simplifies frontend development"
    ],
    "answer": "It enhances performance, scalability, and security simultaneously",
    "explanation": "Combining compression, pagination, and throttling optimizes API performance, improves scalability, and ensures security by controlling resource usage and preventing abuse.",
    "tags": ["API Optimization", "Compression", "Pagination", "Throttling"]
  },
  {
    "question": "Which of the following is true about API compression?",
    "options": [
      "It increases the size of API responses",
      "It reduces the bandwidth required to transmit responses",
      "It requires manual configuration for every response",
      "It eliminates the need for pagination"
    ],
    "answer": "It reduces the bandwidth required to transmit responses",
    "explanation": "API compression reduces the size of responses, minimizing bandwidth usage and speeding up data transfer, especially over slow networks.",
    "tags": ["Compression", "Bandwidth", "Performance"]
  },
  {
    "question": "What is the role of the `skip` parameter in MongoDB pagination?",
    "options": [
      "To define the number of items per page",
      "To specify the maximum number of requests allowed",
      "To skip a certain number of items before returning results",
      "To encrypt sensitive data"
    ],
    "answer": "To skip a certain number of items before returning results",
    "explanation": "The `skip` parameter in MongoDB skips a specified number of items in the dataset, allowing you to fetch results from a specific offset for pagination.",
    "tags": ["Pagination", "MongoDB", "Mongoose"]
  },
  {
    "question": "Which of the following is a common use case for throttling?",
    "options": [
      "Storing passwords securely",
      "Preventing brute force attacks and DDoS",
      "Encrypting communication between services",
      "Managing file uploads"
    ],
    "answer": "Preventing brute force attacks and DDoS",
    "explanation": "Throttling is widely used to prevent abuse, such as brute force attacks or DDoS, by limiting the number of requests a user can make within a time window.",
    "tags": ["Throttling", "Security", "Rate Limiting"]
  },
  {
    "question": "What is the primary goal of API optimization?",
    "options": [
      "To increase the complexity of API logic",
      "To enhance performance, scalability, and efficiency",
      "To eliminate the need for databases",
      "To focus solely on frontend development"
    ],
    "answer": "To enhance performance, scalability, and efficiency",
    "explanation": "API optimization aims to improve performance, ensure scalability, and increase efficiency by employing techniques like compression, pagination, and throttling.",
    "tags": ["API Optimization", "Performance", "Scalability"]
  },
  {
    "question": "Which of the following is true about paginated API responses?",
    "options": [
      "They return all data at once, increasing response time",
      "They divide data into smaller chunks, improving response efficiency",
      "They require Redis for implementation",
      "They eliminate the need for throttling"
    ],
    "answer": "They divide data into smaller chunks, improving response efficiency",
    "explanation": "Paginated API responses break down large datasets into smaller chunks, making it easier to handle and reducing the load on both the server and database.",
    "tags": ["Pagination", "API Optimization", "Efficiency"]
  },
  {
    "question": "What is the default time window for throttling in `express-rate-limit`?",
    "options": [
      "1 minute",
      "5 minutes",
      "1 hour",
      "No default; must be explicitly defined"
    ],
    "answer": "No default; must be explicitly defined",
    "explanation": "`express-rate-limit` does not have a default time window; the `windowMs` option must be explicitly defined based on your requirements.",
    "tags": ["Throttling", "express-rate-limit", "Configuration"]
  },
  {
    "question": "Which of the following is a benefit of using throttling in APIs?",
    "options": [
      "It allows unlimited requests from users",
      "It prevents server overload by controlling request frequency",
      "It increases the size of API responses",
      "It simplifies database queries"
    ],
    "answer": "It prevents server overload by controlling request frequency",
    "explanation": "Throttling helps protect servers from overload by controlling the frequency and volume of incoming requests, ensuring fair usage and preventing abuse.",
    "tags": ["Throttling", "API Optimization", "Server Protection"]
  },
  {
    "question": "What is the purpose of the `message` option in `express-rate-limit`?",
    "options": [
      "To define the encryption algorithm",
      "To specify the custom error message when the rate limit is exceeded",
      "To configure the size of compressed responses",
      "To manage database connections"
    ],
    "answer": "To specify the custom error message when the rate limit is exceeded",
    "explanation": "The `message` option in `express-rate-limit` allows you to define a custom error message that is returned when a user exceeds the rate limit.",
    "tags": ["Throttling", "express-rate-limit", "Error Handling"]
  },
  {
    "question": "Which of the following is true about API compression?",
    "options": [
      "It works only with text-based data formats",
      "It significantly reduces response sizes, improving performance",
      "It replaces the need for pagination",
      "It encrypts sensitive data"
    ],
    "answer": "It significantly reduces response sizes, improving performance",
    "explanation": "API compression, such as Gzip, reduces response sizes by compressing data, leading to faster transmission and improved performance.",
    "tags": ["Compression", "Performance", "Gzip"]
  },
  {
    "question": "What is the role of the `limit` parameter in API pagination?",
    "options": [
      "To define the maximum size of compressed responses",
      "To specify the number of items returned per page",
      "To encrypt communication between client and server",
      "To manage database migrations"
    ],
    "answer": "To specify the number of items returned per page",
    "explanation": "The `limit` parameter in API pagination defines how many items should be returned per page, giving clients control over the amount of data fetched.",
    "tags": ["Pagination", "API Optimization", "Query Parameters"]
  },
  {
    "question": "Which of the following is a key difference between compression and throttling?",
    "options": [
      "Compression focuses on reducing response size, while throttling controls request frequency",
      "Compression increases response size, while throttling decreases it",
      "There is no difference; both serve the same purpose",
      "Throttling replaces the need for compression"
    ],
    "answer": "Compression focuses on reducing response size, while throttling controls request frequency",
    "explanation": "Compression reduces the size of API responses, while throttling limits the number of requests a user can make within a time window, addressing different aspects of API optimization.",
    "tags": ["Compression", "Throttling", "Comparison"]
  },
  {
    "question": "What is the purpose of the `total` field in paginated API responses?",
    "options": [
      "To indicate the total number of items in the dataset",
      "To define the maximum size of compressed responses",
      "To specify the encryption algorithm",
      "To manage database connections"
    ],
    "answer": "To indicate the total number of items in the dataset",
    "explanation": "The `total` field in paginated API responses provides the total count of items in the dataset, helping clients understand the full scope of available data.",
    "tags": ["Pagination", "API Optimization", "Response Fields"]
  },
  {
    "question": "What is the primary purpose of rate limiting in web applications?",
    "options": [
      "To encrypt communication between client and server",
      "To prevent abuse by limiting requests per user",
      "To store session data securely",
      "To replace traditional databases"
    ],
    "answer": "To prevent abuse by limiting requests per user",
    "explanation": "Rate limiting restricts the number of requests a user can make within a specific time frame, preventing abuse such as DDoS attacks or brute force attempts.",
    "tags": ["Rate Limiting", "Security", "Performance"]
  },
  {
    "question": "Which library is commonly used for implementing rate limiting in Express.js?",
    "options": [
      "express-redis-cache",
      "express-rate-limit",
      "cloudflare-cdn",
      "axios"
    ],
    "answer": "express-rate-limit",
    "explanation": "`express-rate-limit` is a middleware library that allows you to easily implement rate limiting in Express.js applications.",
    "tags": ["Express.js", "Rate Limiting", "Middleware"]
  },
  {
    "question": "Why is Redis often used for rate limiting in distributed systems?",
    "options": [
      "It provides persistent storage for logs",
      "It stores rate limits in-memory for high performance",
      "It eliminates the need for APIs",
      "It focuses on frontend development"
    ],
    "answer": "It stores rate limits in-memory for high performance",
    "explanation": "Redis is ideal for rate limiting in distributed systems because it stores data in-memory, ensuring fast access and persistence across multiple servers.",
    "tags": ["Redis", "Rate Limiting", "Distributed Systems"]
  },
  {
    "question": "What happens when a user exceeds the rate limit defined in an Express.js application?",
    "options": [
      "The server sends a 200 OK response",
      "The server sends a 429 Too Many Requests error",
      "The server automatically restarts",
      "The server redirects the user to a login page"
    ],
    "answer": "The server sends a 429 Too Many Requests error",
    "explanation": "When a user exceeds the rate limit, the server responds with a 429 status code, indicating that too many requests have been made within the allowed time window.",
    "tags": ["Express.js", "Rate Limiting", "Error Handling"]
  },
  {
    "question": "Which caching strategy reduces database load by storing frequent queries in memory?",
    "options": [
      "Edge caching",
      "In-memory caching with Redis",
      "Database indexing",
      "Frontend state management"
    ],
    "answer": "In-memory caching with Redis",
    "explanation": "Redis provides in-memory caching, allowing frequent queries to be stored and retrieved quickly, reducing database load and improving application performance.",
    "tags": ["Caching", "Redis", "Performance Optimization"]
  },
  {
    "question": "What does the `setex` method in Redis do?",
    "options": [
      "Sets a key with no expiration",
      "Sets a key with a specified expiration time (TTL)",
      "Deletes a key from Redis",
      "Encrypts sensitive data"
    ],
    "answer": "Sets a key with a specified expiration time (TTL)",
    "explanation": "The `setex` method in Redis sets a key with a specified expiration time (in seconds), ensuring cached data is automatically removed after the TTL expires.",
    "tags": ["Redis", "Caching", "TTL"]
  },
  {
    "question": "Which HTTP header controls caching behavior in Cloudflare?",
    "options": [
      "Content-Type",
      "Cache-Control",
      "Authorization",
      "X-RateLimit-Limit"
    ],
    "answer": "Cache-Control",
    "explanation": "The `Cache-Control` header specifies caching rules, such as `public`, `max-age`, and `s-maxage`, which control how long responses are cached in Cloudflare.",
    "tags": ["Cloudflare", "Caching", "HTTP Headers"]
  },
  {
    "question": "What is the advantage of using Cloudflare's edge caching?",
    "options": [
      "It stores data locally on the user's device",
      "It caches content globally for faster delivery",
      "It replaces the need for Redis",
      "It encrypts all API responses"
    ],
    "answer": "It caches content globally for faster delivery",
    "explanation": "Cloudflare's edge caching stores content at geographically distributed locations, enabling faster delivery to users regardless of their location.",
    "tags": ["Cloudflare", "Edge Caching", "Global Delivery"]
  },
  {
    "question": "Which of the following best describes the difference between Redis caching and Cloudflare caching?",
    "options": [
      "Redis is used for frontend caching, while Cloudflare is for backend",
      "Redis stores data in-memory on the server, while Cloudflare caches content at the edge",
      "There is no difference; both serve the same purpose",
      "Cloudflare eliminates the need for Redis"
    ],
    "answer": "Redis stores data in-memory on the server, while Cloudflare caches content at the edge",
    "explanation": "Redis provides in-memory caching on the server side, while Cloudflare caches content at the edge, closer to the user, for faster global delivery.",
    "tags": ["Redis", "Cloudflare", "Caching", "Comparison"]
  },
  {
    "question": "What is the role of the `req.ip` property in rate limiting with Redis?",
    "options": [
      "To define the request body",
      "To identify the user's IP address for rate limiting",
      "To set the cache expiration time",
      "To manage database connections"
    ],
    "answer": "To identify the user's IP address for rate limiting",
    "explanation": "The `req.ip` property identifies the user's IP address, allowing rate limits to be applied per user in distributed systems.",
    "tags": ["Redis", "Rate Limiting", "IP Identification"]
  },
  {
    "question": "Which of the following is true about Cloudflare's DDoS protection?",
    "options": [
      "It blocks malicious traffic before it reaches the server",
      "It increases the size of API responses",
      "It requires manual configuration for every request",
      "It replaces traditional firewalls entirely"
    ],
    "answer": "It blocks malicious traffic before it reaches the server",
    "explanation": "Cloudflare's DDoS protection blocks malicious traffic at the edge, ensuring only legitimate requests reach your server.",
    "tags": ["Cloudflare", "DDoS Protection", "Security"]
  },
  {
    "question": "What is the purpose of the `consume` method in `rate-limiter-flexible`?",
    "options": [
      "To fetch data from Redis",
      "To consume API responses directly",
      "To deduct points from the user's rate limit quota",
      "To generate random session IDs"
    ],
    "answer": "To deduct points from the user's rate limit quota",
    "explanation": "The `consume` method in `rate-limiter-flexible` deducts points from the user's rate limit quota, ensuring compliance with defined limits.",
    "tags": ["Rate Limiting", "Redis", "rate-limiter-flexible"]
  },
  {
    "question": "Which of the following is a benefit of using Redis over Cloudflare for caching?",
    "options": [
      "Redis caches content globally at the edge",
      "Redis provides more control over cache invalidation",
      "Cloudflare cannot handle large-scale traffic",
      "Redis eliminates the need for APIs"
    ],
    "answer": "Redis provides more control over cache invalidation",
    "explanation": "While Cloudflare offers edge caching, Redis provides finer-grained control over cache invalidation and TTL settings, making it suitable for custom caching strategies.",
    "tags": ["Redis", "Cloudflare", "Caching", "Comparison"]
  },
  {
    "question": "What is the purpose of the `Cache-Control` header's `s-maxage` directive?",
    "options": [
      "To specify the maximum age for shared caches like Cloudflare",
      "To define the encryption algorithm",
      "To increase the size of API responses",
      "To replace traditional databases"
    ],
    "answer": "To specify the maximum age for shared caches like Cloudflare",
    "explanation": "The `s-maxage` directive in the `Cache-Control` header specifies the maximum age for shared caches (e.g., Cloudflare), overriding the `max-age` for proxy servers.",
    "tags": ["Cloudflare", "Caching", "HTTP Headers"]
  },
  {
    "question": "Which of the following is true about caching with Redis?",
    "options": [
      "It is slower than traditional databases",
      "It stores data in-memory for fast retrieval",
      "It eliminates the need for APIs",
      "It focuses exclusively on frontend caching"
    ],
    "answer": "It stores data in-memory for fast retrieval",
    "explanation": "Redis stores cached data in-memory, ensuring fast retrieval times for frequently accessed information.",
    "tags": ["Redis", "Caching", "Performance"]
  },
  {
    "question": "What is the role of `rate-limiter-flexible` in distributed rate limiting?",
    "options": [
      "To define caching strategies",
      "To implement persistent rate limits across multiple servers",
      "To replace the need for APIs",
      "To manage database connections"
    ],
    "answer": "To implement persistent rate limits across multiple servers",
    "explanation": "`rate-limiter-flexible` integrates with Redis to implement persistent rate limits across multiple servers in a distributed system.",
    "tags": ["Rate Limiting", "Redis", "rate-limiter-flexible"]
  },
  {
    "question": "Which of the following is a common use case for Cloudflare caching?",
    "options": [
      "Storing passwords securely",
      "Caching static assets globally for faster delivery",
      "Managing database migrations",
      "Replacing traditional APIs"
    ],
    "answer": "Caching static assets globally for faster delivery",
    "explanation": "Cloudflare is commonly used to cache static assets and API responses globally, ensuring faster delivery to users worldwide.",
    "tags": ["Cloudflare", "Caching", "Static Assets"]
  },
  {
    "question": "What happens when a cached response expires in Redis?",
    "options": [
      "The server sends a 404 Not Found error",
      "The server fetches fresh data and updates the cache",
      "The cache remains forever unless manually cleared",
      "The server redirects the user to a login page"
    ],
    "answer": "The server fetches fresh data and updates the cache",
    "explanation": "When a cached response expires in Redis, the server fetches fresh data from the source and updates the cache with the new response.",
    "tags": ["Redis", "Caching", "Expiration"]
  },
  {
    "question": "Which of the following is true about Redis's role in caching?",
    "options": [
      "It encrypts all API responses",
      "It stores cached data in-memory for fast access",
      "It replaces the need for Cloudflare",
      "It focuses exclusively on frontend state management"
    ],
    "answer": "It stores cached data in-memory for fast access",
    "explanation": "Redis stores cached data in-memory, providing fast access and reducing latency for frequent queries.",
    "tags": ["Redis", "Caching", "In-Memory Storage"]
  },
  {
    "question": "What is the main advantage of combining Redis and Cloudflare for caching?",
    "options": [
      "Redis handles edge caching, while Cloudflare manages in-memory storage",
      "Cloudflare handles global distribution, while Redis provides fine-grained control",
      "Both tools focus exclusively on frontend caching",
      "They eliminate the need for APIs entirely"
    ],
    "answer": "Cloudflare handles global distribution, while Redis provides fine-grained control",
    "explanation": "Cloudflare distributes cached content globally at the edge, while Redis provides fine-grained control over caching policies and TTL settings.",
    "tags": ["Redis", "Cloudflare", "Caching", "Integration"]
  },
  {
    "question": "Which HTTP status code indicates that a user has exceeded the rate limit?",
    "options": [
      "200 OK",
      "404 Not Found",
      "500 Internal Server Error",
      "429 Too Many Requests"
    ],
    "answer": "429 Too Many Requests",
    "explanation": "The 429 status code is returned when a user exceeds the defined rate limit, signaling that they should slow down their requests.",
    "tags": ["Rate Limiting", "HTTP Status Codes", "Error Handling"]
  },
  {
    "question": "What is the primary purpose of setting `Cache-Control: public, max-age=300, s-maxage=600` in an Express.js API?",
    "options": [
      "To encrypt API responses",
      "To define caching rules for browsers and proxies",
      "To increase the size of API responses",
      "To replace Redis caching entirely"
    ],
    "answer": "To define caching rules for browsers and proxies",
    "explanation": "The `Cache-Control` header defines caching rules, such as `max-age` for browser caching and `s-maxage` for shared caches like Cloudflare.",
    "tags": ["Express.js", "Caching", "HTTP Headers"]
  },
  {
    "question": "Which of the following is true about Redis's TTL (Time To Live) feature?",
    "options": [
      "It ensures data persists indefinitely",
      "It specifies the expiration time for cached data",
      "It replaces the need for APIs",
      "It focuses exclusively on frontend development"
    ],
    "answer": "It specifies the expiration time for cached data",
    "explanation": "Redis's TTL feature allows you to define the expiration time for cached data, ensuring stale data is automatically removed.",
    "tags": ["Redis", "Caching", "TTL"]
  },
  {
    "question": "What is the role of Cloudflare in improving web application performance?",
    "options": [
      "It encrypts all API communications",
      "It acts as a global CDN for caching and distributing content",
      "It replaces traditional databases",
      "It focuses solely on rate limiting"
    ],
    "answer": "It acts as a global CDN for caching and distributing content",
    "explanation": "Cloudflare serves as a global CDN, caching content at the edge and distributing it efficiently to users worldwide, improving performance and scalability.",
    "tags": ["Cloudflare", "CDN", "Performance"]
  },
  {
    "question": "What is a vector in Linear Algebra?",
    "options": [
      "A scalar value representing magnitude",
      "An ordered list of numbers representing a point or direction in space",
      "A rectangular array of numbers",
      "A function that maps vectors to scalars"
    ],
    "answer": "An ordered list of numbers representing a point or direction in space",
    "explanation": "A vector is an ordered list of numbers that can represent a point or direction in multi-dimensional space.",
    "tags": ["Linear Algebra", "Vectors", "Definition"]
  },
  {
    "question": "What does scalar multiplication do to a vector?",
    "options": [
      "It changes the direction of the vector",
      "It scales the vector's magnitude",
      "It adds another vector to it",
      "It calculates the determinant"
    ],
    "answer": "It scales the vector's magnitude",
    "explanation": "Scalar multiplication scales the magnitude of a vector by multiplying each component by the scalar value.",
    "tags": ["Linear Algebra", "Vectors", "Scalar Multiplication"]
  },
  {
    "question": "What is a matrix in Linear Algebra?",
    "options": [
      "A single number representing magnitude",
      "A rectangular array of numbers used for transformations",
      "An ordered list of numbers",
      "A function that maps vectors to scalars"
    ],
    "answer": "A rectangular array of numbers used for transformations",
    "explanation": "A matrix is a rectangular array of numbers used for transformations, solving systems of equations, and representing linear maps.",
    "tags": ["Linear Algebra", "Matrices", "Definition"]
  },
  {
    "question": "What does the determinant of a matrix indicate?",
    "options": [
      "The sum of all elements in the matrix",
      "Whether the matrix is invertible",
      "The dot product of its rows",
      "The eigenvalues of the matrix"
    ],
    "answer": "Whether the matrix is invertible",
    "explanation": "The determinant of a matrix tells us whether it is invertible. If the determinant is non-zero, the matrix has an inverse; otherwise, it does not.",
    "tags": ["Linear Algebra", "Matrices", "Determinant"]
  },
  {
    "question": "What are eigenvalues and eigenvectors used for in Linear Algebra?",
    "options": [
      "To calculate the determinant of a matrix",
      "To describe how a matrix scales or rotates vectors",
      "To add two matrices together",
      "To perform scalar multiplication on vectors"
    ],
    "answer": "To describe how a matrix scales or rotates vectors",
    "explanation": "Eigenvalues and eigenvectors describe how a matrix transforms vectors, specifically scaling or rotating them without changing their direction.",
    "tags": ["Linear Algebra", "Eigenvalues", "Eigenvectors"]
  },
  {
    "question": "What is the significance of eigenvalues in Principal Component Analysis (PCA)?",
    "options": [
      "They determine the variance explained by each principal component",
      "They calculate the determinant of the covariance matrix",
      "They add vectors in the dataset",
      "They encrypt data in the dataset"
    ],
    "answer": "They determine the variance explained by each principal component",
    "explanation": "In PCA, eigenvalues represent the amount of variance captured by each principal component, helping reduce dimensionality while preserving important information.",
    "tags": ["Linear Algebra", "Eigenvalues", "PCA"]
  },
  {
    "question": "What happens when a matrix has a determinant of zero?",
    "options": [
      "The matrix is invertible",
      "The matrix is not invertible",
      "The matrix becomes a vector",
      "The matrix performs scalar multiplication"
    ],
    "answer": "The matrix is not invertible",
    "explanation": "If the determinant of a matrix is zero, the matrix is singular and cannot be inverted. This indicates linear dependence among its rows or columns.",
    "tags": ["Linear Algebra", "Matrices", "Determinant"]
  },
  {
    "question": "Which operation is performed during matrix addition?",
    "options": [
      "Adding corresponding elements of the matrices",
      "Multiplying corresponding elements of the matrices",
      "Calculating the determinant of both matrices",
      "Finding eigenvalues of both matrices"
    ],
    "answer": "Adding corresponding elements of the matrices",
    "explanation": "Matrix addition involves adding corresponding elements of two matrices of the same dimensions.",
    "tags": ["Linear Algebra", "Matrices", "Addition"]
  },
  {
    "question": "What is the purpose of eigenvectors in Linear Algebra?",
    "options": [
      "To calculate the determinant of a matrix",
      "To represent directions that remain unchanged under a transformation",
      "To add vectors in the dataset",
      "To encrypt communication between agents"
    ],
    "answer": "To represent directions that remain unchanged under a transformation",
    "explanation": "Eigenvectors represent directions in space that remain unchanged when a matrix transformation is applied, scaled only by their corresponding eigenvalues.",
    "tags": ["Linear Algebra", "Eigenvectors", "Transformations"]
  },
  {
    "question": "Which of the following best describes the role of Linear Algebra in AI?",
    "options": [
      "It provides tools for image compression",
      "It forms the foundation for algorithms like neural networks and PCA",
      "It simplifies database management",
      "It eliminates the need for programming"
    ],
    "answer": "It forms the foundation for algorithms like neural networks and PCA",
    "explanation": "Linear Algebra underpins many AI algorithms, including neural networks, PCA, and reinforcement learning, enabling operations on vectors and matrices in high-dimensional spaces.",
    "tags": ["Linear Algebra", "AI", "Applications"]
  },
  {
    "question": "Which of the following is true about eigenvectors?",
    "options": [
      "They are always orthogonal to each other",
      "They represent directions that remain unchanged under a transformation",
      "They calculate the determinant of a matrix",
      "They replace traditional databases"
    ],
    "answer": "They represent directions that remain unchanged under a transformation",
    "explanation": "Eigenvectors represent specific directions in space that remain unchanged when a matrix transformation is applied, making them crucial for understanding system behavior.",
    "tags": ["Linear Algebra", "Eigenvectors", "Transformations"]
  },
  {
    "question": "What is the primary use of the dot product in Linear Algebra?",
    "options": [
      "To measure angles between vectors",
      "To calculate the determinant of a matrix",
      "To add two matrices together",
      "To perform scalar multiplication"
    ],
    "answer": "To measure angles between vectors",
    "explanation": "The dot product measures the cosine of the angle between two vectors, providing insight into their alignment and similarity.",
    "tags": ["Linear Algebra", "Vectors", "Dot Product"]
  },
  {
    "question": "Which of the following is true about the determinant of a matrix?",
    "options": [
      "It determines the size of the matrix",
      "It indicates whether the matrix is invertible",
      "It calculates the dot product of two vectors",
      "It replaces the need for eigenvalues"
    ],
    "answer": "It indicates whether the matrix is invertible",
    "explanation": "The determinant of a matrix indicates whether it is invertible. A non-zero determinant means the matrix has an inverse, while a zero determinant implies it does not.",
    "tags": ["Linear Algebra", "Matrices", "Determinant"]
  },
  {
    "question": "What is the primary application of eigenvectors in computer graphics?",
    "options": [
      "To compress images",
      "To define transformations like rotations and scaling",
      "To calculate the determinant of matrices",
      "To manage file systems"
    ],
    "answer": "To define transformations like rotations and scaling",
    "explanation": "Eigenvectors are used in computer graphics to define transformations such as rotations, scaling, and projections, ensuring realistic rendering and animation.",
    "tags": ["Linear Algebra", "Eigenvectors", "Computer Graphics"]
  },
  {
    "question": "Which of the following is true about Linear Algebra in AI?",
    "options": [
      "It is irrelevant to modern AI techniques",
      "It underpins algorithms like neural networks and PCA",
      "It focuses exclusively on symbolic reasoning",
      "It eliminates the need for optimization techniques"
    ],
    "answer": "It underpins algorithms like neural networks and PCA",
    "explanation": "Linear Algebra is foundational to AI, powering algorithms like neural networks, PCA, and reinforcement learning by enabling operations on vectors and matrices.",
    "tags": ["Linear Algebra", "AI", "Applications"]
  },
  {
    "question": "What does Agentic AI refer to?",
    "options": [
      "AI systems that require human intervention for decision-making",
      "AI systems capable of autonomous decision-making, problem-solving, and executing tasks dynamically",
      "Traditional rule-based AI systems",
      "AI systems focused solely on natural language processing"
    ],
    "answer": "AI systems capable of autonomous decision-making, problem-solving, and executing tasks dynamically",
    "explanation": "Agentic AI refers to systems that can make decisions, solve problems, and execute tasks autonomously in complex environments.",
    "tags": ["Agentic AI", "Definition", "Autonomy"]
  },
  {
    "question": "Which mathematical concept is essential for understanding neural networks in Phase 1?",
    "options": [
      "Linear Algebra (Vectors, Matrices, Eigenvalues)",
      "Graph Coloring Algorithms",
      "Sorting Algorithms",
      "Basic Arithmetic Operations"
    ],
    "answer": "Linear Algebra (Vectors, Matrices, Eigenvalues)",
    "explanation": "Linear algebra is crucial for understanding the operations within neural networks, such as matrix multiplications and transformations.",
    "tags": ["Phase 1", "Mathematics", "Neural Networks"]
  },
  {
    "question": "Which tool is recommended for deploying machine learning models in Phase 1?",
    "options": ["Docker", "Excel", "Photoshop", "Notepad++"],
    "answer": "Docker",
    "explanation": "Docker is used for containerizing applications, including machine learning models, ensuring they run consistently across different environments.",
    "tags": ["Phase 1", "Deployment", "Docker"]
  },
  {
    "question": "What is the primary goal of Phase 2 in the Agentic AI roadmap?",
    "options": [
      "Building foundational knowledge in AI and ML",
      "Learning reinforcement learning and large language models",
      "Deploying real-world AI systems",
      "Publishing research papers in AI conferences"
    ],
    "answer": "Learning reinforcement learning and large language models",
    "explanation": "Phase 2 focuses on mastering reinforcement learning (RL) and large language models (LLMs), which are critical for decision-making and reasoning in AI agents.",
    "tags": ["Phase 2", "Reinforcement Learning", "LLMs"]
  },
  {
    "question": "Which reinforcement learning algorithm uses a value function to estimate the expected return?",
    "options": [
      "Q-Learning",
      "Random Forest",
      "K-Means Clustering",
      "Gradient Boosting"
    ],
    "answer": "Q-Learning",
    "explanation": "Q-Learning is a reinforcement learning algorithm that estimates the expected return (value function) for actions in a given state.",
    "tags": ["Phase 2", "Reinforcement Learning", "Q-Learning"]
  },
  {
    "question": "What is the purpose of fine-tuning LLMs in Phase 2?",
    "options": [
      "To create entirely new models from scratch",
      "To adapt pre-trained models to specific tasks or domains",
      "To reduce the size of the model",
      "To encrypt communication between AI agents"
    ],
    "answer": "To adapt pre-trained models to specific tasks or domains",
    "explanation": "Fine-tuning LLMs involves adapting pre-trained models to perform better on specific tasks or domains by training them on task-specific data.",
    "tags": ["Phase 2", "LLMs", "Fine-Tuning"]
  },
  {
    "question": "Which concept in Phase 3 involves combining symbolic reasoning with deep learning?",
    "options": [
      "Supervised Learning",
      "Hybrid AI (Neuro-symbolic AI)",
      "Unsupervised Learning",
      "Data Augmentation"
    ],
    "answer": "Hybrid AI (Neuro-symbolic AI)",
    "explanation": "Hybrid AI combines symbolic reasoning (logic-based) with deep learning (data-driven) to enable reasoning and learning in AI agents.",
    "tags": ["Phase 3", "Symbolic AI", "Hybrid AI"]
  },
  {
    "question": "What is the role of Knowledge Graphs in Agentic AI?",
    "options": [
      "To store and represent structured knowledge for reasoning",
      "To generate synthetic images",
      "To manage database connections",
      "To optimize image classification models"
    ],
    "answer": "To store and represent structured knowledge for reasoning",
    "explanation": "Knowledge Graphs are used to store and represent structured knowledge, enabling reasoning and inference in AI systems.",
    "tags": ["Phase 3", "Knowledge Graphs", "Reasoning"]
  },
  {
    "question": "Which technology is essential for scaling AI systems in Phase 4?",
    "options": [
      "Microsoft Word",
      "Distributed AI (Ray, Dask, Kubernetes)",
      "Pen & Paper",
      "Basic Spreadsheets"
    ],
    "answer": "Distributed AI (Ray, Dask, Kubernetes)",
    "explanation": "Distributed AI technologies like Ray, Dask, and Kubernetes are essential for scaling AI systems to handle large datasets and complex computations.",
    "tags": ["Phase 4", "Scalability", "Distributed AI"]
  },
  {
    "question": "What is Sim-to-Real Learning primarily used for in Phase 4?",
    "options": [
      "Training AI agents in simulated environments before deploying them in the real world",
      "Encrypting communication between AI agents",
      "Managing database migrations",
      "Handling API requests"
    ],
    "answer": "Training AI agents in simulated environments before deploying them in the real world",
    "explanation": "Sim-to-Real Learning involves training AI agents in simulated environments to prepare them for real-world deployment, improving their adaptability and performance.",
    "tags": ["Phase 4", "Sim-to-Real Learning", "Robotics"]
  },
  {
    "question": "Which ethical concern is addressed in Phase 4?",
    "options": [
      "Optimizing database queries",
      "Ensuring AI alignment and safety",
      "Designing user interfaces",
      "Managing file systems"
    ],
    "answer": "Ensuring AI alignment and safety",
    "explanation": "Ethical AI concerns like alignment and safety are critical in Phase 4, ensuring AI systems act in alignment with human values and remain robust against adversarial attacks.",
    "tags": ["Phase 4", "Ethical AI", "Alignment"]
  },
  {
    "question": "Which book is recommended for learning reinforcement learning in the Agentic AI roadmap?",
    "options": [
      "The Alignment Problem - Brian Christian",
      "Reinforcement Learning: An Introduction - Richard Sutton",
      "Introduction to Algorithms - Cormen",
      "Clean Code - Robert C. Martin"
    ],
    "answer": "Reinforcement Learning: An Introduction - Richard Sutton",
    "explanation": "Richard Sutton's 'Reinforcement Learning: An Introduction' is a foundational resource for understanding reinforcement learning concepts.",
    "tags": ["Books", "Reinforcement Learning", "Resources"]
  },
  {
    "question": "Which course is recommended for learning deep learning in the Agentic AI roadmap?",
    "options": [
      "MIT 6.S191 (Intro to Deep Learning)",
      "Adobe Photoshop Basics",
      "Database Management Systems",
      "Web Development with React"
    ],
    "answer": "MIT 6.S191 (Intro to Deep Learning)",
    "explanation": "MIT 6.S191 provides an introduction to deep learning, covering neural networks and advanced topics relevant to Agentic AI.",
    "tags": ["Courses", "Deep Learning", "Resources"]
  },
  {
    "question": "What is the primary focus of Phase 5 in the Agentic AI roadmap?",
    "options": [
      "Building foundational knowledge in AI",
      "Mastering reinforcement learning and LLMs",
      "Achieving expert-level mastery through ongoing learning and research",
      "Deploying basic chatbots"
    ],
    "answer": "Achieving expert-level mastery through ongoing learning and research",
    "explanation": "Phase 5 emphasizes continuous learning, contributing to open-source projects, and staying updated with the latest advancements in AI research.",
    "tags": ["Phase 5", "Expert-Level Mastery", "Research"]
  },
  {
    "question": "Which project idea aligns with Phase 2 of the Agentic AI roadmap?",
    "options": [
      "Developing a self-learning chatbot using reinforcement learning",
      "Creating a static website",
      "Designing a logo",
      "Writing a novel"
    ],
    "answer": "Developing a self-learning chatbot using reinforcement learning",
    "explanation": "A self-learning chatbot using reinforcement learning fits Phase 2, where the focus is on decision-making and reasoning with RL and LLMs.",
    "tags": ["Phase 2", "Projects", "Chatbots"]
  },
  {
    "question": "What is the purpose of Memory Augmented Models in Agentic AI?",
    "options": [
      "To reduce the need for memory in AI systems",
      "To enhance AI agents' ability to retain and retrieve information over time",
      "To replace traditional databases",
      "To simplify UI/UX design"
    ],
    "answer": "To enhance AI agents' ability to retain and retrieve information over time",
    "explanation": "Memory Augmented Models, often backed by vector databases like Pinecone or Weaviate, help AI agents retain and retrieve information effectively for long-term reasoning.",
    "tags": ["Phase 3", "Memory Augmented Models", "Long-term Context"]
  },
  {
    "question": "Which conference is recommended for publishing Agentic AI research?",
    "options": [
      "NeurIPS (Conference on Neural Information Processing Systems)",
      "Comic-Con",
      "Mobile World Congress",
      "International Film Festival"
    ],
    "answer": "NeurIPS (Conference on Neural Information Processing Systems)",
    "explanation": "NeurIPS is one of the premier conferences for publishing cutting-edge research in AI, including agentic systems and reinforcement learning.",
    "tags": ["Phase 5", "Conferences", "Research"]
  },
  {
    "question": "What is the main advantage of multi-agent systems in Agentic AI?",
    "options": [
      "They eliminate the need for machine learning",
      "They enable cooperation and competition among multiple AI agents",
      "They simplify single-agent decision-making",
      "They focus exclusively on symbolic AI"
    ],
    "answer": "They enable cooperation and competition among multiple AI agents",
    "explanation": "Multi-agent systems allow AI agents to interact, cooperate, and compete, leading to emergent behaviors and more sophisticated decision-making.",
    "tags": ["Phase 3", "Multi-Agent Systems", "Cooperation"]
  },
  {
    "question": "Which technique is used to improve the robustness of AI models against adversarial attacks?",
    "options": [
      "Adversarial Training",
      "Data Encryption",
      "Image Compression",
      "Manual Testing"
    ],
    "answer": "Adversarial Training",
    "explanation": "Adversarial Training enhances AI models' robustness by exposing them to adversarial examples during training, making them less vulnerable to attacks.",
    "tags": ["Phase 4", "Adversarial Attacks", "Robustness"]
  },
  {
    "question": "What is the role of Vector DBs like Pinecone or Weaviate in Agentic AI?",
    "options": [
      "To store and retrieve embeddings for memory-augmented reasoning",
      "To manage file systems",
      "To encrypt communication between agents",
      "To optimize CSS styles"
    ],
    "answer": "To store and retrieve embeddings for memory-augmented reasoning",
    "explanation": "Vector databases like Pinecone or Weaviate store and retrieve high-dimensional embeddings, enabling memory-augmented reasoning in AI agents.",
    "tags": ["Phase 3", "Vector DBs", "Memory Augmentation"]
  },
  {
    "question": "Which method is commonly used for planning in autonomous AI agents?",
    "options": [
      "A* Search Algorithm",
      "Bubble Sort",
      "Linear Regression",
      "Database Indexing"
    ],
    "answer": "A* Search Algorithm",
    "explanation": "The A* search algorithm is widely used for planning and pathfinding in autonomous AI agents, especially in robotics and navigation systems.",
    "tags": ["Phase 3", "Planning", "Algorithms"]
  },
  {
    "question": "What is the purpose of Red Teaming in AGI safety?",
    "options": [
      "To test and challenge AI systems' robustness and alignment",
      "To design user interfaces",
      "To manage database migrations",
      "To write documentation"
    ],
    "answer": "To test and challenge AI systems' robustness and alignment",
    "explanation": "Red Teaming involves testing and challenging AI systems to identify potential risks and ensure alignment with human values, improving safety and reliability.",
    "tags": ["Phase 5", "AGI Safety", "Red Teaming"]
  },
  {
    "question": "Which of the following is a key characteristic of Agentic AI?",
    "options": [
      "Static behavior without adaptation",
      "Dynamic decision-making and task execution",
      "Focus on image processing only",
      "Limited to symbolic reasoning"
    ],
    "answer": "Dynamic decision-making and task execution",
    "explanation": "Agentic AI is characterized by its ability to make dynamic decisions and execute tasks autonomously in complex environments.",
    "tags": ["Agentic AI", "Characteristics", "Autonomy"]
  },
  {
    "question": "What is the role of Instruction Following in LLMs for Agentic AI?",
    "options": [
      "To enable LLMs to understand and execute user commands",
      "To generate random numbers",
      "To manage file uploads",
      "To encrypt sensitive data"
    ],
    "answer": "To enable LLMs to understand and execute user commands",
    "explanation": "Instruction Following allows LLMs to interpret and execute user-provided instructions, making them more versatile and useful in agentic systems.",
    "tags": ["Phase 2", "LLMs", "Instruction Following"]
  },
  {
    "question": "Which framework is commonly used for simulating multi-agent environments?",
    "options": ["React.js", "Mesa", "TensorFlow.js", "Wordpress"],
    "answer": "Mesa",
    "explanation": "Mesa is a Python framework designed for simulating multi-agent environments, enabling the study of emergent behaviors in multi-agent systems.",
    "tags": ["Phase 3", "Multi-Agent Systems", "Simulation"]
  },
  {
    "question": "What is the significance of AlphaZero in reinforcement learning?",
    "options": [
      "It demonstrates model-based reinforcement learning for game-playing agents",
      "It is a database management system",
      "It simplifies web development",
      "It replaces the need for neural networks"
    ],
    "answer": "It demonstrates model-based reinforcement learning for game-playing agents",
    "explanation": "AlphaZero showcases model-based reinforcement learning, achieving superhuman performance in games like chess and Go through Monte Carlo Tree Search (MCTS).",
    "tags": ["Phase 2", "Reinforcement Learning", "AlphaZero"]
  },
  {
    "question": "What is the primary purpose of GitHub Actions?",
    "options": [
      "To manage containerized applications",
      "To automate CI/CD pipelines for testing, building, and deploying applications",
      "To encrypt communication between services",
      "To handle database migrations"
    ],
    "answer": "To automate CI/CD pipelines for testing, building, and deploying applications",
    "explanation": "GitHub Actions automates continuous integration and deployment (CI/CD) pipelines by running workflows that test, build, and deploy applications whenever specific events occur, such as pushes or pull requests.",
    "tags": ["GitHub Actions", "CI/CD", "Automation"]
  },
  {
    "question": "Which event triggers a GitHub Actions workflow in the example provided?",
    "options": [
      "On every commit to the `main` branch",
      "On every comment in an issue",
      "On manual execution only",
      "On every release creation"
    ],
    "answer": "On every commit to the `main` branch",
    "explanation": "The workflow in the example runs automatically whenever there is a push to the `main` branch, ensuring tests are executed on each update.",
    "tags": ["GitHub Actions", "Triggers", "CI/CD"]
  },
  {
    "question": "What does the `actions/setup-node@v3` step in a GitHub Actions workflow do?",
    "options": [
      "Sets up a Node.js environment for testing",
      "Deploys the application to a server",
      "Configures Kubernetes settings",
      "Manages Docker containers"
    ],
    "answer": "Sets up a Node.js environment for testing",
    "explanation": "The `actions/setup-node@v3` step sets up a Node.js environment with the specified version, allowing you to install dependencies and run tests within the GitHub Actions runner.",
    "tags": ["GitHub Actions", "Node.js", "Setup"]
  },
  {
    "question": "What is the main advantage of using Docker in application development?",
    "options": [
      "It eliminates the need for databases",
      "It packages applications into lightweight, isolated environments",
      "It manages frontend state",
      "It replaces traditional APIs"
    ],
    "answer": "It packages applications into lightweight, isolated environments",
    "explanation": "Docker creates lightweight, isolated environments called containers, ensuring that applications run consistently across different machines and environments.",
    "tags": ["Docker", "Containerization", "Isolation"]
  },
  {
    "question": "Which command builds a Docker image for your application?",
    "options": [
      "docker run -t my-app .",
      "docker build -t my-app .",
      "docker push my-app",
      "kubectl apply -f deployment.yaml"
    ],
    "answer": "docker build -t my-app .",
    "explanation": "The `docker build -t my-app .` command builds a Docker image for your application, tagging it with the name `my-app` for easy reference.",
    "tags": ["Docker", "Build", "Commands"]
  },
  {
    "question": "What is the role of the `WORKDIR` instruction in a Dockerfile?",
    "options": [
      "Defines the working directory inside the container",
      "Installs application dependencies",
      "Starts the application server",
      "Configures Kubernetes settings"
    ],
    "answer": "Defines the working directory inside the container",
    "explanation": "The `WORKDIR` instruction in a Dockerfile sets the working directory inside the container where subsequent commands will execute.",
    "tags": ["Docker", "Dockerfile", "WORKDIR"]
  },
  {
    "question": "What is Kubernetes primarily used for?",
    "options": [
      "Automating frontend development",
      "Managing multiple Docker containers in production",
      "Encrypting sensitive data",
      "Handling API requests"
    ],
    "answer": "Managing multiple Docker containers in production",
    "explanation": "Kubernetes is a container orchestration platform that automates the deployment, scaling, and management of containerized applications, making it ideal for managing multi-container apps in production.",
    "tags": ["Kubernetes", "Orchestration", "Containers"]
  },
  {
    "question": "Which Kubernetes object ensures that a specified number of pod replicas are running at all times?",
    "options": ["Service", "Deployment", "Pod", "ConfigMap"],
    "answer": "Deployment",
    "explanation": "A Kubernetes Deployment ensures that a specified number of pod replicas are running at all times, providing scalability and fault tolerance for containerized applications.",
    "tags": ["Kubernetes", "Deployment", "Scalability"]
  },
  {
    "question": "What does the `containerPort` field in a Kubernetes Deployment YAML file specify?",
    "options": [
      "The port exposed by the container",
      "The port used by the host machine",
      "The number of containers to deploy",
      "The type of service being deployed"
    ],
    "answer": "The port exposed by the container",
    "explanation": "The `containerPort` field in a Kubernetes Deployment specifies the port that the container exposes, enabling communication between the container and external systems.",
    "tags": ["Kubernetes", "Deployment", "Ports"]
  },
  {
    "question": "Which command applies a Kubernetes configuration file?",
    "options": ["docker build", "kubectl apply", "npm test", "git push"],
    "answer": "kubectl apply",
    "explanation": "The `kubectl apply` command applies a Kubernetes configuration file (e.g., `deployment.yaml`, `service.yaml`) to create or update resources like Deployments and Services.",
    "tags": ["Kubernetes", "kubectl", "Configuration"]
  },
  {
    "question": "What is the purpose of the `LoadBalancer` type in a Kubernetes Service?",
    "options": [
      "To expose the service externally via a cloud load balancer",
      "To define a local testing environment",
      "To manage database connections",
      "To replace Docker containers"
    ],
    "answer": "To expose the service externally via a cloud load balancer",
    "explanation": "The `LoadBalancer` type in a Kubernetes Service exposes the service externally through a cloud provider's load balancer, enabling access from outside the cluster.",
    "tags": ["Kubernetes", "Service", "Load Balancing"]
  },
  {
    "question": "Which of the following best describes the difference between Docker and Kubernetes?",
    "options": [
      "Docker handles containerization, while Kubernetes manages multiple containers in production",
      "Docker manages CI/CD pipelines, while Kubernetes handles frontend development",
      "There is no difference; both serve the same purpose",
      "Kubernetes eliminates the need for Docker"
    ],
    "answer": "Docker handles containerization, while Kubernetes manages multiple containers in production",
    "explanation": "Docker focuses on containerizing applications, while Kubernetes orchestrates and manages multiple containers in production, handling scaling, load balancing, and fault tolerance.",
    "tags": ["Docker", "Kubernetes", "Comparison"]
  },
  {
    "question": "What is the role of the `CMD` instruction in a Dockerfile?",
    "options": [
      "Defines the default command to run when the container starts",
      "Installs application dependencies",
      "Configures environment variables",
      "Manages Kubernetes deployments"
    ],
    "answer": "Defines the default command to run when the container starts",
    "explanation": "The `CMD` instruction in a Dockerfile specifies the default command to execute when the container starts, typically starting the application server.",
    "tags": ["Docker", "Dockerfile", "CMD"]
  },
  {
    "question": "Which GitHub Actions step checks out the code repository during a workflow?",
    "options": [
      "actions/test-code@v1",
      "actions/deploy@v2",
      "actions/checkout@v3",
      "actions/containerize@v4"
    ],
    "answer": "actions/checkout@v3",
    "explanation": "The `actions/checkout@v3` step in a GitHub Actions workflow checks out the code repository so that subsequent steps can access and work with the code.",
    "tags": ["GitHub Actions", "Checkout", "Workflows"]
  },
  {
    "question": "What is the purpose of the `selector` field in a Kubernetes Deployment?",
    "options": [
      "Specifies which pods the Deployment manages",
      "Defines the application's environment variables",
      "Configures the container's exposed ports",
      "Handles API requests"
    ],
    "answer": "Specifies which pods the Deployment manages",
    "explanation": "The `selector` field in a Kubernetes Deployment defines the labels used to identify and manage the pods associated with the Deployment.",
    "tags": ["Kubernetes", "Deployment", "Selectors"]
  },
  {
    "question": "Which of the following is true about Docker's `EXPOSE` instruction?",
    "options": [
      "It exposes the container's port to the host machine",
      "It informs Docker which port the application listens on inside the container",
      "It replaces the need for a Kubernetes Service",
      "It configures environment variables"
    ],
    "answer": "It informs Docker which port the application listens on inside the container",
    "explanation": "The `EXPOSE` instruction in a Dockerfile informs Docker which port the application listens on inside the container but does not expose it to the host machine directly.",
    "tags": ["Docker", "Dockerfile", "EXPOSE"]
  },
  {
    "question": "What is the role of the `service.yaml` file in Kubernetes?",
    "options": [
      "Defines how to package the application into a container",
      "Specifies how to expose the application to external traffic",
      "Manages CI/CD pipelines",
      "Handles database migrations"
    ],
    "answer": "Specifies how to expose the application to external traffic",
    "explanation": "The `service.yaml` file in Kubernetes defines how to expose the application to external traffic, often using types like `LoadBalancer` or `ClusterIP`.",
    "tags": ["Kubernetes", "Service", "Exposure"]
  },
  {
    "question": "Which of the following best describes the relationship between GitHub Actions, Docker, and Kubernetes?",
    "options": [
      "GitHub Actions builds Docker images, and Kubernetes deploys them in production",
      "Docker manages CI/CD pipelines, while Kubernetes handles testing",
      "GitHub Actions replaces the need for Docker and Kubernetes",
      "Kubernetes automates GitHub Actions workflows"
    ],
    "answer": "GitHub Actions builds Docker images, and Kubernetes deploys them in production",
    "explanation": "GitHub Actions automates tasks like building Docker images during CI/CD pipelines, while Kubernetes manages the deployment and scaling of these containers in production.",
    "tags": ["GitHub Actions", "Docker", "Kubernetes", "Relationship"]
  },
  {
    "question": "What is the purpose of the `replicas` field in a Kubernetes Deployment?",
    "options": [
      "Defines the number of copies of the pod to run",
      "Specifies the application's exposed port",
      "Configures environment variables",
      "Handles database connections"
    ],
    "answer": "Defines the number of copies of the pod to run",
    "explanation": "The `replicas` field in a Kubernetes Deployment specifies the desired number of pod replicas to run, ensuring high availability and scalability.",
    "tags": ["Kubernetes", "Deployment", "Replicas"]
  },
  {
    "question": "Which command runs a built Docker image locally?",
    "options": [
      "docker push my-app",
      "docker run -p 3000:3000 my-app",
      "kubectl apply -f deployment.yaml",
      "npx jest"
    ],
    "answer": "docker run -p 3000:3000 my-app",
    "explanation": "The `docker run -p 3000:3000 my-app` command runs a built Docker image locally, mapping port 3000 inside the container to port 3000 on the host machine.",
    "tags": ["Docker", "Run", "Commands"]
  },
  {
    "question": "What is the main advantage of using Kubernetes over Docker alone?",
    "options": [
      "Kubernetes eliminates the need for containers",
      "Kubernetes provides automated scaling and management of multiple containers",
      "Docker cannot handle CI/CD pipelines",
      "Kubernetes simplifies frontend development"
    ],
    "answer": "Kubernetes provides automated scaling and management of multiple containers",
    "explanation": "While Docker handles containerization, Kubernetes automates the scaling, deployment, and management of multiple containers, making it ideal for large-scale applications.",
    "tags": ["Kubernetes", "Docker", "Comparison"]
  },
  {
    "question": "Which of the following is true about GitHub Actions' `on` keyword?",
    "options": [
      "It specifies the operating system for the workflow",
      "It defines the events that trigger the workflow",
      "It manages Docker containers",
      "It replaces the need for Kubernetes"
    ],
    "answer": "It defines the events that trigger the workflow",
    "explanation": "The `on` keyword in GitHub Actions specifies the events (e.g., `push`, `pull_request`) that trigger the workflow, enabling automation based on repository activity.",
    "tags": ["GitHub Actions", "Triggers", "Workflow Configuration"]
  },
  {
    "question": "What does the `kubectl apply -f deployment.yaml` command do?",
    "options": [
      "Checks out code from the repository",
      "Applies a Kubernetes configuration file to create or update resources",
      "Runs unit tests for the application",
      "Builds a Docker image"
    ],
    "answer": "Applies a Kubernetes configuration file to create or update resources",
    "explanation": "The `kubectl apply -f deployment.yaml` command applies a Kubernetes configuration file, creating or updating resources like Deployments and Services.",
    "tags": ["Kubernetes", "kubectl", "Configuration"]
  },
  {
    "question": "Which of the following is a benefit of using Docker in conjunction with Kubernetes?",
    "options": [
      "Docker eliminates the need for Kubernetes",
      "Kubernetes simplifies container creation",
      "Docker packages applications, and Kubernetes manages their deployment and scaling",
      "Kubernetes replaces traditional APIs"
    ],
    "answer": "Docker packages applications, and Kubernetes manages their deployment and scaling",
    "explanation": "Docker packages applications into containers, while Kubernetes orchestrates and manages their deployment, scaling, and availability in production environments.",
    "tags": ["Docker", "Kubernetes", "Integration"]
  },
  {
    "question": "What is the primary purpose of unit testing in software development?",
    "options": [
      "To test the entire application flow",
      "To ensure individual functions or components work as expected",
      "To simulate real-world user interactions",
      "To manage database connections"
    ],
    "answer": "To ensure individual functions or components work as expected",
    "explanation": "Unit testing focuses on verifying that small, isolated units of code (like functions or methods) behave correctly under various conditions.",
    "tags": ["Testing", "Jest", "Unit Testing"]
  },
  {
    "question": "Which library is commonly used for testing HTTP APIs in Node.js?",
    "options": ["Jest", "Supertest", "Mocha", "Chai"],
    "answer": "Supertest",
    "explanation": "Supertest is a popular library for testing HTTP servers and APIs, making it ideal for integration testing in Node.js applications.",
    "tags": ["Supertest", "HTTP API Testing", "Integration Testing"]
  },
  {
    "question": "What does the `expect()` function in Jest do?",
    "options": [
      "Logs debug information during tests",
      "Asserts that a condition or value matches expectations",
      "Sends HTTP requests to an API",
      "Manages database connections"
    ],
    "answer": "Asserts that a condition or value matches expectations",
    "explanation": "The `expect()` function in Jest is used to make assertions about the output or behavior of the code being tested, ensuring it meets the expected criteria.",
    "tags": ["Jest", "Assertions", "Testing"]
  },
  {
    "question": "Which method is used to define a test case in Jest?",
    "options": ["test()", "describe()", "it()", "jest.fn()"],
    "answer": "test()",
    "explanation": "In Jest, the `test()` method (or its alias `it()`) is used to define individual test cases, specifying the behavior to be tested.",
    "tags": ["Jest", "Test Case Definition", "Syntax"]
  },
  {
    "question": "What is the role of Supertest in integration testing?",
    "options": [
      "To mock database queries",
      "To send HTTP requests and validate responses",
      "To generate test coverage reports",
      "To handle file uploads"
    ],
    "answer": "To send HTTP requests and validate responses",
    "explanation": "Supertest allows you to send HTTP requests to your server and validate the responses, making it perfect for integration testing of APIs and HTTP-based services.",
    "tags": ["Supertest", "Integration Testing", "HTTP Requests"]
  },
  {
    "question": "Which of the following is true about Jest's `.toBe()` matcher?",
    "options": [
      "It checks if two values are strictly equal",
      "It validates the length of an array",
      "It sends HTTP requests to an API",
      "It generates random test data"
    ],
    "answer": "It checks if two values are strictly equal",
    "explanation": "The `.toBe()` matcher in Jest checks if two values are strictly equal using the `===` operator, ensuring precise comparisons during testing.",
    "tags": ["Jest", "Matchers", "toBe"]
  },
  {
    "question": "How do you test an Express route that returns JSON data using Supertest?",
    "options": [
      "Using `request(app).get().send()`",
      "Using `request(app).post().json()`",
      "Using `request(app).get().expect()`",
      "Using `jest.fn()`"
    ],
    "answer": "Using `request(app).get().expect()`",
    "explanation": "With Supertest, you can use `request(app).get().expect()` to test an Express route that returns JSON data, asserting the response status and content.",
    "tags": ["Supertest", "Express", "Integration Testing"]
  },
  {
    "question": "Which Jest method is used to group multiple related test cases?",
    "options": ["test()", "describe()", "expect()", "jest.fn()"],
    "answer": "describe()",
    "explanation": "The `describe()` method in Jest groups multiple related test cases together, improving test organization and readability.",
    "tags": ["Jest", "Test Organization", "describe"]
  },
  {
    "question": "What does the `jest.fn()` function do in Jest?",
    "options": [
      "Creates a mock function for testing",
      "Defines a new test case",
      "Sends HTTP requests to an API",
      "Validates JSON responses"
    ],
    "answer": "Creates a mock function for testing",
    "explanation": "`jest.fn()` creates a mock function in Jest, allowing you to track calls, arguments, and return values during testing.",
    "tags": ["Jest", "Mock Functions", "jest.fn"]
  },
  {
    "question": "Which of the following best describes the difference between unit testing and integration testing?",
    "options": [
      "Unit testing focuses on individual components, while integration testing verifies interactions between multiple components",
      "Unit testing requires external libraries, while integration testing does not",
      "Unit testing tests only frontend code, while integration testing tests backend code",
      "There is no difference; both serve the same purpose"
    ],
    "answer": "Unit testing focuses on individual components, while integration testing verifies interactions between multiple components",
    "explanation": "Unit testing isolates and tests individual components, whereas integration testing ensures that multiple components work together as expected.",
    "tags": ["Testing", "Unit Testing", "Integration Testing", "Comparison"]
  },
  {
    "question": "What is the purpose of the `.expect(200)` method in Supertest?",
    "options": [
      "To send a POST request with data",
      "To assert that the HTTP response status is 200",
      "To mock database queries",
      "To generate test coverage reports"
    ],
    "answer": "To assert that the HTTP response status is 200",
    "explanation": "The `.expect(200)` method in Supertest asserts that the HTTP response status code is 200 (OK), ensuring the API behaves as expected.",
    "tags": ["Supertest", "HTTP Status Codes", "Assertions"]
  },
  {
    "question": "Which Jest matcher is used to compare objects or arrays deeply?",
    "options": [".toEqual()", ".toBe()", ". expect()", ".mock()"],
    "answer": ".toEqual()",
    "explanation": "The `.toEqual()` matcher in Jest performs a deep comparison of objects or arrays, ensuring all nested properties match the expected value.",
    "tags": ["Jest", "Matchers", "toEqual"]
  },
  {
    "question": "How do you send JSON data in a POST request using Supertest?",
    "options": [
      "Using `request(app).post().send()`",
      "Using `request(app).get().json()`",
      "Using `jest.fn()`",
      "Using `describe()`"
    ],
    "answer": "Using `request(app).post().send()`",
    "explanation": "With Supertest, you can send JSON data in a POST request using `request(app).post().send(data)`, where `data` is the JSON payload to be sent.",
    "tags": ["Supertest", "POST Requests", "JSON Data"]
  },
  {
    "question": "Which of the following is true about mocking in Jest?",
    "options": [
      "Mocking replaces actual implementations with controlled substitutes for testing",
      "Mocking is only used for database connections",
      "Mocking eliminates the need for integration tests",
      "Mocking increases the size of test payloads"
    ],
    "answer": "Mocking replaces actual implementations with controlled substitutes for testing",
    "explanation": "Mocking in Jest allows you to replace actual implementations (e.g., functions, modules) with controlled substitutes, isolating the code being tested.",
    "tags": ["Jest", "Mocking", "Substitutions"]
  },
  {
    "question": "What is the purpose of the `beforeEach()` function in Jest?",
    "options": [
      "To run setup code before each test case",
      "To define environment variables",
      "To send HTTP requests",
      "To generate test coverage reports"
    ],
    "answer": "To run setup code before each test case",
    "explanation": "The `beforeEach()` function in Jest runs setup code before each test case, ensuring a clean state or initializing required dependencies.",
    "tags": ["Jest", "Test Lifecycle", "beforeEach"]
  },
  {
    "question": "Which method is used to validate the body of an HTTP response in Supertest?",
    "options": [
      "res.body.toEqual()",
      "expect(res.body).toEqual()",
      "request(app).get().body()",
      "jest.fn()"
    ],
    "answer": "expect(res.body).toEqual()",
    "explanation": "In Supertest, you can use `expect(res.body).toEqual()` to validate the body of an HTTP response, ensuring it matches the expected structure or data.",
    "tags": ["Supertest", "Response Validation", "Assertions"]
  },
  {
    "question": "What is the main advantage of using Supertest over Jest alone for API testing?",
    "options": [
      "Supertest allows testing HTTP APIs by sending requests and validating responses",
      "Supertest simplifies unit testing of individual functions",
      "Supertest eliminates the need for a test runner",
      "Supertest manages database connections automatically"
    ],
    "answer": "Supertest allows testing HTTP APIs by sending requests and validating responses",
    "explanation": "Supertest is specifically designed for testing HTTP APIs, enabling you to send requests and validate responses, which Jest alone cannot do.",
    "tags": ["Supertest", "API Testing", "Advantages"]
  },
  {
    "question": "Which of the following is true about integration testing?",
    "options": [
      "It tests individual functions in isolation",
      "It verifies interactions between multiple components or services",
      "It replaces the need for unit testing",
      "It focuses solely on frontend UI elements"
    ],
    "answer": "It verifies interactions between multiple components or services",
    "explanation": "Integration testing ensures that multiple components or services work together as expected, unlike unit testing, which focuses on isolated components.",
    "tags": ["Integration Testing", "Component Interactions", "Verification"]
  },
  {
    "question": "What is the purpose of the `.mockImplementation()` method in Jest?",
    "options": [
      "To define the implementation of a mock function",
      "To send HTTP requests to an API",
      "To validate JSON responses",
      "To configure CORS policies"
    ],
    "answer": "To define the implementation of a mock function",
    "explanation": "The `.mockImplementation()` method in Jest allows you to define the behavior of a mock function, replacing its original implementation for testing purposes.",
    "tags": ["Jest", "Mock Functions", "mockImplementation"]
  },
  {
    "question": "Which command is used to run Jest tests?",
    "options": ["npm test", "npx jest", "node test.js", "supertest run"],
    "answer": "npx jest",
    "explanation": "The `npx jest` command runs Jest tests, executing all test files and reporting their results.",
    "tags": ["Jest", "Test Execution", "Commands"]
  },
  {
    "question": "What does the `.send()` method in Supertest do?",
    "options": [
      "Sends HTTP requests with a JSON payload",
      "Mocks database queries",
      "Generates random test data",
      "Configures middleware"
    ],
    "answer": "Sends HTTP requests with a JSON payload",
    "explanation": "The `.send()` method in Supertest is used to send HTTP requests with a JSON payload, typically for testing POST or PUT endpoints.",
    "tags": ["Supertest", "HTTP Requests", "send Method"]
  },
  {
    "question": "Which of the following is true about Jest's snapshot testing?",
    "options": [
      "It compares the current output of a function with a previously saved snapshot",
      "It eliminates the need for assertions",
      "It focuses solely on testing database queries",
      "It replaces the need for Supertest"
    ],
    "answer": "It compares the current output of a function with a previously saved snapshot",
    "explanation": "Jest's snapshot testing captures the output of a function or component and compares it with a previously saved snapshot, ensuring consistency across test runs.",
    "tags": ["Jest", "Snapshot Testing", "Consistency"]
  },
  {
    "question": "How do you test a route that expects query parameters using Supertest?",
    "options": [
      "Using `request(app).get('/route').query({ param: 'value' })`",
      "Using `request(app).post('/route').send({ param: 'value' })`",
      "Using `jest.fn()`",
      "Using `describe()`"
    ],
    "answer": "Using `request(app).get('/route').query({ param: 'value' })`",
    "explanation": "With Supertest, you can test routes expecting query parameters using `request(app).get('/route').query({ param: 'value' })`, appending query parameters to the request.",
    "tags": ["Supertest", "Query Parameters", "GET Requests"]
  },
  {
    "question": "Which Jest matcher is used to check if an object contains specific properties?",
    "options": [".toContain()", ".toInclude()", ".toHaveProperty()", ".toBe()"],
    "answer": ".toHaveProperty()",
    "explanation": "The `.toHaveProperty()` matcher in Jest checks if an object contains specific properties, making it useful for testing complex JSON responses.",
    "tags": ["Jest", "Matchers", "toHaveProperty"]
  },
  {
    "question": "What is the purpose of the `.mockResolvedValue()` method in Jest?",
    "options": [
      "To define the resolved value of a mocked asynchronous function",
      "To send HTTP requests",
      "To validate JSON responses",
      "To configure middleware"
    ],
    "answer": "To define the resolved value of a mocked asynchronous function",
    "explanation": "The `.mockResolvedValue()` method in Jest defines the resolved value of a mocked asynchronous function, such as Promises, for testing purposes.",
    "tags": ["Jest", "Mock Functions", "Asynchronous Testing"]
  },
  {
    "question": "Which of the following best describes the difference between Jest and Supertest?",
    "options": [
      "Jest is used for HTTP API testing, while Supertest is for unit testing",
      "Jest provides a test runner and assertion library, while Supertest focuses on testing HTTP APIs",
      "There is no difference; both serve the same purpose",
      "Supertest manages database connections, while Jest does not"
    ],
    "answer": "Jest provides a test runner and assertion library, while Supertest focuses on testing HTTP APIs",
    "explanation": "Jest serves as a comprehensive testing framework, providing a test runner and assertion library, while Supertest specializes in testing HTTP APIs by simulating requests and validating responses.",
    "tags": ["Jest", "Supertest", "Comparison"]
  },
  {
    "question": "What is the primary purpose of gRPC in microservices architectures?",
    "options": [
      "To encrypt communication between services",
      "To enable high-performance, efficient communication between services",
      "To replace traditional databases",
      "To manage frontend state"
    ],
    "answer": "To enable high-performance, efficient communication between services",
    "explanation": "gRPC is designed for efficient and low-latency communication between services, making it ideal for microservices architectures where performance and scalability are critical.",
    "tags": ["gRPC", "Microservices", "Performance"]
  },
  {
    "question": "Which data format does gRPC use for serialization?",
    "options": ["JSON", "XML", "Protocol Buffers (Protobuf)", "YAML"],
    "answer": "Protocol Buffers (Protobuf)",
    "explanation": "gRPC uses Protocol Buffers (Protobuf), a compact binary format, for serialization, which reduces payload sizes and improves performance compared to JSON or XML.",
    "tags": ["gRPC", "Serialization", "Protobuf"]
  },
  {
    "question": "What is the role of the `.proto` file in gRPC?",
    "options": [
      "To store database configurations",
      "To define service methods and message structures",
      "To manage environment variables",
      "To handle client-side routing"
    ],
    "answer": "To define service methods and message structures",
    "explanation": "The `.proto` file in gRPC defines the service methods and message structures using Protocol Buffers, serving as the contract between client and server.",
    "tags": ["gRPC", "Proto File", "Service Definition"]
  },
  {
    "question": "Which type of RPC allows the server to send multiple responses to the client in gRPC?",
    "options": [
      "Unary RPC",
      "Server Streaming RPC",
      "Client Streaming RPC",
      "Bidirectional Streaming RPC"
    ],
    "answer": "Server Streaming RPC",
    "explanation": "Server Streaming RPC enables the server to send multiple responses to the client over time, such as streaming user data or real-time updates.",
    "tags": ["gRPC", "Streaming", "Server Streaming"]
  },
  {
    "question": "What is the default protocol used by gRPC for communication?",
    "options": ["HTTP/1.1", "HTTP/2", "WebSocket", "TCP"],
    "answer": "HTTP/2",
    "explanation": "gRPC uses HTTP/2 as its underlying protocol, enabling features like multiplexing, header compression, and reduced latency for better performance.",
    "tags": ["gRPC", "HTTP/2", "Protocol"]
  },
  {
    "question": "Which library is required to load Protobuf files in Node.js for gRPC?",
    "options": [
      "express-graphql",
      "@grpc/proto-loader",
      "apollo-server",
      "nexus"
    ],
    "answer": "@grpc/proto-loader",
    "explanation": "The `@grpc/proto-loader` library is used to load and parse `.proto` files in Node.js, allowing you to define gRPC services and messages programmatically.",
    "tags": ["gRPC", "Node.js", "Proto Loader"]
  },
  {
    "question": "What does the `Unary RPC` method in gRPC do?",
    "options": [
      "Sends multiple requests from the client to the server",
      "Sends a single request and receives a single response",
      "Streams data bidirectionally between client and server",
      "Encrypts communication between services"
    ],
    "answer": "Sends a single request and receives a single response",
    "explanation": "A `Unary RPC` method sends a single request from the client to the server and receives a single response, similar to traditional RESTful APIs.",
    "tags": ["gRPC", "Unary RPC", "Communication"]
  },
  {
    "question": "Which command starts a gRPC server in Node.js?",
    "options": [
      "server.listen()",
      "server.start()",
      "server.bindAsync()",
      "server.run()"
    ],
    "answer": "server.bindAsync()",
    "explanation": "In gRPC, the `server.bindAsync()` method binds the server to a specific address and port, starting the service after binding.",
    "tags": ["gRPC", "Node.js", "Server Setup"]
  },
  {
    "question": "What is the advantage of using `Bidirectional Streaming RPC` in gRPC?",
    "options": [
      "It allows only the server to send multiple responses",
      "It enables both client and server to send streams of messages asynchronously",
      "It eliminates the need for a schema",
      "It simplifies frontend development"
    ],
    "answer": "It enables both client and server to send streams of messages asynchronously",
    "explanation": "Bidirectional Streaming RPC in gRPC allows both the client and server to send streams of messages asynchronously, making it ideal for real-time applications.",
    "tags": ["gRPC", "Bidirectional Streaming", "Real-Time Communication"]
  },
  {
    "question": "Which of the following is true about gRPC's cross-platform compatibility?",
    "options": [
      "gRPC supports only Node.js and Python",
      "gRPC works with multiple programming languages like Go, Java, C++, Rust, etc.",
      "gRPC requires Docker for cross-platform support",
      "gRPC is limited to frontend frameworks"
    ],
    "answer": "gRPC works with multiple programming languages like Go, Java, C++, Rust, etc.",
    "explanation": "gRPC is highly versatile and supports multiple programming languages, including Go, Java, C++, Rust, and more, ensuring seamless integration across platforms.",
    "tags": ["gRPC", "Cross-Platform", "Language Support"]
  },
  {
    "question": "What is the purpose of the `Empty` message in Protobuf?",
    "options": [
      "To store large datasets",
      "To represent a request or response with no fields",
      "To encrypt sensitive data",
      "To configure CORS policies"
    ],
    "answer": "To represent a request or response with no fields",
    "explanation": "The `Empty` message in Protobuf is used to represent a request or response that contains no fields, often useful for methods like health checks or broadcasting data.",
    "tags": ["gRPC", "Protobuf", "Empty Message"]
  },
  {
    "question": "How do you handle errors in gRPC when a requested resource is not found?",
    "options": [
      "By returning an empty response",
      "By throwing a generic JavaScript error",
      "By using `grpc.status.NOT_FOUND` with a detailed error message",
      "By restarting the server automatically"
    ],
    "answer": "By using `grpc.status.NOT_FOUND` with a detailed error message",
    "explanation": "In gRPC, you can handle errors like 'resource not found' by returning a status code (`grpc.status.NOT_FOUND`) along with a detailed error message.",
    "tags": ["gRPC", "Error Handling", "Status Codes"]
  },
  {
    "question": "Which feature ensures secure communication in gRPC?",
    "options": [
      "Built-in TLS encryption",
      "Manual configuration of HTTPS",
      "Use of WebSocket protocols",
      "Automatic generation of API keys"
    ],
    "answer": "Built-in TLS encryption",
    "explanation": "gRPC supports built-in TLS encryption for secure communication between client and server, ensuring data privacy and integrity.",
    "tags": ["gRPC", "Security", "TLS Encryption"]
  },
  {
    "question": "What is the main benefit of using gRPC over REST for microservices communication?",
    "options": [
      "gRPC supports only text-based data formats",
      "gRPC offers higher performance due to binary serialization and HTTP/2",
      "gRPC eliminates the need for a schema",
      "gRPC simplifies frontend development"
    ],
    "answer": "gRPC offers higher performance due to binary serialization and HTTP/2",
    "explanation": "gRPC provides superior performance compared to REST by leveraging Protocol Buffers for efficient serialization and HTTP/2 for faster, multiplexed communication.",
    "tags": ["gRPC", "REST", "Comparison", "Performance"]
  },
  {
    "question": "Which method is used to implement a server-side streaming RPC in gRPC?",
    "options": [
      "rpc GetUser",
      "rpc StreamUsers",
      "rpc BidirectionalStream",
      "rpc ClientStream"
    ],
    "answer": "rpc StreamUsers",
    "explanation": "A server-side streaming RPC (e.g., `rpc StreamUsers`) allows the server to send multiple responses to the client over time, improving efficiency for large datasets.",
    "tags": ["gRPC", "Streaming", "Server Streaming"]
  },
  {
    "question": "What is the role of `call.write()` in gRPC server-side streaming?",
    "options": [
      "To terminate the stream",
      "To send individual messages to the client",
      "To validate user input",
      "To configure CORS headers"
    ],
    "answer": "To send individual messages to the client",
    "explanation": "In server-side streaming, the `call.write()` method is used to send individual messages to the client, while `call.end()` terminates the stream.",
    "tags": ["gRPC", "Server Streaming", "Call Write"]
  },
  {
    "question": "Which event is triggered on the client side when receiving data from a gRPC streaming RPC?",
    "options": ["data", "end", "error", "connect"],
    "answer": "data",
    "explanation": "On the client side, the `data` event is triggered whenever a new message is received from the server during a gRPC streaming RPC.",
    "tags": ["gRPC", "Client Streaming", "Data Event"]
  },
  {
    "question": "What is the purpose of `grpc.ServerCredentials.createInsecure()` in a gRPC server setup?",
    "options": [
      "To enable secure communication using TLS",
      "To disable authentication entirely",
      "To create a server without encryption for testing purposes",
      "To configure rate limiting"
    ],
    "answer": "To create a server without encryption for testing purposes",
    "explanation": "`grpc.ServerCredentials.createInsecure()` creates a gRPC server without encryption, typically used for local development or testing environments.",
    "tags": ["gRPC", "Server Setup", "Insecure Credentials"]
  },
  {
    "question": "Which of the following best describes the difference between Unary RPC and Streaming RPC in gRPC?",
    "options": [
      "Unary RPC sends multiple requests, while Streaming RPC sends a single request",
      "Unary RPC sends a single request and response, while Streaming RPC allows sending multiple messages over time",
      "Unary RPC uses JSON, while Streaming RPC uses Protobuf",
      "There is no difference; both serve the same purpose"
    ],
    "answer": "Unary RPC sends a single request and response, while Streaming RPC allows sending multiple messages over time",
    "explanation": "A Unary RPC sends a single request and receives a single response, whereas Streaming RPC allows sending multiple messages asynchronously over time.",
    "tags": ["gRPC", "RPC Types", "Comparison"]
  },
  {
    "question": "Which of the following is true about gRPC's use of HTTP/2?",
    "options": [
      "HTTP/2 increases the size of payloads",
      "HTTP/2 enables multiplexing, reducing latency for multiple requests",
      "HTTP/2 is only supported in production environments",
      "HTTP/2 eliminates the need for Protobuf"
    ],
    "answer": "HTTP/2 enables multiplexing, reducing latency for multiple requests",
    "explanation": "gRPC leverages HTTP/2's multiplexing feature, allowing multiple requests and responses to be processed concurrently, reducing latency and improving performance.",
    "tags": ["gRPC", "HTTP/2", "Multiplexing"]
  },
  {
    "question": "What is the role of `call.end()` in server-side streaming RPCs?",
    "options": [
      "To send the first message to the client",
      "To terminate the stream after all messages have been sent",
      "To validate user input",
      "To configure middleware"
    ],
    "answer": "To terminate the stream after all messages have been sent",
    "explanation": "In server-side streaming, `call.end()` is used to terminate the stream once all messages have been sent to the client.",
    "tags": ["gRPC", "Server Streaming", "Call End"]
  },
  {
    "question": "Which of the following is a common use case for gRPC in microservices?",
    "options": [
      "Frontend web application development",
      "High-performance communication between backend services",
      "Static website hosting",
      "Image processing"
    ],
    "answer": "High-performance communication between backend services",
    "explanation": "gRPC is widely used for high-performance communication between backend microservices due to its binary serialization, HTTP/2 support, and low latency.",
    "tags": ["gRPC", "Microservices", "Use Cases"]
  },
  {
    "question": "What is the purpose of the `@grpc/grpc-js` package in Node.js?",
    "options": [
      "To manage database connections",
      "To implement gRPC servers and clients in Node.js",
      "To generate random session IDs",
      "To optimize image loading"
    ],
    "answer": "To implement gRPC servers and clients in Node.js",
    "explanation": "The `@grpc/grpc-js` package provides tools for implementing gRPC servers and clients in Node.js, enabling efficient inter-service communication.",
    "tags": ["gRPC", "Node.js", "Package"]
  },
  {
    "question": "Which of the following is true about gRPC's multi-language support?",
    "options": [
      "gRPC supports only Node.js and Python",
      "gRPC supports multiple languages like Go, Java, C++, Rust, etc.",
      "gRPC requires Docker for multi-language support",
      "gRPC eliminates the need for language-specific libraries"
    ],
    "answer": "gRPC supports multiple languages like Go, Java, C++, Rust, etc.",
    "explanation": "gRPC is designed to work across multiple programming languages, including Go, Java, C++, Rust, and others, promoting interoperability in diverse systems.",
    "tags": ["gRPC", "Multi-Language", "Support"]
  },
  {
    "question": "What is the role of `stream.on('data', callback)` in a gRPC client?",
    "options": [
      "To send a single request to the server",
      "To listen for individual messages in a streaming RPC",
      "To validate user input",
      "To configure middleware"
    ],
    "answer": "To listen for individual messages in a streaming RPC",
    "explanation": "In a gRPC client, `stream.on('data', callback)` listens for individual messages received from the server during a streaming RPC.",
    "tags": ["gRPC", "Client Streaming", "Event Handling"]
  },
  {
    "question": "Which of the following is a benefit of using Protobuf over JSON in gRPC?",
    "options": [
      "Protobuf increases payload size",
      "Protobuf reduces payload size and improves serialization speed",
      "Protobuf eliminates the need for a schema",
      "Protobuf simplifies frontend development"
    ],
    "answer": "Protobuf reduces payload size and improves serialization speed",
    "explanation": "Protobuf is a compact binary format that reduces payload sizes and improves serialization/deserialization speed compared to JSON, enhancing gRPC's performance.",
    "tags": ["gRPC", "Protobuf", "Performance"]
  },
  {
    "question": "What is the primary purpose of GraphQL in API development?",
    "options": [
      "To enable clients to request only the data they need",
      "To encrypt communication between services",
      "To manage database connections directly",
      "To replace traditional REST APIs entirely"
    ],
    "answer": "To enable clients to request only the data they need",
    "explanation": "GraphQL allows clients to specify exactly what data they need, avoiding over-fetching or under-fetching and improving efficiency.",
    "tags": ["GraphQL", "API Development", "Data Fetching"]
  },
  {
    "question": "Which protocol does gRPC use for communication?",
    "options": ["HTTP", "HTTP/2", "WebSocket", "TCP"],
    "answer": "HTTP/2",
    "explanation": "gRPC uses HTTP/2 for efficient, high-performance communication between services, leveraging features like multiplexing and bidirectional streaming.",
    "tags": ["gRPC", "Protocol", "HTTP/2"]
  },
  {
    "question": "What is the main advantage of using Protocol Buffers (Protobuf) in gRPC?",
    "options": [
      "It supports only text-based data formats",
      "It provides a self-documenting API",
      "It uses a compact binary format for faster serialization/deserialization",
      "It eliminates the need for a server"
    ],
    "answer": "It uses a compact binary format for faster serialization/deserialization",
    "explanation": "Protocol Buffers (Protobuf) is a binary serialization format used by gRPC, offering faster and more efficient data transfer compared to JSON or XML.",
    "tags": ["gRPC", "Protobuf", "Binary Format"]
  },
  {
    "question": "Which library is commonly used to create a GraphQL API with Apollo Server?",
    "options": ["express-graphql", "apollo-server", "graphql-yoga", "nexus"],
    "answer": "apollo-server",
    "explanation": "`apollo-server` is a popular library for creating GraphQL APIs with Apollo Server, providing tools for schema definition, resolvers, and query execution.",
    "tags": ["GraphQL", "Apollo Server", "Library"]
  },
  {
    "question": "What is the role of the `typeDefs` in an Apollo Server GraphQL setup?",
    "options": [
      "To define the application's business logic",
      "To specify the schema and type definitions for the API",
      "To handle database connections",
      "To optimize performance of the API"
    ],
    "answer": "To specify the schema and type definitions for the API",
    "explanation": "The `typeDefs` in Apollo Server define the schema and type definitions for the GraphQL API, allowing clients to understand the available queries and mutations.",
    "tags": ["GraphQL", "Apollo Server", "Schema Definition"]
  },
  {
    "question": "Which of the following best describes the difference between GraphQL and gRPC?",
    "options": [
      "GraphQL uses Protobuf, while gRPC uses JSON",
      "GraphQL is designed for frontend APIs, while gRPC is optimized for microservices",
      "GraphQL requires Docker, while gRPC does not",
      "GraphQL eliminates the need for a client, while gRPC requires one"
    ],
    "answer": "GraphQL is designed for frontend APIs, while gRPC is optimized for microservices",
    "explanation": "GraphQL is ideal for flexible, frontend-driven APIs, while gRPC is optimized for high-performance communication between microservices using Protobuf.",
    "tags": ["GraphQL", "gRPC", "Comparison"]
  },
  {
    "question": "What is the default endpoint for a GraphQL API?",
    "options": ["/api", "/graphql", "/rest", "/rpc"],
    "answer": "/graphql",
    "explanation": "The default endpoint for a GraphQL API is `/graphql`, where clients send their queries and receive responses.",
    "tags": ["GraphQL", "Endpoint", "API"]
  },
  {
    "question": "Which feature ensures that GraphQL APIs are self-documenting?",
    "options": [
      "Introspection",
      "RESTful routing",
      "CORS policies",
      "Rate limiting"
    ],
    "answer": "Introspection",
    "explanation": "GraphQL's introspection feature allows clients to query the schema itself, making the API self-documenting and easier to explore and integrate with.",
    "tags": ["GraphQL", "Introspection", "Self-Documentation"]
  },
  {
    "question": "What is the purpose of the `resolvers` in a GraphQL API?",
    "options": [
      "To define environment variables",
      "To handle database migrations",
      "To map fields in the schema to actual data sources",
      "To encrypt communication between services"
    ],
    "answer": "To map fields in the schema to actual data sources",
    "explanation": "Resolvers in GraphQL define how to fetch data for each field in the schema, acting as the bridge between the schema and the underlying data sources.",
    "tags": ["GraphQL", "Resolvers", "Schema Mapping"]
  },
  {
    "question": "Which of the following is true about gRPC's performance compared to GraphQL?",
    "options": [
      "gRPC is slower due to its reliance on HTTP/1.1",
      "gRPC offers higher performance due to its use of Protobuf and HTTP/2",
      "gRPC requires manual configuration of endpoints",
      "gRPC eliminates the need for a schema"
    ],
    "answer": "gRPC offers higher performance due to its use of Protobuf and HTTP/2",
    "explanation": "gRPC achieves higher performance than GraphQL by using Protobuf for efficient serialization and HTTP/2 for fast, multiplexed communication.",
    "tags": ["gRPC", "Performance", "Comparison"]
  },
  {
    "question": "What is the purpose of the `.proto` file in gRPC?",
    "options": [
      "To define environment variables for the service",
      "To specify the schema and message structures for the API",
      "To configure CORS policies",
      "To store session data"
    ],
    "answer": "To specify the schema and message structures for the API",
    "explanation": "The `.proto` file in gRPC defines the service methods and message structures using Protocol Buffers, ensuring efficient communication between services.",
    "tags": ["gRPC", "Proto File", "Schema Definition"]
  },
  {
    "question": "Which of the following is a benefit of using Nexus for GraphQL development?",
    "options": [
      "It eliminates the need for a schema",
      "It provides a code-first approach for defining schemas",
      "It replaces the need for a database",
      "It simplifies REST API development"
    ],
    "answer": "It provides a code-first approach for defining schemas",
    "explanation": "Nexus is a TypeScript-first, code-first GraphQL framework that allows developers to define schemas programmatically without writing raw SDL (Schema Definition Language).",
    "tags": ["GraphQL", "Nexus", "Code-First Approach"]
  },
  {
    "question": "How do you start a gRPC server in Node.js?",
    "options": [
      "server.listen()",
      "server.start()",
      "server.bindAsync()",
      "server.run()"
    ],
    "answer": "server.bindAsync()",
    "explanation": "In gRPC, the `server.bindAsync()` method is used to bind the server to a specific address and port, starting the service after binding.",
    "tags": ["gRPC", "Server Setup", "Node.js"]
  },
  {
    "question": "Which of the following is true about GraphQL's strongly typed schema?",
    "options": [
      "It prevents clients from querying invalid fields",
      "It eliminates the need for input validation",
      "It uses Protobuf for type definitions",
      "It requires manual configuration of CORS headers"
    ],
    "answer": "It prevents clients from querying invalid fields",
    "explanation": "GraphQL's strongly typed schema ensures that clients can only query valid fields and types, reducing errors and improving API consistency.",
    "tags": ["GraphQL", "Schema", "Type Safety"]
  },
  {
    "question": "What is the role of bidirectional streaming in gRPC?",
    "options": [
      "To allow both client and server to send streams of messages asynchronously",
      "To encrypt communication between client and server",
      "To replace the need for a database",
      "To optimize image loading"
    ],
    "answer": "To allow both client and server to send streams of messages asynchronously",
    "explanation": "Bidirectional streaming in gRPC enables both the client and server to send streams of messages asynchronously, making it ideal for real-time applications.",
    "tags": ["gRPC", "Streaming", "Real-Time Communication"]
  },
  {
    "question": "Which command is used to run a gRPC client in Node.js?",
    "options": [
      "node server.js",
      "node client.js",
      "npm start",
      "docker-compose up"
    ],
    "answer": "node client.js",
    "explanation": "To run a gRPC client in Node.js, you execute the client script using `node client.js`, which sends requests to the gRPC server.",
    "tags": ["gRPC", "Client", "Node.js"]
  },
  {
    "question": "What is the main advantage of using Apollo Server for GraphQL development?",
    "options": [
      "It eliminates the need for a schema",
      "It provides built-in support for Protobuf",
      "It simplifies schema definition and resolver implementation",
      "It automatically manages database connections"
    ],
    "answer": "It simplifies schema definition and resolver implementation",
    "explanation": "Apollo Server streamlines the process of defining schemas and implementing resolvers, making it easier to build and manage GraphQL APIs.",
    "tags": ["GraphQL", "Apollo Server", "Development Tools"]
  },
  {
    "question": "Which of the following is a common use case for gRPC?",
    "options": [
      "Frontend web applications",
      "High-performance microservices communication",
      "Static website hosting",
      "Database encryption"
    ],
    "answer": "High-performance microservices communication",
    "explanation": "gRPC is widely used for high-performance communication between microservices due to its efficient binary format and support for bidirectional streaming.",
    "tags": ["gRPC", "Use Cases", "Microservices"]
  },
  {
    "question": "What is the purpose of the `queryType` in a Nexus GraphQL setup?",
    "options": [
      "To define mutation operations",
      "To specify the root query fields for the API",
      "To encrypt sensitive data",
      "To replace the need for a Dockerfile"
    ],
    "answer": "To specify the root query fields for the API",
    "explanation": "In Nexus, the `queryType` is used to define the root query fields of the GraphQL API, enabling clients to request data through these fields.",
    "tags": ["GraphQL", "Nexus", "Query Type"]
  },
  {
    "question": "Which of the following is true about GraphQL's single endpoint approach?",
    "options": [
      "It increases the number of endpoints required for an API",
      "It consolidates all queries and mutations into a single `/graphql` endpoint",
      "It requires multiple servers for different data sources",
      "It eliminates the need for resolvers"
    ],
    "answer": "It consolidates all queries and mutations into a single `/graphql` endpoint",
    "explanation": "GraphQL uses a single endpoint (`/graphql`) for all queries and mutations, simplifying API design and reducing complexity.",
    "tags": ["GraphQL", "Single Endpoint", "API Design"]
  },
  {
    "question": "What is the main disadvantage of using GraphQL over gRPC for microservices communication?",
    "options": [
      "GraphQL lacks strong typing",
      "GraphQL has moderate performance compared to gRPC's high-speed communication",
      "GraphQL cannot handle real-time data",
      "GraphQL requires Docker for deployment"
    ],
    "answer": "GraphQL has moderate performance compared to gRPC's high-speed communication",
    "explanation": "While GraphQL is flexible and frontend-friendly, gRPC offers superior performance for microservices communication due to its binary serialization and HTTP/2 protocol.",
    "tags": ["GraphQL", "gRPC", "Performance Comparison"]
  },
  {
    "question": "Which of the following is a benefit of using gRPC for microservices?",
    "options": [
      "It supports flexible, frontend-driven queries",
      "It uses a compact binary format for efficient data transfer",
      "It eliminates the need for a schema",
      "It simplifies image processing"
    ],
    "answer": "It uses a compact binary format for efficient data transfer",
    "explanation": "gRPC leverages Protobuf, a compact binary format, for efficient serialization and deserialization of data, reducing payload sizes and improving performance.",
    "tags": ["gRPC", "Protobuf", "Efficiency"]
  },
  {
    "question": "Which of the following is true about Apollo Server?",
    "options": [
      "It supports only code-first approaches",
      "It provides tools for building and managing GraphQL APIs",
      "It requires Docker for deployment",
      "It uses Protobuf for data serialization"
    ],
    "answer": "It provides tools for building and managing GraphQL APIs",
    "explanation": "Apollo Server is a comprehensive toolkit for building and managing GraphQL APIs, supporting both schema-first and code-first approaches.",
    "tags": ["GraphQL", "Apollo Server", "Development Tools"]
  },
  {
    "question": "What is the primary purpose of Docker in application development?",
    "options": [
      "To containerize applications for consistent deployment across environments",
      "To encrypt communication between services",
      "To manage database connections directly",
      "To replace the need for a package manager like npm"
    ],
    "answer": "To containerize applications for consistent deployment across environments",
    "explanation": "Docker allows you to containerize applications, ensuring that dependencies and configurations remain consistent across different operating systems and environments.",
    "tags": ["Docker", "Containerization", "Deployment"]
  },
  {
    "question": "Which command checks if Docker is installed correctly?",
    "options": ["docker -v", "npm -v", "node -v", "express -v"],
    "answer": "docker -v",
    "explanation": "The `docker -v` command displays the installed Docker version, confirming that Docker is installed and working properly.",
    "tags": ["Docker", "Installation", "Command"]
  },
  {
    "question": "What does the `WORKDIR /app` instruction in a Dockerfile do?",
    "options": [
      "Sets the working directory inside the container",
      "Copies all files into the container",
      "Installs Node.js dependencies",
      "Starts the application server"
    ],
    "answer": "Sets the working directory inside the container",
    "explanation": "The `WORKDIR /app` instruction in a Dockerfile sets the working directory inside the container where subsequent commands will execute.",
    "tags": ["Dockerfile", "WORKDIR", "Container Setup"]
  },
  {
    "question": "Which file prevents unnecessary files from being copied into the Docker container?",
    "options": [".gitignore", "package.json", ".dockerignore", "Dockerfile"],
    "answer": ".dockerignore",
    "explanation": "The `.dockerignore` file specifies which files or directories should be ignored when building the Docker image, similar to how `.gitignore` works for Git.",
    "tags": ["Docker", ".dockerignore", "File Management"]
  },
  {
    "question": "What does the `EXPOSE 3000` instruction in a Dockerfile do?",
    "options": [
      "Installs Express.js on port 3000",
      "Defines the port the app listens on inside the container",
      "Encrypts data transmitted over port 3000",
      "Connects to external databases on port 3000"
    ],
    "answer": "Defines the port the app listens on inside the container",
    "explanation": "The `EXPOSE 3000` instruction in a Dockerfile informs Docker that the containerized application listens on port 3000 inside the container.",
    "tags": ["Dockerfile", "EXPOSE", "Port Configuration"]
  },
  {
    "question": "Which command builds a Docker image for your Node.js app?",
    "options": [
      "docker run -t myapp .",
      "docker build -t myapp .",
      "docker push myapp",
      "docker login"
    ],
    "answer": "docker build -t myapp .",
    "explanation": "The `docker build -t myapp .` command builds a Docker image for your Node.js app, tagging it with the name `myapp`.",
    "tags": ["Docker", "Build", "Image Creation"]
  },
  {
    "question": "How do you run a Docker container in detached mode?",
    "options": [
      "docker run -d myapp",
      "docker run --detach myapp",
      "docker start -d myapp",
      "docker compose up -d"
    ],
    "answer": "docker run -d myapp",
    "explanation": "The `-d` flag in `docker run -d myapp` runs the container in detached mode, keeping it running in the background.",
    "tags": ["Docker", "Run", "Detached Mode"]
  },
  {
    "question": "Which command lists all running Docker containers?",
    "options": ["docker ps", "docker list", "docker images", "docker status"],
    "answer": "docker ps",
    "explanation": "The `docker ps` command lists all currently running Docker containers.",
    "tags": ["Docker", "Container Management", "Running Containers"]
  },
  {
    "question": "Which command stops a running Docker container?",
    "options": [
      "docker stop <container_id>",
      "docker kill <container_id>",
      "docker pause <container_id>",
      "docker remove <container_id>"
    ],
    "answer": "docker stop <container_id>",
    "explanation": "The `docker stop <container_id>` command gracefully stops a running Docker container using its ID or name.",
    "tags": ["Docker", "Container Management", "Stopping Containers"]
  },
  {
    "question": "What is the role of Docker Compose in managing applications?",
    "options": [
      "To manage multiple containers (e.g., Node.js + Database) together",
      "To encrypt communication between containers",
      "To replace the need for a Dockerfile",
      "To optimize container performance"
    ],
    "answer": "To manage multiple containers (e.g., Node.js + Database) together",
    "explanation": "Docker Compose simplifies the management of multi-container applications by allowing you to define and run multiple services (e.g., Node.js, MongoDB, Redis) together in a single configuration file.",
    "tags": ["Docker Compose", "Multi-Container Apps", "Configuration"]
  },
  {
    "question": "Which file defines the services in a Docker Compose setup?",
    "options": [
      "Dockerfile",
      "docker-compose.yml",
      "package.json",
      ".dockerignore"
    ],
    "answer": "docker-compose.yml",
    "explanation": "The `docker-compose.yml` file defines the services, networks, and volumes used in a Docker Compose setup, enabling easy management of multi-container applications.",
    "tags": ["Docker Compose", "Configuration File", "Services"]
  },
  {
    "question": "What is the primary purpose of event-driven architecture in microservices?",
    "options": [
      "To ensure tight coupling between services",
      "To decouple services using events instead of direct API calls",
      "To encrypt communication between services",
      "To store data in a centralized database"
    ],
    "answer": "To decouple services using events instead of direct API calls",
    "explanation": "Event-driven architecture decouples services by allowing them to communicate asynchronously through events, improving scalability and flexibility.",
    "tags": ["Microservices", "Event-Driven Architecture", "Decoupling"]
  },
  {
    "question": "Which messaging system is best suited for high-throughput event streaming?",
    "options": ["RabbitMQ", "Kafka", "Redis Pub/Sub", "gRPC"],
    "answer": "Kafka",
    "explanation": "Kafka is designed for high-throughput event streaming, making it ideal for real-time data processing and large-scale systems.",
    "tags": ["Kafka", "Event Streaming", "High-Throughput"]
  },
  {
    "question": "What is RabbitMQ primarily used for in microservices?",
    "options": [
      "Real-time messaging between services",
      "Reliable message queuing for task processing",
      "High-speed service-to-service communication",
      "Centralized storage of service data"
    ],
    "answer": "Reliable message queuing for task processing",
    "explanation": "RabbitMQ is a reliable message broker that queues messages for consumers, ensuring tasks are processed even under heavy load or failure scenarios.",
    "tags": ["RabbitMQ", "Message Queuing", "Task Processing"]
  },
  {
    "question": "Which library is commonly used to interact with RabbitMQ in Node.js?",
    "options": ["amqplib", "kafkajs", "redis", "grpc"],
    "answer": "amqplib",
    "explanation": "`amqplib` is a popular library for interacting with RabbitMQ in Node.js, enabling producers to send messages and consumers to receive them.",
    "tags": ["RabbitMQ", "Node.js", "amqplib"]
  },
  {
    "question": "What is the role of a producer in event-driven architecture?",
    "options": [
      "To process incoming requests synchronously",
      "To generate and publish events to a message broker",
      "To listen for events and react accordingly",
      "To manage service-to-service encryption"
    ],
    "answer": "To generate and publish events to a message broker",
    "explanation": "A producer generates events (e.g., 'Order Created') and publishes them to a message broker like RabbitMQ or Kafka, which then delivers them to consumers.",
    "tags": ["Event-Driven Architecture", "Producer", "Message Broker"]
  },
  {
    "question": "Which of the following is true about Kafka?",
    "options": [
      "It is a lightweight messaging system suitable for small applications",
      "It supports high-throughput event streaming for real-time data processing",
      "It requires Redis as a dependency",
      "It is primarily used for synchronous communication"
    ],
    "answer": "It supports high-throughput event streaming for real-time data processing",
    "explanation": "Kafka is a distributed event streaming platform designed for high-throughput, real-time data processing and communication between services.",
    "tags": ["Kafka", "Event Streaming", "Real-Time Data"]
  },
  {
    "question": "What does Redis Pub/Sub provide in microservices?",
    "options": [
      "Reliable message queuing with persistence",
      "Lightweight real-time messaging",
      "High-throughput event streaming",
      "Encrypted service-to-service communication"
    ],
    "answer": "Lightweight real-time messaging",
    "explanation": "Redis Pub/Sub provides a lightweight mechanism for real-time messaging between services, though it lacks persistence and durability compared to RabbitMQ or Kafka.",
    "tags": ["Redis", "Pub/Sub", "Real-Time Messaging"]
  },
  {
    "question": "Which component in RabbitMQ ensures messages are stored reliably until consumed?",
    "options": ["Publisher", "Queue", "Consumer", "Topic"],
    "answer": "Queue",
    "explanation": "In RabbitMQ, a queue stores messages reliably until they are consumed by one or more consumers, ensuring task processing even under failure conditions.",
    "tags": ["RabbitMQ", "Queues", "Reliability"]
  },
  {
    "question": "What is gRPC primarily used for in microservices?",
    "options": [
      "Reliable message queuing",
      "High-speed service-to-service communication",
      "Lightweight real-time messaging",
      "Centralized storage of service data"
    ],
    "answer": "High-speed service-to-service communication",
    "explanation": "gRPC is a high-performance RPC framework that enables fast and efficient communication between microservices, often replacing REST for inter-service communication.",
    "tags": ["gRPC", "Service Communication", "Performance"]
  },
  {
    "question": "What is the main advantage of using Kafka over RabbitMQ?",
    "options": [
      "Kafka provides reliable message queuing with FIFO guarantees",
      "Kafka supports high-throughput event streaming for real-time data processing",
      "Kafka is simpler and easier to set up than RabbitMQ",
      "Kafka eliminates the need for producers and consumers"
    ],
    "answer": "Kafka supports high-throughput event streaming for real-time data processing",
    "explanation": "While RabbitMQ focuses on reliable message queuing, Kafka excels at high-throughput event streaming, making it ideal for real-time data pipelines and analytics.",
    "tags": ["Kafka", "RabbitMQ", "Comparison"]
  },
  {
    "question": "Which of the following is a benefit of using Redis Pub/Sub in microservices?",
    "options": [
      "Persistent message storage",
      "Lightweight real-time messaging",
      "Centralized database management",
      "Encryption of service communication"
    ],
    "answer": "Lightweight real-time messaging",
    "explanation": "Redis Pub/Sub provides a lightweight and simple solution for real-time messaging between services, though it lacks persistence and durability.",
    "tags": ["Redis", "Pub/Sub", "Real-Time Messaging"]
  },
  {
    "question": "What is the purpose of the `durable: true` option in RabbitMQ?",
    "options": [
      "Ensures messages are delivered instantly",
      "Guarantees message persistence across server restarts",
      "Encrypts messages for secure transmission",
      "Limits the number of messages in a queue"
    ],
    "answer": "Guarantees message persistence across server restarts",
    "explanation": "The `durable: true` option in RabbitMQ ensures that messages remain persisted in the queue even if the server restarts, providing reliability for critical tasks.",
    "tags": ["RabbitMQ", "Durability", "Message Persistence"]
  },
  {
    "question": "Which of the following is a key difference between gRPC and REST?",
    "options": [
      "gRPC uses HTTP/2 for faster communication, while REST uses HTTP/1.1",
      "gRPC is primarily used for frontend development, while REST is for backend",
      "gRPC encrypts all messages automatically, while REST does not",
      "gRPC eliminates the need for input validation, while REST requires it"
    ],
    "answer": "gRPC uses HTTP/2 for faster communication, while REST uses HTTP/1.1",
    "explanation": "gRPC leverages HTTP/2 for faster and more efficient communication between services, offering features like multiplexing and bidirectional streaming.",
    "tags": ["gRPC", "REST", "Comparison"]
  },
  {
    "question": "What is the role of a consumer in event-driven architecture?",
    "options": [
      "To generate and publish events",
      "To store events in a centralized database",
      "To listen for events and react accordingly",
      "To encrypt communication between services"
    ],
    "answer": "To listen for events and react accordingly",
    "explanation": "A consumer listens for events published by producers and reacts to them, such as updating inventory or sending emails based on an 'Order Created' event.",
    "tags": ["Event-Driven Architecture", "Consumer", "Message Broker"]
  },
  {
    "question": "Which of the following is true about Redis Pub/Sub?",
    "options": [
      "It supports persistent message storage",
      "It is ideal for lightweight real-time messaging",
      "It replaces the need for RabbitMQ or Kafka",
      "It encrypts all messages automatically"
    ],
    "answer": "It is ideal for lightweight real-time messaging",
    "explanation": "Redis Pub/Sub is a lightweight messaging system suitable for real-time communication but lacks persistence and durability, making it less suitable for critical task processing.",
    "tags": ["Redis", "Pub/Sub", "Real-Time Messaging"]
  },
  {
    "question": "What is the purpose of the `fromBeginning: true` option in Kafka consumers?",
    "options": [
      "To consume only new messages",
      "To consume messages from the earliest available offset",
      "To encrypt messages before consumption",
      "To limit the number of messages consumed"
    ],
    "answer": "To consume messages from the earliest available offset",
    "explanation": "The `fromBeginning: true` option in Kafka ensures that consumers start reading messages from the earliest available offset, allowing them to process historical data.",
    "tags": ["Kafka", "Consumers", "Message Consumption"]
  },
  {
    "question": "Which of the following is a common use case for RabbitMQ?",
    "options": [
      "Real-time stock price updates",
      "Task processing with guaranteed delivery",
      "High-speed service-to-service communication",
      "Centralized session management"
    ],
    "answer": "Task processing with guaranteed delivery",
    "explanation": "RabbitMQ is commonly used for task processing where guaranteed delivery and reliability are essential, such as order processing or email sending.",
    "tags": ["RabbitMQ", "Use Cases", "Task Processing"]
  },
  {
    "question": "What is the primary advantage of using Kafka over Redis Pub/Sub?",
    "options": [
      "Kafka is simpler to set up",
      "Kafka supports high-throughput event streaming with persistence",
      "Kafka eliminates the need for producers and consumers",
      "Kafka is only suitable for lightweight messaging"
    ],
    "answer": "Kafka supports high-throughput event streaming with persistence",
    "explanation": "Kafka is designed for high-throughput event streaming and provides persistence, making it more robust for large-scale systems compared to Redis Pub/Sub, which is lightweight but lacks persistence.",
    "tags": ["Kafka", "Redis", "Comparison"]
  },
  {
    "question": "Which tool would you choose for lightweight real-time messaging in a microservices system?",
    "options": ["RabbitMQ", "Kafka", "Redis Pub/Sub", "gRPC"],
    "answer": "Redis Pub/Sub",
    "explanation": "Redis Pub/Sub is ideal for lightweight real-time messaging due to its simplicity and speed, though it lacks persistence and durability.",
    "tags": ["Redis", "Pub/Sub", "Real-Time Messaging"]
  },
  {
    "question": "What is the purpose of Protocol Buffers in gRPC?",
    "options": [
      "To define the structure of messages and services",
      "To encrypt communication between services",
      "To store messages persistently",
      "To implement rate limiting"
    ],
    "answer": "To define the structure of messages and services",
    "explanation": "Protocol Buffers (`.proto` files) define the structure of messages and services in gRPC, enabling efficient serialization and deserialization of data.",
    "tags": ["gRPC", "Protocol Buffers", "Message Structure"]
  },
  {
    "question": "Which of the following is true about gRPC's performance compared to REST?",
    "options": [
      "gRPC is slower due to encryption overhead",
      "gRPC is faster due to binary encoding and HTTP/2",
      "gRPC requires manual setup for every request",
      "gRPC eliminates the need for input validation"
    ],
    "answer": "gRPC is faster due to binary encoding and HTTP/2",
    "explanation": "gRPC is faster than REST because it uses binary encoding (Protocol Buffers) and HTTP/2, enabling efficient communication between services.",
    "tags": ["gRPC", "REST", "Performance"]
  },
  {
    "question": "What is the role of Zookeeper in Kafka?",
    "options": [
      "To encrypt messages in transit",
      "To manage Kafka clusters and ensure consistency",
      "To act as a lightweight messaging system",
      "To replace the need for Redis Pub/Sub"
    ],
    "answer": "To manage Kafka clusters and ensure consistency",
    "explanation": "Zookeeper is used by Kafka to manage cluster state, topic metadata, and ensure consistency across brokers in a Kafka cluster.",
    "tags": ["Kafka", "Zookeeper", "Cluster Management"]
  },
  {
    "question": "Which of the following is a benefit of using event-driven architecture in microservices?",
    "options": [
      "Tight coupling between services",
      "Decoupled and scalable service communication",
      "Increased complexity in deployment",
      "Elimination of message brokers"
    ],
    "answer": "Decoupled and scalable service communication",
    "explanation": "Event-driven architecture decouples services, allowing them to communicate asynchronously via events, improving scalability and flexibility.",
    "tags": ["Event-Driven Architecture", "Microservices", "Benefits"]
  },
  {
    "question": "What is the purpose of the `ack()` method in RabbitMQ consumers?",
    "options": [
      "To encrypt messages after consumption",
      "To acknowledge receipt of a message and remove it from the queue",
      "To resend failed messages",
      "To limit the number of messages consumed"
    ],
    "answer": "To acknowledge receipt of a message and remove it from the queue",
    "explanation": "The `ack()` method in RabbitMQ consumers acknowledges receipt of a message, ensuring it is removed from the queue after successful processing.",
    "tags": ["RabbitMQ", "Consumers", "Acknowledgment"]
  },
  {
    "question": "Which of the following is true about Redis Pub/Sub?",
    "options": [
      "It guarantees message delivery and persistence",
      "It is ideal for lightweight real-time messaging without persistence",
      "It replaces the need for RabbitMQ or Kafka",
      "It supports high-throughput event streaming"
    ],
    "answer": "It is ideal for lightweight real-time messaging without persistence",
    "explanation": "Redis Pub/Sub is well-suited for lightweight real-time messaging but does not guarantee message persistence or delivery, unlike RabbitMQ or Kafka.",
    "tags": ["Redis", "Pub/Sub", "Real-Time Messaging"]
  },
  {
    "question": "What is the primary purpose of rate limiting in web applications?",
    "options": [
      "To encrypt communication between client and server",
      "To prevent DDoS attacks, brute-force attempts, and API abuse",
      "To validate user input data",
      "To manage database connections securely"
    ],
    "answer": "To prevent DDoS attacks, brute-force attempts, and API abuse",
    "explanation": "Rate limiting restricts the number of requests a user can make within a specified time frame, helping to protect against DDoS attacks, brute-force login attempts, and API abuse.",
    "tags": ["Rate Limiting", "Security", "DDoS Prevention"]
  },
  {
    "question": "Which library is commonly used for rate limiting in Express.js?",
    "options": ["express-validator", "express-rate-limit", "cors", "zod"],
    "answer": "express-rate-limit",
    "explanation": "`express-rate-limit` is a middleware library used to enforce rate limits in Express.js applications, ensuring that users cannot exceed a defined request limit within a time window.",
    "tags": ["Express.js", "Rate Limiting", "Middleware"]
  },
  {
    "question": "What does Zod provide in web development?",
    "options": [
      "A TypeScript-first schema validation library",
      "A middleware for handling cross-origin requests",
      "A library for encrypting sensitive data",
      "A tool for generating random session IDs"
    ],
    "answer": "A TypeScript-first schema validation library",
    "explanation": "Zod is a TypeScript-first schema validation library that ensures user inputs match expected formats, making it ideal for input validation in both JavaScript and TypeScript projects.",
    "tags": ["Zod", "Input Validation", "TypeScript"]
  },
  {
    "question": "Which method is used to validate data using Zod?",
    "options": [
      "userSchema.parse()",
      "userSchema.validate()",
      "userSchema.safeParse()",
      "userSchema.check()"
    ],
    "answer": "userSchema.safeParse()",
    "explanation": "The `safeParse()` method in Zod is used to validate data safely, returning an error object if validation fails without throwing an exception.",
    "tags": ["Zod", "Validation", "SafeParse"]
  },
  {
    "question": "What is the main advantage of using Joi over Zod for input validation?",
    "options": [
      "Joi supports TypeScript out of the box",
      "Joi provides more flexible and customizable validation rules",
      "Joi is faster than Zod",
      "Joi eliminates the need for rate limiting"
    ],
    "answer": "Joi provides more flexible and customizable validation rules",
    "explanation": "While Zod is TypeScript-first, Joi offers more flexibility and customization options for validation rules, making it suitable for complex validation scenarios.",
    "tags": ["Joi", "Input Validation", "Comparison"]
  },
  {
    "question": "Which of the following is true about Cross-Origin Resource Sharing (CORS)?",
    "options": [
      "It allows or restricts cross-origin requests for security",
      "It encrypts data transmitted between client and server",
      "It is used exclusively for input validation",
      "It generates JWT tokens for authentication"
    ],
    "answer": "It allows or restricts cross-origin requests for security",
    "explanation": "CORS is a security feature that controls which origins (domains) can access your API, preventing unauthorized cross-origin requests.",
    "tags": ["CORS", "Security", "Cross-Origin Requests"]
  },
  {
    "question": "How do you enable CORS for all origins in an Express.js application?",
    "options": [
      "app.use(cors({ origin: 'https://example.com' }));",
      "app.use(cors());",
      "app.use(cors({ methods: ['GET', 'POST'] }));",
      "app.use(cors({ credentials: true }));"
    ],
    "answer": "app.use(cors());",
    "explanation": "By calling `app.use(cors())`, you enable CORS for all origins, allowing any domain to make requests to your API.",
    "tags": ["CORS", "Express.js", "Middleware"]
  },
  {
    "question": "Which property in the CORS middleware restricts allowed origins?",
    "options": ["methods", "credentials", "origin", "headers"],
    "answer": "origin",
    "explanation": "The `origin` property in the CORS middleware specifies which domains are allowed to make cross-origin requests to your API.",
    "tags": ["CORS", "Express.js", "Configuration"]
  },
  {
    "question": "What is the purpose of input validation in web applications?",
    "options": [
      "To store passwords securely in the database",
      "To ensure user inputs match expected formats and prevent security vulnerabilities",
      "To encrypt data in transit",
      "To implement rate limiting"
    ],
    "answer": "To ensure user inputs match expected formats and prevent security vulnerabilities",
    "explanation": "Input validation ensures that user-provided data matches the expected format, reducing the risk of security vulnerabilities like SQL injection and XSS attacks.",
    "tags": ["Input Validation", "Security", "Best Practices"]
  },
  {
    "question": "Which of the following best describes the difference between Zod and Joi?",
    "options": [
      "Zod is used for rate limiting, while Joi is used for CORS",
      "Zod is TypeScript-first, while Joi supports both JavaScript and TypeScript",
      "Zod encrypts data, while Joi validates inputs",
      "There is no difference; both libraries serve the same purpose"
    ],
    "answer": "Zod is TypeScript-first, while Joi supports both JavaScript and TypeScript",
    "explanation": "Zod is specifically designed for TypeScript and provides strong type inference, while Joi supports both JavaScript and TypeScript with more flexible validation rules.",
    "tags": ["Zod", "Joi", "Comparison", "Input Validation"]
  },
  {
    "question": "What happens when a user exceeds the rate limit set by `express-rate-limit`?",
    "options": [
      "The server responds with a success message",
      "The server blocks further requests and responds with an error",
      "The server automatically resets the password",
      "The server redirects the user to a login page"
    ],
    "answer": "The server blocks further requests and responds with an error",
    "explanation": "When a user exceeds the rate limit defined by `express-rate-limit`, the server blocks additional requests and responds with an error message until the time window resets.",
    "tags": ["Rate Limiting", "express-rate-limit", "Security"]
  },
  {
    "question": "Which of the following is a common use case for CORS?",
    "options": [
      "Validating user passwords during login",
      "Restricting which domains can access your API",
      "Encrypting sensitive data in transit",
      "Generating JWT tokens for authentication"
    ],
    "answer": "Restricting which domains can access your API",
    "explanation": "CORS is used to control which domains (origins) can access your API, ensuring that only authorized domains can make cross-origin requests.",
    "tags": ["CORS", "Security", "Cross-Origin Requests"]
  },
  {
    "question": "What does the `max` property define in `express-rate-limit`?",
    "options": [
      "The maximum size of the response body",
      "The maximum number of requests allowed within the time window",
      "The maximum length of a password",
      "The maximum number of concurrent connections"
    ],
    "answer": "The maximum number of requests allowed within the time window",
    "explanation": "The `max` property in `express-rate-limit` defines the maximum number of requests a user can make within the specified time window (`windowMs`).",
    "tags": ["Rate Limiting", "express-rate-limit", "Configuration"]
  },
  {
    "question": "Which method in Joi is used to validate user input data?",
    "options": [
      "userSchema.parse()",
      "userSchema.validate()",
      "userSchema.safeParse()",
      "userSchema.check()"
    ],
    "answer": "userSchema.validate()",
    "explanation": "In Joi, the `validate()` method is used to validate user input data against a defined schema, returning an error if validation fails.",
    "tags": ["Joi", "Input Validation", "Validation Method"]
  },
  {
    "question": "What is the purpose of the `windowMs` property in `express-rate-limit`?",
    "options": [
      "To define the encryption key for secure communication",
      "To specify the time window for rate limiting (in milliseconds)",
      "To set the expiration time for JWT tokens",
      "To configure CORS policies"
    ],
    "answer": "To specify the time window for rate limiting (in milliseconds)",
    "explanation": "The `windowMs` property in `express-rate-limit` specifies the duration of the time window (in milliseconds) during which the rate limit applies.",
    "tags": ["Rate Limiting", "express-rate-limit", "Configuration"]
  },
  {
    "question": "Which of the following is a security best practice when implementing CORS?",
    "options": [
      "Allow all origins by default",
      "Restrict allowed origins to trusted domains",
      "Disable HTTPS to improve performance",
      "Use the same domain for frontend and backend"
    ],
    "answer": "Restrict allowed origins to trusted domains",
    "explanation": "To ensure security, restrict allowed origins to trusted domains when implementing CORS, preventing unauthorized access from other domains.",
    "tags": ["CORS", "Security", "Best Practices"]
  },
  {
    "question": "What does the `message` property in `express-rate-limit` define?",
    "options": [
      "The encryption algorithm for secure communication",
      "The custom error message returned when the rate limit is exceeded",
      "The validation rules for user input",
      "The list of allowed origins for CORS"
    ],
    "answer": "The custom error message returned when the rate limit is exceeded",
    "explanation": "The `message` property in `express-rate-limit` allows you to define a custom error message that is returned when a user exceeds the rate limit.",
    "tags": ["Rate Limiting", "express-rate-limit", "Error Handling"]
  },
  {
    "question": "Which of the following is true about Zod's `safeParse()` method?",
    "options": [
      "It throws an exception if validation fails",
      "It returns an error object if validation fails, without throwing an exception",
      "It encrypts user input data",
      "It generates random session IDs"
    ],
    "answer": "It returns an error object if validation fails, without throwing an exception",
    "explanation": "Zod's `safeParse()` method validates data and returns an error object if validation fails, making it safer to handle errors without causing the application to crash.",
    "tags": ["Zod", "Input Validation", "SafeParse"]
  },
  {
    "question": "Which of the following is a benefit of using Joi for input validation?",
    "options": [
      "It provides TypeScript type inference out of the box",
      "It supports both JavaScript and TypeScript with flexible validation rules",
      "It automatically encrypts sensitive data",
      "It eliminates the need for rate limiting"
    ],
    "answer": "It supports both JavaScript and TypeScript with flexible validation rules",
    "explanation": "Joi supports both JavaScript and TypeScript, offering flexible and customizable validation rules for user input data.",
    "tags": ["Joi", "Input Validation", "Flexibility"]
  },
  {
    "question": "What is the purpose of the `methods` property in the CORS middleware?",
    "options": [
      "To define the encryption algorithm for secure communication",
      "To specify which HTTP methods are allowed for cross-origin requests",
      "To set the expiration time for JWT tokens",
      "To configure rate limiting"
    ],
    "answer": "To specify which HTTP methods are allowed for cross-origin requests",
    "explanation": "The `methods` property in the CORS middleware specifies which HTTP methods (e.g., GET, POST) are allowed for cross-origin requests.",
    "tags": ["CORS", "Express.js", "Configuration"]
  },
  {
    "question": "Which of the following is a security vulnerability that input validation helps prevent?",
    "options": [
      "SQL Injection",
      "Brute-force login attempts",
      "Cross-Site Scripting (XSS)",
      "All of the above"
    ],
    "answer": "All of the above",
    "explanation": "Input validation helps prevent various security vulnerabilities, including SQL injection, XSS, and malformed data submissions, ensuring that user inputs are safe and valid.",
    "tags": ["Input Validation", "Security", "Vulnerability Prevention"]
  },
  {
    "question": "What is the role of the `credentials` property in the CORS middleware?",
    "options": [
      "To encrypt user credentials",
      "To allow or disallow cookies and authentication headers in cross-origin requests",
      "To define rate limits for API requests",
      "To generate JWT tokens"
    ],
    "answer": "To allow or disallow cookies and authentication headers in cross-origin requests",
    "explanation": "The `credentials` property in the CORS middleware determines whether cookies and authentication headers are included in cross-origin requests.",
    "tags": ["CORS", "Express.js", "Credentials"]
  },
  {
    "question": "What is JWT (JSON Web Token) primarily used for in authentication?",
    "options": [
      "To store user passwords securely",
      "To generate random session IDs",
      "To transmit information securely between parties",
      "To encrypt database connections"
    ],
    "answer": "To transmit information securely between parties",
    "explanation": "JWT is a self-contained token that securely transmits information between parties as a JSON object, making it ideal for stateless authentication in APIs.",
    "tags": ["Authentication", "JWT", "Security"]
  },
  {
    "question": "Which library is commonly used to hash passwords before storing them in a database?",
    "options": ["jsonwebtoken", "bcryptjs", "passport", "dotenv"],
    "answer": "bcryptjs",
    "explanation": "`bcryptjs` is used to hash passwords before storing them in a database, ensuring that even if the database is compromised, user passwords remain secure.",
    "tags": ["Security", "Password Hashing", "bcryptjs"]
  },
  {
    "question": "What does OAuth 2.0 allow users to do?",
    "options": [
      "Log in using third-party services like Google or GitHub",
      "Generate JWT tokens manually",
      "Encrypt sensitive data in transit",
      "Store session data on the server"
    ],
    "answer": "Log in using third-party services like Google or GitHub",
    "explanation": "OAuth 2.0 enables users to log in with third-party services such as Google, GitHub, or Facebook without sharing their credentials directly with your application.",
    "tags": ["Authentication", "OAuth", "Third-Party Login"]
  },
  {
    "question": "Which middleware is used to verify JWT tokens in Express.js?",
    "options": [
      "express.json()",
      "jsonwebtoken.verify()",
      "passport.authenticate()",
      "cors()"
    ],
    "answer": "jsonwebtoken.verify()",
    "explanation": "The `jsonwebtoken.verify()` method is used to decode and verify the authenticity of a JWT token in Express.js, ensuring that the token has not been tampered with.",
    "tags": ["Express.js", "JWT", "Middleware"]
  },
  {
    "question": "What is the purpose of Single Sign-On (SSO)?",
    "options": [
      "To allow users to log in once and access multiple services",
      "To store session data on the client side",
      "To encrypt communication between the client and server",
      "To manage database connections securely"
    ],
    "answer": "To allow users to log in once and access multiple services",
    "explanation": "Single Sign-On (SSO) allows users to authenticate once and gain access to multiple services without needing to log in repeatedly.",
    "tags": ["Authentication", "SSO", "Security"]
  },
  {
    "question": "Which library provides pre-built login, signup, and user management features?",
    "options": ["jsonwebtoken", "bcryptjs", "Clerk", "passport"],
    "answer": "Clerk",
    "explanation": "Clerk is an authentication provider that offers pre-built login, signup, and user management features, simplifying the implementation of secure authentication flows.",
    "tags": ["Authentication", "Clerk", "User Management"]
  },
  {
    "question": "Which strategy is used in Passport.js for Google OAuth 2.0 authentication?",
    "options": [
      "passport-local",
      "passport-jwt",
      "passport-google-oauth20",
      "passport-session"
    ],
    "answer": "passport-google-oauth20",
    "explanation": "The `passport-google-oauth20` strategy is used in Passport.js to implement Google OAuth 2.0 authentication, allowing users to log in with their Google accounts.",
    "tags": ["Passport.js", "OAuth", "Google Authentication"]
  },
  {
    "question": "What is the purpose of hashing passwords before storing them in a database?",
    "options": [
      "To compress the password size",
      "To ensure passwords are stored securely and cannot be easily read if the database is compromised",
      "To generate JWT tokens",
      "To enable password recovery"
    ],
    "answer": "To ensure passwords are stored securely and cannot be easily read if the database is compromised",
    "explanation": "Hashing passwords ensures that even if the database is compromised, attackers cannot easily retrieve the original passwords, protecting user data.",
    "tags": ["Security", "Password Hashing", "bcryptjs"]
  },
  {
    "question": "Which security practice limits the number of requests from a single IP address within a time window?",
    "options": [
      "Rate limiting",
      "SQL injection prevention",
      "HTTPS encryption",
      "CORS policy"
    ],
    "answer": "Rate limiting",
    "explanation": "Rate limiting restricts the number of requests a single IP can make within a specified time window, helping prevent abuse and brute-force attacks.",
    "tags": ["Security", "Rate Limiting", "API Protection"]
  },
  {
    "question": "Which middleware is used to handle cross-origin resource sharing (CORS) in Express.js?",
    "options": ["express-rate-limit", "cors", "passport", "jsonwebtoken"],
    "answer": "cors",
    "explanation": "The `cors` middleware in Express.js is used to define rules for cross-origin resource sharing, restricting which domains can make requests to your API.",
    "tags": ["Express.js", "CORS", "Middleware"]
  },
  {
    "question": "What is the primary advantage of using Clerk for authentication?",
    "options": [
      "It provides pre-built UI components for login and signup",
      "It requires manual setup for OAuth providers",
      "It generates JWT tokens automatically",
      "It encrypts all database connections"
    ],
    "answer": "It provides pre-built UI components for login and signup",
    "explanation": "Clerk simplifies authentication by providing pre-built UI components for login, signup, and user management, reducing development time and effort.",
    "tags": ["Authentication", "Clerk", "UI Components"]
  },
  {
    "question": "Which of the following best describes the role of Passport.js in Node.js?",
    "options": [
      "It manages database connections",
      "It serves as an authentication middleware for various strategies",
      "It encrypts communication between the client and server",
      "It generates random session IDs"
    ],
    "answer": "It serves as an authentication middleware for various strategies",
    "explanation": "Passport.js is a flexible authentication middleware for Node.js that supports various strategies, including local, OAuth, and JWT-based authentication.",
    "tags": ["Passport.js", "Authentication", "Middleware"]
  },
  {
    "question": "What is the purpose of setting an expiration time (TTL) for JWT tokens?",
    "options": [
      "To increase the size of the token",
      "To limit the validity period of the token for enhanced security",
      "To encrypt the token contents",
      "To store session data in the token"
    ],
    "answer": "To limit the validity period of the token for enhanced security",
    "explanation": "Setting an expiration time (TTL) for JWT tokens ensures that they are valid only for a limited time, enhancing security by preventing long-term token misuse.",
    "tags": ["JWT", "Security", "Token Expiry"]
  },
  {
    "question": "Which of the following is a common use case for SSO (Single Sign-On)?",
    "options": [
      "Storing passwords in plain text",
      "Allowing users to log in once and access multiple enterprise applications",
      "Generating random session IDs",
      "Encrypting database connections"
    ],
    "answer": "Allowing users to log in once and access multiple enterprise applications",
    "explanation": "SSO enables users to authenticate once and access multiple applications or services without needing to log in repeatedly, often used in enterprise environments.",
    "tags": ["SSO", "Authentication", "Enterprise Use Case"]
  },
  {
    "question": "Which of the following is true about bcryptjs?",
    "options": [
      "It is used to encrypt database connections",
      "It hashes passwords securely before storing them in the database",
      "It generates JWT tokens for authentication",
      "It handles OAuth 2.0 authentication flows"
    ],
    "answer": "It hashes passwords securely before storing them in the database",
    "explanation": "`bcryptjs` is a library used to hash passwords securely before storing them in the database, ensuring that even if the database is compromised, passwords remain protected.",
    "tags": ["bcryptjs", "Password Hashing", "Security"]
  },
  {
    "question": "What is the purpose of the `passport.serializeUser` and `passport.deserializeUser` methods?",
    "options": [
      "To encrypt and decrypt JWT tokens",
      "To define how user data is stored and retrieved in the session",
      "To handle rate limiting for API requests",
      "To configure CORS policies"
    ],
    "answer": "To define how user data is stored and retrieved in the session",
    "explanation": "In Passport.js, `serializeUser` and `deserializeUser` methods define how user data is stored in the session and retrieved during subsequent requests.",
    "tags": ["Passport.js", "Session Management", "Authentication"]
  },
  {
    "question": "Which security practice helps prevent SQL injection attacks?",
    "options": [
      "Using parameterized queries with knex.js or ORM",
      "Storing passwords in plain text",
      "Enabling CORS for all origins",
      "Using JWT tokens for session management"
    ],
    "answer": "Using parameterized queries with knex.js or ORM",
    "explanation": "Parameterized queries with libraries like `knex.js` or ORMs help prevent SQL injection attacks by separating SQL logic from user input.",
    "tags": ["Security", "SQL Injection", "Prevention"]
  },
  {
    "question": "What is the purpose of the `Authorization: Bearer <token>` header in HTTP requests?",
    "options": [
      "To send raw user credentials",
      "To transmit a JWT token for authentication",
      "To define CORS policies",
      "To encrypt communication between the client and server"
    ],
    "answer": "To transmit a JWT token for authentication",
    "explanation": "The `Authorization: Bearer <token>` header is used to transmit a JWT token for authentication, allowing the server to verify the user's identity.",
    "tags": ["JWT", "HTTP Headers", "Authentication"]
  },
  {
    "question": "Which of the following is a security best practice when implementing authentication?",
    "options": [
      "Store passwords in plain text for easy retrieval",
      "Use HTTPS to encrypt data in transit",
      "Disable rate limiting to improve performance",
      "Avoid using third-party authentication providers"
    ],
    "answer": "Use HTTPS to encrypt data in transit",
    "explanation": "Using HTTPS encrypts data in transit, protecting sensitive information like passwords and tokens from being intercepted by attackers.",
    "tags": ["Security", "Best Practices", "HTTPS"]
  },
  {
    "question": "What is the main advantage of using Clerk over traditional authentication solutions?",
    "options": [
      "It requires manual setup for each OAuth provider",
      "It provides pre-built UI components and simplifies user management",
      "It stores passwords in plain text for easier recovery",
      "It eliminates the need for HTTPS"
    ],
    "answer": "It provides pre-built UI components and simplifies user management",
    "explanation": "Clerk simplifies authentication by offering pre-built UI components for login, signup, and user management, reducing the need for custom implementation.",
    "tags": ["Clerk", "Authentication", "User Management"]
  },
  {
    "question": "Which middleware is used to enforce rate limiting in Express.js?",
    "options": ["express-rate-limit", "jsonwebtoken", "passport", "cors"],
    "answer": "express-rate-limit",
    "explanation": "`express-rate-limit` is a middleware used to enforce rate limiting in Express.js, restricting the number of requests from a single IP address within a time window.",
    "tags": ["Express.js", "Rate Limiting", "Middleware"]
  },
  {
    "question": "What is the primary purpose of using HTTPS in web applications?",
    "options": [
      "To store session data securely",
      "To encrypt communication between the client and server",
      "To generate random passwords",
      "To handle database connections"
    ],
    "answer": "To encrypt communication between the client and server",
    "explanation": "HTTPS encrypts communication between the client and server, protecting sensitive data like passwords, tokens, and personal information from being intercepted.",
    "tags": ["Security", "HTTPS", "Encryption"]
  },
  {
    "question": "What is Redis primarily used for in web applications?",
    "options": [
      "Storing large files",
      "Providing high-speed data access for caching and session management",
      "Managing relational databases",
      "Rendering HTML templates"
    ],
    "answer": "Providing high-speed data access for caching and session management",
    "explanation": "Redis is an in-memory data store that provides high-speed data access, making it ideal for caching, session management, and real-time analytics.",
    "tags": ["Redis", "Caching", "In-Memory Data Store"]
  },
  {
    "question": "Which command is used to check if Redis is running locally?",
    "options": [
      "redis-cli ping",
      "redis-server status",
      "redis-check",
      "redis-health"
    ],
    "answer": "redis-cli ping",
    "explanation": "The `redis-cli ping` command sends a PING request to the Redis server, which responds with PONG if it's running correctly.",
    "tags": ["Redis", "Setup", "Testing"]
  },
  {
    "question": "What does the `setex` method in Redis do?",
    "options": [
      "Sets a key with no expiration time",
      "Sets a key with a specified expiration time (TTL)",
      "Deletes a key from Redis",
      "Fetches the value of a key"
    ],
    "answer": "Sets a key with a specified expiration time (TTL)",
    "explanation": "The `setex` method in Redis sets a key with a specified expiration time (Time To Live) in seconds, ensuring the key automatically expires after the given duration.",
    "tags": ["Redis", "TTL", "Expiration"]
  },
  {
    "question": "Which Node.js library is commonly used to interact with Redis?",
    "options": ["express-redis", "ioredis", "mongoose", "knex"],
    "answer": "ioredis",
    "explanation": "`ioredis` is a popular Node.js client for interacting with Redis, providing features like connection pooling, Pub/Sub, and pipeline support.",
    "tags": ["Redis", "Node.js", "ioredis"]
  },
  {
    "question": "What is the purpose of caching in web applications?",
    "options": [
      "To increase database query complexity",
      "To reduce database load and improve response times",
      "To store user passwords securely",
      "To handle file uploads"
    ],
    "answer": "To reduce database load and improve response times",
    "explanation": "Caching stores frequently accessed data in memory, reducing the need for repeated database queries and improving application performance.",
    "tags": ["Redis", "Caching", "Performance Optimization"]
  },
  {
    "question": "Which caching strategy updates the cache whenever the database is updated?",
    "options": [
      "Write-Through",
      "Write-Back",
      "Cache-Aside",
      "Least Recently Used (LRU)"
    ],
    "answer": "Write-Through",
    "explanation": "The Write-Through strategy ensures that the cache is updated whenever the database is updated, maintaining consistency between the two.",
    "tags": ["Redis", "Caching Strategies", "Write-Through"]
  },
  {
    "question": "How do you delete a specific key in Redis?",
    "options": [
      "await redis.remove('key')",
      "await redis.del('key')",
      "await redis.clear('key')",
      "await redis.flush('key')"
    ],
    "answer": "await redis.del('key')",
    "explanation": "The `del` method in Redis is used to delete a specific key from the data store.",
    "tags": ["Redis", "Key Management", "Deletion"]
  },
  {
    "question": "Which Redis command checks the remaining time-to-live (TTL) of a key?",
    "options": ["TTL", "EXPIRE", "SET", "GET"],
    "answer": "TTL",
    "explanation": "The `TTL` command in Redis retrieves the remaining time-to-live (in seconds) of a key before it expires.",
    "tags": ["Redis", "TTL", "Expiration"]
  },
  {
    "question": "What happens when you use the `flushall` command in Redis?",
    "options": [
      "It deletes a single key",
      "It clears all keys in the current database",
      "It flushes all keys across all databases",
      "It restarts the Redis server"
    ],
    "answer": "It flushes all keys across all databases",
    "explanation": "The `flushall` command in Redis removes all keys from all databases, effectively clearing the entire data store. Use this with caution in production environments.",
    "tags": ["Redis", "Key Management", "Flush Commands"]
  },
  {
    "question": "Which Redis feature allows real-time event broadcasting?",
    "options": ["Lists", "Pub/Sub", "Hashes", "Sets"],
    "answer": "Pub/Sub",
    "explanation": "Redis's Pub/Sub (Publish/Subscribe) feature enables real-time messaging by allowing publishers to send messages to channels and subscribers to listen for them.",
    "tags": ["Redis", "Real-Time Messaging", "Pub/Sub"]
  },
  {
    "question": "What is the primary advantage of using Redis for caching?",
    "options": [
      "It supports SQL queries",
      "It stores data persistently on disk",
      "It provides fast in-memory data access",
      "It replaces the need for a database"
    ],
    "answer": "It provides fast in-memory data access",
    "explanation": "Redis stores data in memory, making it extremely fast for read-heavy operations like caching and session management.",
    "tags": ["Redis", "Caching", "Performance"]
  },
  {
    "question": "Which caching strategy involves checking the cache first and fetching data from the database only if it's missing?",
    "options": [
      "Write-Through",
      "Write-Back",
      "Cache-Aside",
      "Least Recently Used (LRU)"
    ],
    "answer": "Cache-Aside",
    "explanation": "The Cache-Aside strategy checks the cache first, and if the data is missing or expired, it fetches the data from the database and updates the cache.",
    "tags": ["Redis", "Caching Strategies", "Cache-Aside"]
  },
  {
    "question": "How do you subscribe to a channel in Redis Pub/Sub?",
    "options": [
      "await redis.subscribe('channel')",
      "await redis.listen('channel')",
      "await redis.join('channel')",
      "await redis.connect('channel')"
    ],
    "answer": "await redis.subscribe('channel')",
    "explanation": "In Redis Pub/Sub, the `subscribe` method is used to listen to messages on a specific channel.",
    "tags": ["Redis", "Pub/Sub", "Real-Time Messaging"]
  },
  {
    "question": "What is the Least Recently Used (LRU) eviction policy in Redis?",
    "options": [
      "Removes the least recently used items when memory is full",
      "Keeps all items in memory indefinitely",
      "Removes the most frequently used items",
      "Randomly selects items for removal"
    ],
    "answer": "Removes the least recently used items when memory is full",
    "explanation": "The LRU eviction policy in Redis removes the least recently used items when the memory limit is reached, ensuring efficient memory usage.",
    "tags": ["Redis", "Eviction Policies", "LRU"]
  },
  {
    "question": "Which of the following is true about Redis Pub/Sub?",
    "options": [
      "Messages are stored permanently in Redis",
      "Subscribers receive messages only if they are active at the time of publishing",
      "Pub/Sub requires a database write operation",
      "It supports only one subscriber per channel"
    ],
    "answer": "Subscribers receive messages only if they are active at the time of publishing",
    "explanation": "In Redis Pub/Sub, subscribers must be actively listening to a channel to receive messages; messages are not stored permanently.",
    "tags": ["Redis", "Pub/Sub", "Real-Time Messaging"]
  },
  {
    "question": "What is the purpose of the `get` method in Redis?",
    "options": [
      "To retrieve the value of a key",
      "To set a new key-value pair",
      "To delete a key",
      "To list all keys in the database"
    ],
    "answer": "To retrieve the value of a key",
    "explanation": "The `get` method in Redis retrieves the value associated with a specific key from the data store.",
    "tags": ["Redis", "Key-Value Operations", "Get"]
  },
  {
    "question": "Which of the following best describes Redis's role in session management?",
    "options": [
      "It stores session data in memory for fast access",
      "It encrypts session data for security",
      "It manages user authentication directly",
      "It generates unique session IDs for users"
    ],
    "answer": "It stores session data in memory for fast access",
    "explanation": "Redis is often used for session management because it stores session data in memory, providing fast access and reducing database load.",
    "tags": ["Redis", "Session Management", "In-Memory Storage"]
  },
  {
    "question": "What is the difference between `flushdb` and `flushall` in Redis?",
    "options": [
      "`flushdb` clears all keys in the current database, while `flushall` clears all keys across all databases",
      "`flushdb` deletes a single key, while `flushall` deletes all keys",
      "`flushdb` restarts Redis, while `flushall` stops it",
      "`flushdb` and `flushall` are identical"
    ],
    "answer": "`flushdb` clears all keys in the current database, while `flushall` clears all keys across all databases",
    "explanation": "`flushdb` clears all keys in the currently selected database, whereas `flushall` clears all keys across all databases in Redis.",
    "tags": ["Redis", "Key Management", "Flush Commands"]
  },
  {
    "question": "Which of the following is a common use case for Redis?",
    "options": [
      "Storing large binary files",
      "Caching API responses to reduce database load",
      "Managing relational database schemas",
      "Rendering HTML templates"
    ],
    "answer": "Caching API responses to reduce database load",
    "explanation": "Redis is commonly used for caching API responses, session management, and other scenarios requiring fast data access.",
    "tags": ["Redis", "Use Cases", "Caching"]
  },
  {
    "question": "How do you publish a message to a Redis channel?",
    "options": [
      "await redis.publish('channel', 'message')",
      "await redis.send('channel', 'message')",
      "await redis.broadcast('channel', 'message')",
      "await redis.notify('channel', 'message')"
    ],
    "answer": "await redis.publish('channel', 'message')",
    "explanation": "The `publish` method in Redis sends a message to all subscribers of a specific channel.",
    "tags": ["Redis", "Pub/Sub", "Real-Time Messaging"]
  },
  {
    "question": "What is Redis primarily used for in web applications?",
    "options": [
      "Storing large files",
      "Providing high-speed data access for caching and session management",
      "Managing relational databases",
      "Rendering HTML templates"
    ],
    "answer": "Providing high-speed data access for caching and session management",
    "explanation": "Redis is an in-memory data store that provides high-speed data access, making it ideal for caching, session management, and real-time analytics.",
    "tags": ["Redis", "Caching", "In-Memory Data Store"]
  },
  {
    "question": "Which command is used to check if Redis is running locally?",
    "options": [
      "redis-cli ping",
      "redis-server status",
      "redis-check",
      "redis-health"
    ],
    "answer": "redis-cli ping",
    "explanation": "The `redis-cli ping` command sends a PING request to the Redis server, which responds with PONG if it's running correctly.",
    "tags": ["Redis", "Setup", "Testing"]
  },
  {
    "question": "What does the `setex` method in Redis do?",
    "options": [
      "Sets a key with no expiration time",
      "Sets a key with a specified expiration time (TTL)",
      "Deletes a key from Redis",
      "Fetches the value of a key"
    ],
    "answer": "Sets a key with a specified expiration time (TTL)",
    "explanation": "The `setex` method in Redis sets a key with a specified expiration time (Time To Live) in seconds, ensuring the key automatically expires after the given duration.",
    "tags": ["Redis", "TTL", "Expiration"]
  },
  {
    "question": "Which Node.js library is commonly used to interact with Redis?",
    "options": ["express-redis", "ioredis", "mongoose", "knex"],
    "answer": "ioredis",
    "explanation": "`ioredis` is a popular Node.js client for interacting with Redis, providing features like connection pooling, Pub/Sub, and pipeline support.",
    "tags": ["Redis", "Node.js", "ioredis"]
  },
  {
    "question": "What is the purpose of caching in web applications?",
    "options": [
      "To increase database query complexity",
      "To reduce database load and improve response times",
      "To store user passwords securely",
      "To handle file uploads"
    ],
    "answer": "To reduce database load and improve response times",
    "explanation": "Caching stores frequently accessed data in memory, reducing the need for repeated database queries and improving application performance.",
    "tags": ["Redis", "Caching", "Performance Optimization"]
  },
  {
    "question": "Which caching strategy updates the cache whenever the database is updated?",
    "options": [
      "Write-Through",
      "Write-Back",
      "Cache-Aside",
      "Least Recently Used (LRU)"
    ],
    "answer": "Write-Through",
    "explanation": "The Write-Through strategy ensures that the cache is updated whenever the database is updated, maintaining consistency between the two.",
    "tags": ["Redis", "Caching Strategies", "Write-Through"]
  },
  {
    "question": "How do you delete a specific key in Redis?",
    "options": [
      "await redis.remove('key')",
      "await redis.del('key')",
      "await redis.clear('key')",
      "await redis.flush('key')"
    ],
    "answer": "await redis.del('key')",
    "explanation": "The `del` method in Redis is used to delete a specific key from the data store.",
    "tags": ["Redis", "Key Management", "Deletion"]
  },
  {
    "question": "Which Redis command checks the remaining time-to-live (TTL) of a key?",
    "options": ["TTL", "EXPIRE", "SET", "GET"],
    "answer": "TTL",
    "explanation": "The `TTL` command in Redis retrieves the remaining time-to-live (in seconds) of a key before it expires.",
    "tags": ["Redis", "TTL", "Expiration"]
  },
  {
    "question": "What happens when you use the `flushall` command in Redis?",
    "options": [
      "It deletes a single key",
      "It clears all keys in the current database",
      "It flushes all keys across all databases",
      "It restarts the Redis server"
    ],
    "answer": "It flushes all keys across all databases",
    "explanation": "The `flushall` command in Redis removes all keys from all databases, effectively clearing the entire data store. Use this with caution in production environments.",
    "tags": ["Redis", "Key Management", "Flush Commands"]
  },
  {
    "question": "Which Redis feature allows real-time event broadcasting?",
    "options": ["Lists", "Pub/Sub", "Hashes", "Sets"],
    "answer": "Pub/Sub",
    "explanation": "Redis's Pub/Sub (Publish/Subscribe) feature enables real-time messaging by allowing publishers to send messages to channels and subscribers to listen for them.",
    "tags": ["Redis", "Real-Time Messaging", "Pub/Sub"]
  },
  {
    "question": "What is the primary advantage of using Redis for caching?",
    "options": [
      "It supports SQL queries",
      "It stores data persistently on disk",
      "It provides fast in-memory data access",
      "It replaces the need for a database"
    ],
    "answer": "It provides fast in-memory data access",
    "explanation": "Redis stores data in memory, making it extremely fast for read-heavy operations like caching and session management.",
    "tags": ["Redis", "Caching", "Performance"]
  },
  {
    "question": "Which caching strategy involves checking the cache first and fetching data from the database only if it's missing?",
    "options": [
      "Write-Through",
      "Write-Back",
      "Cache-Aside",
      "Least Recently Used (LRU)"
    ],
    "answer": "Cache-Aside",
    "explanation": "The Cache-Aside strategy checks the cache first, and if the data is missing or expired, it fetches the data from the database and updates the cache.",
    "tags": ["Redis", "Caching Strategies", "Cache-Aside"]
  },
  {
    "question": "How do you subscribe to a channel in Redis Pub/Sub?",
    "options": [
      "await redis.subscribe('channel')",
      "await redis.listen('channel')",
      "await redis.join('channel')",
      "await redis.connect('channel')"
    ],
    "answer": "await redis.subscribe('channel')",
    "explanation": "In Redis Pub/Sub, the `subscribe` method is used to listen to messages on a specific channel.",
    "tags": ["Redis", "Pub/Sub", "Real-Time Messaging"]
  },
  {
    "question": "What is the Least Recently Used (LRU) eviction policy in Redis?",
    "options": [
      "Removes the least recently used items when memory is full",
      "Keeps all items in memory indefinitely",
      "Removes the most frequently used items",
      "Randomly selects items for removal"
    ],
    "answer": "Removes the least recently used items when memory is full",
    "explanation": "The LRU eviction policy in Redis removes the least recently used items when the memory limit is reached, ensuring efficient memory usage.",
    "tags": ["Redis", "Eviction Policies", "LRU"]
  },
  {
    "question": "Which of the following is true about Redis Pub/Sub?",
    "options": [
      "Messages are stored permanently in Redis",
      "Subscribers receive messages only if they are active at the time of publishing",
      "Pub/Sub requires a database write operation",
      "It supports only one subscriber per channel"
    ],
    "answer": "Subscribers receive messages only if they are active at the time of publishing",
    "explanation": "In Redis Pub/Sub, subscribers must be actively listening to a channel to receive messages; messages are not stored permanently.",
    "tags": ["Redis", "Pub/Sub", "Real-Time Messaging"]
  },
  {
    "question": "What is the purpose of the `get` method in Redis?",
    "options": [
      "To retrieve the value of a key",
      "To set a new key-value pair",
      "To delete a key",
      "To list all keys in the database"
    ],
    "answer": "To retrieve the value of a key",
    "explanation": "The `get` method in Redis retrieves the value associated with a specific key from the data store.",
    "tags": ["Redis", "Key-Value Operations", "Get"]
  },
  {
    "question": "Which of the following best describes Redis's role in session management?",
    "options": [
      "It stores session data in memory for fast access",
      "It encrypts session data for security",
      "It manages user authentication directly",
      "It generates unique session IDs for users"
    ],
    "answer": "It stores session data in memory for fast access",
    "explanation": "Redis is often used for session management because it stores session data in memory, providing fast access and reducing database load.",
    "tags": ["Redis", "Session Management", "In-Memory Storage"]
  },
  {
    "question": "What is the difference between `flushdb` and `flushall` in Redis?",
    "options": [
      "`flushdb` clears all keys in the current database, while `flushall` clears all keys across all databases",
      "`flushdb` deletes a single key, while `flushall` deletes all keys",
      "`flushdb` restarts Redis, while `flushall` stops it",
      "`flushdb` and `flushall` are identical"
    ],
    "answer": "`flushdb` clears all keys in the current database, while `flushall` clears all keys across all databases",
    "explanation": "`flushdb` clears all keys in the currently selected database, whereas `flushall` clears all keys across all databases in Redis.",
    "tags": ["Redis", "Key Management", "Flush Commands"]
  },
  {
    "question": "Which of the following is a common use case for Redis?",
    "options": [
      "Storing large binary files",
      "Caching API responses to reduce database load",
      "Managing relational database schemas",
      "Rendering HTML templates"
    ],
    "answer": "Caching API responses to reduce database load",
    "explanation": "Redis is commonly used for caching API responses, session management, and other scenarios requiring fast data access.",
    "tags": ["Redis", "Use Cases", "Caching"]
  },
  {
    "question": "How do you publish a message to a Redis channel?",
    "options": [
      "await redis.publish('channel', 'message')",
      "await redis.send('channel', 'message')",
      "await redis.broadcast('channel', 'message')",
      "await redis.notify('channel', 'message')"
    ],
    "answer": "await redis.publish('channel', 'message')",
    "explanation": "The `publish` method in Redis sends a message to all subscribers of a specific channel.",
    "tags": ["Redis", "Pub/Sub", "Real-Time Messaging"]
  },
  {
    "question": "What is the primary purpose of an ORM (Object-Relational Mapper) like Prisma or Knex.js?",
    "options": [
      "To simplify database interaction by writing JavaScript instead of raw SQL",
      "To optimize database performance",
      "To manage server configurations",
      "To handle frontend UI development"
    ],
    "answer": "To simplify database interaction by writing JavaScript instead of raw SQL",
    "explanation": "An ORM like Prisma or Knex.js allows developers to interact with databases using JavaScript code, abstracting away the need to write raw SQL queries.",
    "tags": ["ORM", "Prisma", "Knex.js", "Databases"]
  },
  {
    "question": "Which command initializes Prisma in a project?",
    "options": [
      "npx knex init",
      "npm install prisma",
      "npx prisma init",
      "npm run prisma"
    ],
    "answer": "npx prisma init",
    "explanation": "The `npx prisma init` command initializes Prisma in a project by creating the necessary files and configuration.",
    "tags": ["Prisma", "Initialization", "Setup"]
  },
  {
    "question": "In Prisma's schema file (`prisma/schema.prisma`), what does the `@id` attribute signify?",
    "options": [
      "It marks the field as a unique identifier",
      "It defines a foreign key relationship",
      "It specifies the default value for a field",
      "It indicates the field is optional"
    ],
    "answer": "It marks the field as a unique identifier",
    "explanation": "In Prisma, the `@id` attribute marks a field as the unique identifier (primary key) for a model.",
    "tags": ["Prisma", "Schema", "Primary Key"]
  },
  {
    "question": "Which method is used to create a new record in Prisma?",
    "options": [
      "prisma.create()",
      "prisma.insert()",
      "prisma.user.create()",
      "prisma.add()"
    ],
    "answer": "prisma.user.create()",
    "explanation": "In Prisma, you use `prisma.<model>.create()` to create a new record in the specified model (e.g., `prisma.user.create()` for the User model).",
    "tags": ["Prisma", "CRUD", "Create"]
  },
  {
    "question": "What is the purpose of the `knexfile.js` in Knex.js?",
    "options": [
      "To define database migrations",
      "To configure the database connection",
      "To generate models automatically",
      "To serve static files"
    ],
    "answer": "To configure the database connection",
    "explanation": "The `knexfile.js` in Knex.js is used to configure the database connection, including the client type (e.g., PostgreSQL or MySQL) and connection details.",
    "tags": ["Knex.js", "Configuration", "Setup"]
  },
  {
    "question": "Which command generates a migration file in Knex.js?",
    "options": [
      "npx knex migrate:init",
      "npx knex migrate:make <name>",
      "npx knex generate:migration",
      "npx knex init:migration"
    ],
    "answer": "npx knex migrate:make <name>",
    "explanation": "The `npx knex migrate:make <name>` command generates a new migration file with the specified name in Knex.js.",
    "tags": ["Knex.js", "Migrations", "Database Setup"]
  },
  {
    "question": "How do you insert data into a table using Knex.js?",
    "options": [
      "knex('table').insert(data)",
      "knex.table('table').add(data)",
      "knex.create('table', data)",
      "knex.addRecord('table', data)"
    ],
    "answer": "knex('table').insert(data)",
    "explanation": "In Knex.js, you use `knex('table').insert(data)` to insert a new record into a table.",
    "tags": ["Knex.js", "CRUD", "Insert"]
  },
  {
    "question": "Which of the following is true about Prisma's migrations?",
    "options": [
      "They are manually written in SQL",
      "They are generated automatically based on the schema",
      "They require external tools for execution",
      "They are only supported for MySQL"
    ],
    "answer": "They are generated automatically based on the schema",
    "explanation": "Prisma generates migrations automatically based on changes to the `schema.prisma` file, simplifying the migration process.",
    "tags": ["Prisma", "Migrations", "Schema"]
  },
  {
    "question": "What type of database is MongoDB?",
    "options": [
      "Relational Database",
      "NoSQL Database",
      "Graph Database",
      "Key-Value Store"
    ],
    "answer": "NoSQL Database",
    "explanation": "MongoDB is a NoSQL database that stores data in flexible, JSON-like documents.",
    "tags": ["MongoDB", "NoSQL", "Database"]
  },
  {
    "question": "What does Mongoose provide for MongoDB in Node.js?",
    "options": [
      "A front-end framework",
      "An ODM (Object Data Modeling) library",
      "A cloud hosting service",
      "An HTTP request handler"
    ],
    "answer": "An ODM (Object Data Modeling) library",
    "explanation": "Mongoose is an ODM library that helps define schemas and interact with MongoDB using JavaScript.",
    "tags": ["Mongoose", "ODM", "MongoDB"]
  },
  {
    "question": "Which command installs Mongoose in a Node.js project?",
    "options": [
      "npm install mongo",
      "npm install mongoose",
      "npm install mongodb",
      "npm install odm"
    ],
    "answer": "npm install mongoose",
    "explanation": "The correct package installation command for Mongoose is 'npm install mongoose'.",
    "tags": ["Mongoose", "Node.js", "npm"]
  },
  {
    "question": "What is MongoDB's default port number?",
    "options": ["3306", "5432", "27017", "8080"],
    "answer": "27017",
    "explanation": "MongoDB uses port 27017 by default for local connections.",
    "tags": ["MongoDB", "Configuration"]
  },
  {
    "question": "What does the 'required: true' option in a Mongoose schema enforce?",
    "options": [
      "The field must be a string",
      "The field must have a unique value",
      "The field must be provided",
      "The field must be a number"
    ],
    "answer": "The field must be provided",
    "explanation": "The 'required: true' option ensures the field cannot be omitted when creating a document.",
    "tags": ["Mongoose", "Schema", "Validation"]
  },
  {
    "question": "Which method is used to retrieve all users from the 'User' collection?",
    "options": [
      "User.findOne()",
      "User.get()",
      "User.findAll()",
      "User.find()"
    ],
    "answer": "User.find()",
    "explanation": "User.find() returns all documents in the 'User' collection when called without arguments.",
    "tags": ["Mongoose", "CRUD", "Query"]
  },
  {
    "question": "Why is '{ new: true }' used in findOneAndUpdate?",
    "options": [
      "To create a new document if none exists",
      "To return the updated document instead of the original",
      "To enforce validation rules",
      "To encrypt the data"
    ],
    "answer": "To return the updated document instead of the original",
    "explanation": "The '{ new: true }' option ensures the updated document is returned after the operation.",
    "tags": ["Mongoose", "Update", "CRUD"]
  },
  {
    "question": "What is a Mongoose virtual field?",
    "options": [
      "A field stored in MongoDB",
      "A computed property not stored in the database",
      "A placeholder for future data",
      "A field with encrypted data"
    ],
    "answer": "A computed property not stored in the database",
    "explanation": "Virtual fields are dynamically computed at runtime and not persisted to MongoDB.",
    "tags": ["Mongoose", "Schema", "Virtuals"]
  },
  {
    "question": "What does a 'pre('save')' middleware hook do?",
    "options": [
      "Executes logic after a document is saved",
      "Validates data before sending an HTTP response",
      "Executes logic before a document is saved",
      "Deletes a document before an update"
    ],
    "answer": "Executes logic before a document is saved",
    "explanation": "pre('save') hooks run specified logic before the save operation is completed.",
    "tags": ["Mongoose", "Middleware", "Hooks"]
  },
  {
    "question": "Which method deletes a user by their email?",
    "options": [
      "User.deleteOne()",
      "User.findOneAndRemove()",
      "User.findOneAndDelete()",
      "User.remove()"
    ],
    "answer": "User.findOneAndDelete()",
    "explanation": "User.findOneAndDelete() finds a document by criteria (e.g., email) and deletes it.",
    "tags": ["Mongoose", "CRUD", "Delete"]
  },
  {
    "question": "What is the primary purpose of an ORM (Object-Relational Mapper) like Prisma or Knex.js?",
    "options": [
      "To simplify database interaction by writing JavaScript instead of raw SQL",
      "To manage front-end UI components",
      "To handle HTTP requests and responses",
      "To optimize server performance"
    ],
    "answer": "To simplify database interaction by writing JavaScript instead of raw SQL",
    "explanation": "An ORM allows developers to interact with databases using JavaScript objects and methods, abstracting away the need to write raw SQL queries.",
    "tags": ["ORM", "Prisma", "Knex.js", "Databases"]
  },
  {
    "question": "Which command initializes Prisma in a project?",
    "options": [
      "npx prisma init",
      "npm install prisma",
      "npx knex init",
      "npm install @prisma/client"
    ],
    "answer": "npx prisma init",
    "explanation": "The `npx prisma init` command initializes Prisma in a project by creating the necessary files, including `prisma/schema.prisma`.",
    "tags": ["Prisma", "Initialization", "Setup"]
  },
  {
    "question": "What is the purpose of the `prisma/schema.prisma` file?",
    "options": [
      "To define database migrations",
      "To configure the database connection URL",
      "To define the data models and schema",
      "To generate REST APIs"
    ],
    "answer": "To define the data models and schema",
    "explanation": "The `prisma/schema.prisma` file defines the data models and schema for your application, specifying tables, fields, and relationships.",
    "tags": ["Prisma", "Schema", "Data Models"]
  },
  {
    "question": "Which method is used to create a new record in Prisma?",
    "options": [
      "prisma.insert()",
      "prisma.create()",
      "prisma.add()",
      "prisma.save()"
    ],
    "answer": "prisma.create()",
    "explanation": "In Prisma, the `create()` method is used to insert a new record into the database.",
    "tags": ["Prisma", "CRUD Operations", "Create"]
  },
  {
    "question": "How do you configure the database connection in Prisma?",
    "options": [
      "Using the `.env` file",
      "Using the `knexfile.js` file",
      "Using the `index.js` file",
      "Using the `package.json` file"
    ],
    "answer": "Using the `.env` file",
    "explanation": "Prisma uses the `DATABASE_URL` variable in the `.env` file to configure the database connection.",
    "tags": ["Prisma", "Configuration", "Database Connection"]
  },
  {
    "question": "Which command generates the Prisma client after defining the schema?",
    "options": [
      "npx prisma generate",
      "npx prisma migrate",
      "npx prisma init",
      "npx prisma deploy"
    ],
    "answer": "npx prisma generate",
    "explanation": "After defining the schema, you use `npx prisma generate` to generate the Prisma client, which provides type-safe query methods.",
    "tags": ["Prisma", "Client Generation", "Setup"]
  },
  {
    "question": "What is the main difference between Prisma and Knex.js?",
    "options": [
      "Prisma is a query builder, while Knex.js is an ORM",
      "Prisma provides an ORM-style API, while Knex.js is a query builder",
      "Prisma supports only MySQL, while Knex.js supports only PostgreSQL",
      "There is no difference; both are identical"
    ],
    "answer": "Prisma provides an ORM-style API, while Knex.js is a query builder",
    "explanation": "Prisma offers an ORM-style API with type safety, while Knex.js is a flexible SQL query builder that allows you to write raw SQL queries.",
    "tags": ["Prisma", "Knex.js", "Comparison", "ORM vs Query Builder"]
  },
  {
    "question": "Which command creates a migration in Knex.js?",
    "options": [
      "npx knex migrate:init",
      "npx knex migrate:create",
      "npx knex migrate:make",
      "npx knex migrate:generate"
    ],
    "answer": "npx knex migrate:make",
    "explanation": "The `npx knex migrate:make` command creates a new migration file where you can define schema changes using Knex.js's fluent API.",
    "tags": ["Knex.js", "Migrations", "Setup"]
  },
  {
    "question": "How do you run migrations in Knex.js?",
    "options": [
      "npx knex migrate:run",
      "npx knex migrate:latest",
      "npx knex migrate:apply",
      "npx knex migrate:start"
    ],
    "answer": "npx knex migrate:latest",
    "explanation": "To apply all pending migrations in Knex.js, you use the `npx knex migrate:latest` command.",
    "tags": ["Knex.js", "Migrations", "Execution"]
  },
  {
    "question": "Which method is used to insert a new record in Knex.js?",
    "options": ["knex.insert()", "knex.create()", "knex.add()", "knex.save()"],
    "answer": "knex.insert()",
    "explanation": "In Knex.js, the `insert()` method is used to add a new record to a table.",
    "tags": ["Knex.js", "CRUD Operations", "Insert"]
  },
  {
    "question": "Which of the following best describes the `up` function in a Knex.js migration?",
    "options": [
      "It rolls back changes made by the migration",
      "It defines the schema changes to be applied",
      "It generates the Prisma client",
      "It connects to the database"
    ],
    "answer": "It defines the schema changes to be applied",
    "explanation": "The `up` function in a Knex.js migration defines the schema changes to be applied when running the migration.",
    "tags": ["Knex.js", "Migrations", "Schema Changes"]
  },
  {
    "question": "Which property in the `knexfile.js` specifies the database client?",
    "options": ["client", "connection", "database", "provider"],
    "answer": "client",
    "explanation": "The `client` property in the `knexfile.js` specifies the database client (e.g., `pg` for PostgreSQL or `mysql2` for MySQL).",
    "tags": ["Knex.js", "Configuration", "Database Client"]
  },
  {
    "question": "What is the purpose of the `down` function in a Knex.js migration?",
    "options": [
      "To define the schema changes to be applied",
      "To roll back changes made by the migration",
      "To generate the Prisma client",
      "To connect to the database"
    ],
    "answer": "To roll back changes made by the migration",
    "explanation": "The `down` function in a Knex.js migration specifies how to undo the changes made by the `up` function, enabling rollback functionality.",
    "tags": ["Knex.js", "Migrations", "Rollback"]
  },
  {
    "question": "Which of the following is true about Prisma's type safety?",
    "options": [
      "Prisma does not provide type safety",
      "Prisma generates TypeScript types based on the schema",
      "Prisma requires manual type definitions for each model",
      "Type safety is only available for MySQL databases"
    ],
    "answer": "Prisma generates TypeScript types based on the schema",
    "explanation": "Prisma automatically generates TypeScript types based on the schema defined in `schema.prisma`, ensuring type safety when interacting with the database.",
    "tags": ["Prisma", "Type Safety", "TypeScript"]
  },
  {
    "question": "Which of the following is true about Knex.js?",
    "options": [
      "Knex.js is an ORM that provides type-safe queries",
      "Knex.js is a query builder that allows raw SQL queries",
      "Knex.js automatically generates TypeScript types",
      "Knex.js supports only NoSQL databases"
    ],
    "answer": "Knex.js is a query builder that allows raw SQL queries",
    "explanation": "Knex.js is a flexible SQL query builder that allows you to write raw SQL queries or use its fluent API for building queries.",
    "tags": ["Knex.js", "Query Builder", "Raw SQL"]
  },
  {
    "question": "How do you fetch all records from a table in Prisma?",
    "options": [
      "prisma.findMany()",
      "prisma.getAll()",
      "prisma.select()",
      "prisma.read()"
    ],
    "answer": "prisma.findMany()",
    "explanation": "In Prisma, the `findMany()` method is used to fetch all records from a table.",
    "tags": ["Prisma", "CRUD Operations", "Read"]
  },
  {
    "question": "How do you fetch all records from a table in Knex.js?",
    "options": [
      "knex.selectAll()",
      "knex.findMany()",
      "knex.select('*')",
      "knex.read()"
    ],
    "answer": "knex.select('*')",
    "explanation": "In Knex.js, you use `knex.select('*')` to fetch all records from a table.",
    "tags": ["Knex.js", "CRUD Operations", "Read"]
  },
  {
    "question": "Which of the following is true about Prisma's built-in migration system?",
    "options": [
      "Prisma requires manual migration scripts",
      "Prisma generates and applies migrations automatically",
      "Prisma migrations are written in raw SQL",
      "Prisma does not support migrations"
    ],
    "answer": "Prisma generates and applies migrations automatically",
    "explanation": "Prisma provides a built-in migration system that generates and applies migrations automatically based on changes to the schema.",
    "tags": ["Prisma", "Migrations", "Automatic Migrations"]
  },
  {
    "question": "Which of the following is true about Knex.js migrations?",
    "options": [
      "Knex.js migrations are generated automatically",
      "Knex.js migrations require manual setup and definition",
      "Knex.js does not support migrations",
      "Knex.js migrations are written in TypeScript"
    ],
    "answer": "Knex.js migrations require manual setup and definition",
    "explanation": "Knex.js migrations require you to manually define schema changes in JavaScript files, providing flexibility but requiring more setup compared to Prisma.",
    "tags": ["Knex.js", "Migrations", "Manual Setup"]
  },
  {
    "question": "What is the main advantage of using Prisma over Knex.js?",
    "options": [
      "Prisma allows raw SQL queries",
      "Prisma provides an ORM-style API with type safety",
      "Prisma is faster than Knex.js",
      "Prisma supports only NoSQL databases"
    ],
    "answer": "Prisma provides an ORM-style API with type safety",
    "explanation": "Prisma offers an ORM-style API with type safety, making it easier to work with databases without writing raw SQL queries.",
    "tags": ["Prisma", "Knex.js", "Comparison", "Advantages"]
  },
  {
    "question": "Which of the following is true about Prisma's `$disconnect()` method?",
    "options": [
      "It disconnects the database connection after operations",
      "It generates new migrations",
      "It deletes all records from a table",
      "It connects to the database"
    ],
    "answer": "It disconnects the database connection after operations",
    "explanation": "The `$disconnect()` method in Prisma ensures the database connection is closed after all operations are completed.",
    "tags": ["Prisma", "Database Connection", "Disconnect"]
  },
  {
    "question": "What does the MVC architecture stand for in web development?",
    "options": [
      "Model-View-Controller",
      "Middleware-Validation-Control",
      "Module-View-Component",
      "Model-Validation-Controller"
    ],
    "answer": "Model-View-Controller",
    "explanation": "MVC stands for Model-View-Controller, a design pattern that separates concerns into three components: Model (data and business logic), View (UI or responses), and Controller (handles requests and interacts with Models/Views).",
    "tags": ["MVC", "Architecture", "Express.js", "Koa.js"]
  },
  {
    "question": "Which component in MVC handles user requests and interacts with Models and Views?",
    "options": ["Model", "View", "Controller", "Router"],
    "answer": "Controller",
    "explanation": "The Controller in MVC handles user requests, processes them, and interacts with Models and Views to generate appropriate responses.",
    "tags": ["MVC", "Controller", "Express.js", "Koa.js"]
  },
  {
    "question": "What is the purpose of the Service Layer in an MVC application?",
    "options": [
      "To define routes and handle HTTP requests",
      "To encapsulate business logic and interact with Models",
      "To render HTML templates or JSON responses",
      "To configure middleware for request processing"
    ],
    "answer": "To encapsulate business logic and interact with Models",
    "explanation": "The Service Layer in MVC encapsulates business logic and provides an abstraction layer between Controllers and Models, improving code organization and testability.",
    "tags": ["MVC", "Service Layer", "Dependency Injection"]
  },
  {
    "question": "In Express.js, which module is commonly used for parsing JSON request bodies?",
    "options": [
      "koa-bodyparser",
      "body-parser",
      "express-bodyparser",
      "mongoose"
    ],
    "answer": "body-parser",
    "explanation": "In Express.js, the `body-parser` module is used to parse incoming request bodies in JSON format, making it easier to access data in route handlers.",
    "tags": ["Express.js", "Body Parsing", "Middleware"]
  },
  {
    "question": "In Koa.js, which module is used for parsing JSON request bodies?",
    "options": [
      "body-parser",
      "koa-bodyparser",
      "express-bodyparser",
      "mongoose"
    ],
    "answer": "koa-bodyparser",
    "explanation": "In Koa.js, the `koa-bodyparser` module is used to parse incoming request bodies in JSON format, enabling access to request data in middleware and controllers.",
    "tags": ["Koa.js", "Body Parsing", "Middleware"]
  },
  {
    "question": "Which of the following best describes Dependency Injection (DI) in the context of MVC?",
    "options": [
      "Injecting database queries directly into views",
      "Passing dependencies (e.g., services) to controllers for better modularity",
      "Using middleware to inject data into request objects",
      "Defining all dependencies globally in the server file"
    ],
    "answer": "Passing dependencies (e.g., services) to controllers for better modularity",
    "explanation": "Dependency Injection involves passing dependencies (like services or models) to controllers, promoting loose coupling, modularity, and easier testing.",
    "tags": ["Dependency Injection", "MVC", "Express.js", "Koa.js"]
  },
  {
    "question": "How do you define routes in Express.js?",
    "options": [
      "Using `app.use()`",
      "Using `router.get()` and `router.post()`",
      "Using `koa-router`",
      "Using `ctx.route()`"
    ],
    "answer": "Using `router.get()` and `router.post()`",
    "explanation": "In Express.js, routes are defined using methods like `router.get()` and `router.post()` within a Router instance, which can then be mounted on the app.",
    "tags": ["Express.js", "Routing", "MVC"]
  },
  {
    "question": "How do you define routes in Koa.js?",
    "options": [
      "Using `app.use()`",
      "Using `router.get()` and `router.post()` with `koa-router`",
      "Using `ctx.route()`",
      "Using `express.Router()`"
    ],
    "answer": "Using `router.get()` and `router.post()` with `koa-router`",
    "explanation": "Koa.js does not include built-in routing, so you must use the `koa-router` module and define routes using `router.get()` and `router.post()`.",
    "tags": ["Koa.js", "Routing", "MVC"]
  },
  {
    "question": "Which method is used to send JSON responses in Express.js?",
    "options": [
      "res.json()",
      "ctx.body = ...",
      "res.send()",
      "ctx.response(...)"
    ],
    "answer": "res.json()",
    "explanation": "In Express.js, the `res.json()` method is used to send JSON responses to clients.",
    "tags": ["Express.js", "JSON Response", "MVC"]
  },
  {
    "question": "Which property is used to send JSON responses in Koa.js?",
    "options": [
      "res.json()",
      "ctx.body = ...",
      "res.send()",
      "ctx.response(...)"
    ],
    "answer": "ctx.body = ...",
    "explanation": "In Koa.js, you set the response body using the `ctx.body` property, which can handle strings, JSON, or other data types.",
    "tags": ["Koa.js", "JSON Response", "MVC"]
  },
  {
    "question": "What is the primary difference between Express.js and Koa.js in terms of middleware?",
    "options": [
      "Express.js uses async/await, while Koa.js uses callbacks",
      "Express.js middleware is callback-based, while Koa.js middleware is async/await-based",
      "Express.js requires external modules for middleware, while Koa.js includes built-in middleware",
      "There is no difference; both frameworks use the same middleware system"
    ],
    "answer": "Express.js middleware is callback-based, while Koa.js middleware is async/await-based",
    "explanation": "Express.js middleware uses callback functions (`req, res, next`), while Koa.js middleware leverages async/await for better readability and error handling.",
    "tags": ["Express.js", "Koa.js", "Middleware", "Comparison"]
  },
  {
    "question": "Which module is required to implement routing in Koa.js?",
    "options": ["express.Router", "koa-router", "body-parser", "mongoose"],
    "answer": "koa-router",
    "explanation": "Koa.js does not include built-in routing, so you must install and use the `koa-router` module to define routes.",
    "tags": ["Koa.js", "Routing", "Modules"]
  },
  {
    "question": "What is the role of the Model in an MVC application?",
    "options": [
      "To handle user requests and generate responses",
      "To manage database interactions and business logic",
      "To render HTML templates or JSON responses",
      "To define middleware for request processing"
    ],
    "answer": "To manage database interactions and business logic",
    "explanation": "The Model in MVC is responsible for managing data and business logic, often interacting with databases or external APIs.",
    "tags": ["MVC", "Model", "Express.js", "Koa.js"]
  },
  {
    "question": "How do you connect to a MongoDB database in both Express.js and Koa.js?",
    "options": [
      "Using `mongoose.connect()`",
      "Using `db.connect()`",
      "Using `app.database()`",
      "Using `ctx.db()`"
    ],
    "answer": "Using `mongoose.connect()`",
    "explanation": "Both Express.js and Koa.js can use Mongoose's `mongoose.connect()` method to establish a connection to a MongoDB database.",
    "tags": ["Express.js", "Koa.js", "MongoDB", "Mongoose"]
  },
  {
    "question": "What is the advantage of using Dependency Injection in an MVC application?",
    "options": [
      "It simplifies the routing process",
      "It improves code maintainability and testability",
      "It eliminates the need for middleware",
      "It reduces the size of the application"
    ],
    "answer": "It improves code maintainability and testability",
    "explanation": "Dependency Injection promotes loose coupling by passing dependencies (like services or models) to controllers, making the code more modular, maintainable, and testable.",
    "tags": ["Dependency Injection", "MVC", "Express.js", "Koa.js"]
  },
  {
    "question": "Which of the following is true about error handling in Express.js and Koa.js?",
    "options": [
      "Express.js uses try-catch blocks, while Koa.js uses middleware-based error handling",
      "Koa.js uses try-catch blocks, while Express.js uses middleware-based error handling",
      "Both frameworks use the same error-handling mechanism",
      "Error handling is not supported in either framework"
    ],
    "answer": "Koa.js uses try-catch blocks, while Express.js uses middleware-based error handling",
    "explanation": "In Koa.js, errors are typically handled using try-catch blocks in middleware, while Express.js uses middleware-based error handling (e.g., `app.use((err, req, res, next) => {...})`).",
    "tags": ["Express.js", "Koa.js", "Error Handling", "Comparison"]
  },
  {
    "question": "What is the purpose of the `userService` in the given MVC example?",
    "options": [
      "To define routes for the application",
      "To encapsulate business logic and interact with the database",
      "To render HTML templates for the UI",
      "To configure middleware for request processing"
    ],
    "answer": "To encapsulate business logic and interact with the database",
    "explanation": "The `userService` encapsulates business logic and interacts with the database, abstracting these details from the controller layer.",
    "tags": ["MVC", "Service Layer", "Express.js", "Koa.js"]
  },
  {
    "question": "Which folder in the MVC structure contains files responsible for handling user requests?",
    "options": ["models", "views", "controllers", "routes"],
    "answer": "controllers",
    "explanation": "The `controllers` folder contains files responsible for handling user requests, processing data, and interacting with Models and Views.",
    "tags": ["MVC", "Folder Structure", "Controllers"]
  },
  {
    "question": "What is the main benefit of separating concerns using the MVC pattern?",
    "options": [
      "It makes the application faster",
      "It organizes code into distinct layers for better scalability and maintainability",
      "It eliminates the need for a database",
      "It reduces the number of dependencies in the application"
    ],
    "answer": "It organizes code into distinct layers for better scalability and maintainability",
    "explanation": "The MVC pattern separates concerns into Models, Views, and Controllers, making the application more organized, scalable, and maintainable.",
    "tags": ["MVC", "Scalability", "Maintainability"]
  },
  {
    "question": "Which of the following is true about `koa-bodyparser`?",
    "options": [
      "It is used for defining routes in Koa.js",
      "It parses incoming request bodies in Koa.js",
      "It generates JSON responses automatically",
      "It replaces the need for a service layer in Koa.js"
    ],
    "answer": "It parses incoming request bodies in Koa.js",
    "explanation": "The `koa-bodyparser` module is used to parse incoming request bodies in Koa.js, enabling access to JSON data in middleware and controllers.",
    "tags": ["Koa.js", "Body Parsing", "Middleware"]
  },
  {
    "question": "What is Express.js primarily used for in Node.js?",
    "options": [
      "Database management",
      "Building web applications and APIs",
      "Frontend UI development",
      "Image processing"
    ],
    "answer": "Building web applications and APIs",
    "explanation": "Express.js is a minimalist framework for Node.js that simplifies building web applications and APIs with features like routing, middleware, and error handling.",
    "tags": ["Node.js", "Express.js", "Web Framework"]
  },
  {
    "question": "Which method is used to define a GET route in Express.js?",
    "options": ["app.get()", "app.post()", "app.use()", "app.listen()"],
    "answer": "app.get()",
    "explanation": "The `app.get()` method in Express.js is used to define routes that handle HTTP GET requests.",
    "tags": ["Express.js", "Routing", "HTTP Methods"]
  },
  {
    "question": "What does middleware in Express.js do?",
    "options": [
      "Processes requests before sending responses",
      "Handles database queries exclusively",
      "Serves static files only",
      "Manages server configuration"
    ],
    "answer": "Processes requests before sending responses",
    "explanation": "Middleware functions in Express.js are used to process incoming requests, such as logging, authentication, or modifying request/response objects, before sending responses.",
    "tags": ["Express.js", "Middleware", "Request Processing"]
  },
  {
    "question": "How do you handle 404 errors in Express.js?",
    "options": [
      "Using `app.use()` after all routes",
      "Using `app.get('/')`",
      "Using `app.listen()`",
      "Using `app.error()`"
    ],
    "answer": "Using `app.use()` after all routes",
    "explanation": "To handle 404 errors in Express.js, you can use `app.use()` after defining all routes to catch unmatched requests and send a 'Page Not Found' response.",
    "tags": ["Express.js", "Error Handling", "404 Errors"]
  },
  {
    "question": "Which of the following is true about Koa.js?",
    "options": [
      "It uses callbacks instead of async/await",
      "It was developed by the same team that created Express.js",
      "It includes built-in routing",
      "It is not suitable for building APIs"
    ],
    "answer": "It was developed by the same team that created Express.js",
    "explanation": "Koa.js is a lightweight framework developed by the team behind Express.js, focusing on modern features like async/await for better readability and control.",
    "tags": ["Node.js", "Koa.js", "Framework"]
  },
  {
    "question": "How do you define middleware in Koa.js?",
    "options": [
      "Using `app.use((req, res, next) => {...})`",
      "Using `app.middleware()`",
      "Using `app.use(async (ctx, next) => {...})`",
      "Using `app.route()`"
    ],
    "answer": "Using `app.use(async (ctx, next) => {...})`",
    "explanation": "In Koa.js, middleware is defined using `app.use()` with an async function that takes `ctx` (context) and `next` as arguments.",
    "tags": ["Koa.js", "Middleware", "Async/Await"]
  },
  {
    "question": "Which module is required to add routing functionality in Koa.js?",
    "options": ["koa-router", "express-router", "koa-middleware", "koa-http"],
    "answer": "koa-router",
    "explanation": "Koa.js does not include built-in routing, so you must install and use the `koa-router` module to define routes.",
    "tags": ["Koa.js", "Routing", "Modules"]
  },
  {
    "question": "What is the primary difference between Express.js and Koa.js?",
    "options": [
      "Express.js uses async/await, while Koa.js uses callbacks",
      "Express.js has built-in routing, while Koa.js requires a separate router module",
      "Express.js is faster than Koa.js",
      "Express.js is asynchronous, while Koa.js is synchronous"
    ],
    "answer": "Express.js has built-in routing, while Koa.js requires a separate router module",
    "explanation": "While Express.js includes built-in routing, Koa.js requires you to use an external module like `koa-router` for defining routes.",
    "tags": ["Express.js", "Koa.js", "Comparison"]
  },
  {
    "question": "How do you start a Koa.js server on port 3000?",
    "options": [
      "app.listen(3000)",
      "server.start(3000)",
      "app.run(3000)",
      "koa.listen(3000)"
    ],
    "answer": "app.listen(3000)",
    "explanation": "In Koa.js, you start the server using the `app.listen(port)` method, similar to Express.js.",
    "tags": ["Koa.js", "Server Setup", "Port Configuration"]
  },
  {
    "question": "Which of the following best describes the context (`ctx`) object in Koa.js?",
    "options": [
      "It contains only the request data",
      "It combines both request and response objects into a single object",
      "It is used exclusively for error handling",
      "It is equivalent to `res` in Express.js"
    ],
    "answer": "It combines both request and response objects into a single object",
    "explanation": "In Koa.js, the `ctx` object encapsulates both the request (`ctx.request`) and response (`ctx.response`) objects, making it easier to access request and response properties.",
    "tags": ["Koa.js", "Context Object", "Request/Response"]
  },
  {
    "question": "How do you handle global errors in Koa.js?",
    "options": [
      "Using `app.use((err, req, res, next) => {...})`",
      "Using `try-catch` blocks in middleware",
      "Using `app.error()`",
      "Using `ctx.onerror()`"
    ],
    "answer": "Using `try-catch` blocks in middleware",
    "explanation": "In Koa.js, you wrap `await next()` in a `try-catch` block within middleware to handle errors globally and respond appropriately.",
    "tags": ["Koa.js", "Error Handling", "Global Errors"]
  },
  {
    "question": "Which of the following is a benefit of using Koa.js over Express.js?",
    "options": [
      "Koa.js is more feature-rich out of the box",
      "Koa.js uses async/await for better readability",
      "Koa.js includes built-in support for templating engines",
      "Koa.js is faster than Express.js"
    ],
    "answer": "Koa.js uses async/await for better readability",
    "explanation": "Koa.js leverages async/await for handling asynchronous operations, which improves code readability and avoids callback hell.",
    "tags": ["Koa.js", "Async/Await", "Readability"]
  },
  {
    "question": "What is the purpose of the `next()` function in Express.js middleware?",
    "options": [
      "To terminate the middleware chain",
      "To pass control to the next middleware in the chain",
      "To send a response to the client",
      "To log request details"
    ],
    "answer": "To pass control to the next middleware in the chain",
    "explanation": "The `next()` function in Express.js middleware is used to pass control to the next middleware in the chain, ensuring proper execution order.",
    "tags": ["Express.js", "Middleware", "Control Flow"]
  },
  {
    "question": "Which of the following is true about Express.js and Koa.js?",
    "options": [
      "Express.js supports async/await natively",
      "Koa.js uses callbacks for middleware",
      "Both frameworks require external modules for routing",
      "Koa.js is fully async/await-based, while Express.js uses callbacks"
    ],
    "answer": "Koa.js is fully async/await-based, while Express.js uses callbacks",
    "explanation": "Koa.js is designed to work with async/await for middleware and request handling, whereas Express.js traditionally uses callback-based middleware.",
    "tags": ["Express.js", "Koa.js", "Async/Await", "Callbacks"]
  },
  {
    "question": "How do you send JSON data as a response in Express.js?",
    "options": [
      "Using `res.json(data)`",
      "Using `res.send(data)`",
      "Using `ctx.body = data`",
      "Using `app.use(data)`"
    ],
    "answer": "Using `res.json(data)`",
    "explanation": "In Express.js, you can send JSON data as a response using the `res.json(data)` method.",
    "tags": ["Express.js", "JSON Response", "Response Handling"]
  },
  {
    "question": "How do you set the response body in Koa.js?",
    "options": [
      "Using `res.send()`",
      "Using `ctx.body = ...`",
      "Using `app.use(...)`",
      "Using `res.json()`"
    ],
    "answer": "Using `ctx.body = ...`",
    "explanation": "In Koa.js, you set the response body using the `ctx.body` property, which can handle strings, JSON, or other data types.",
    "tags": ["Koa.js", "Response Handling", "Context Object"]
  },
  {
    "question": "Which of the following is a key advantage of Express.js?",
    "options": [
      "It is fully async/await-based",
      "It provides built-in routing and middleware support",
      "It is lighter than Koa.js",
      "It does not require any external modules"
    ],
    "answer": "It provides built-in routing and middleware support",
    "explanation": "Express.js includes built-in routing and middleware support, making it easier to build web applications and APIs without additional dependencies.",
    "tags": ["Express.js", "Routing", "Middleware"]
  },
  {
    "question": "What is a Buffer in Node.js?",
    "options": [
      "A temporary memory space for holding binary data.",
      "A module for creating HTTP servers.",
      "A tool for compressing files.",
      "A method for reading files synchronously."
    ],
    "answer": "A temporary memory space for holding binary data.",
    "explanation": "A Buffer in Node.js is a temporary memory space used to hold binary data before it is processed or written to a file or network.",
    "tags": ["Node.js", "Buffers", "Binary Data"]
  },
  {
    "question": "Which method is used to create a Buffer from a string in Node.js?",
    "options": [
      "Buffer.create()",
      "Buffer.from()",
      "Buffer.write()",
      "Buffer.read()"
    ],
    "answer": "Buffer.from()",
    "explanation": "The `Buffer.from()` method is used to create a Buffer instance from various sources, including strings, arrays, or other Buffers.",
    "tags": ["Node.js", "Buffers", "Buffer Creation"]
  },
  {
    "question": "What is the primary advantage of using Streams over loading entire files into memory?",
    "options": [
      "Streams allow processing data in chunks, saving memory.",
      "Streams are slower but more secure.",
      "Streams can only handle text data, not binary data.",
      "Streams require additional libraries for file operations."
    ],
    "answer": "Streams allow processing data in chunks, saving memory.",
    "explanation": "Streams process data in smaller chunks, making them ideal for handling large files or network data without consuming excessive memory.",
    "tags": ["Node.js", "Streams", "Memory Efficiency"]
  },
  {
    "question": "Which type of Stream is used for reading data in Node.js?",
    "options": ["Writable", "Readable", "Duplex", "Transform"],
    "answer": "Readable",
    "explanation": "A Readable Stream is used to read data from a source, such as a file or network request, in chunks.",
    "tags": ["Node.js", "Streams", "Readable Streams"]
  },
  {
    "question": "What is the purpose of the `pipe()` method in Node.js Streams?",
    "options": [
      "To manually process each chunk of data.",
      "To directly transfer data between streams without manual handling.",
      "To encrypt data while transferring.",
      "To pause and resume stream operations."
    ],
    "answer": "To directly transfer data between streams without manual handling.",
    "explanation": "The `pipe()` method connects a Readable Stream to a Writable Stream, allowing data to flow between them without manual intervention.",
    "tags": ["Node.js", "Streams", "Piping"]
  },
  {
    "question": "Which of the following is an example of a Duplex Stream in Node.js?",
    "options": [
      "fs.createReadStream",
      "fs.createWriteStream",
      "net.Socket",
      "zlib.createGzip"
    ],
    "answer": "net.Socket",
    "explanation": "A Duplex Stream is both readable and writable, such as a `net.Socket` used for network communication.",
    "tags": ["Node.js", "Streams", "Duplex Streams"]
  },
  {
    "question": "How do you write data to a file using a Writable Stream?",
    "options": [
      "Using the `write()` method followed by `end()`.",
      "Using the `read()` method.",
      "Using the `pipe()` method.",
      "Using the `createBuffer()` method."
    ],
    "answer": "Using the `write()` method followed by `end()`.",
    "explanation": "To write data to a file using a Writable Stream, use the `write()` method to send data and `end()` to close the stream after writing.",
    "tags": ["Node.js", "Streams", "Writable Streams"]
  },
  {
    "question": "Which module in Node.js provides functionality for compressing data using Streams?",
    "options": ["fs", "path", "zlib", "crypto"],
    "answer": "zlib",
    "explanation": "The `zlib` module in Node.js provides methods for compression and decompression, such as `createGzip` and `createGunzip`, which can be used with Streams.",
    "tags": ["Node.js", "Streams", "Compression", "zlib"]
  },
  {
    "question": "What does the `on('data', callback)` event do in a Readable Stream?",
    "options": [
      "It triggers when the stream ends.",
      "It emits each chunk of data as it is read.",
      "It handles errors during stream operations.",
      "It writes data to the stream."
    ],
    "answer": "It emits each chunk of data as it is read.",
    "explanation": "The `on('data', callback)` event in a Readable Stream emits each chunk of data as it is read from the source.",
    "tags": ["Node.js", "Streams", "Readable Streams"]
  },
  {
    "question": "Which method is used to convert a Buffer to a hexadecimal string?",
    "options": ["toString('hex')", "toJSON()", "toBuffer()", "toHex()"],
    "answer": "toString('hex')",
    "explanation": "The `toString('hex')` method converts a Buffer to a hexadecimal string representation, which is useful for debugging or encoding binary data.",
    "tags": ["Node.js", "Buffers", "Encoding"]
  },
  {
    "question": "What is the purpose of Transform Streams in Node.js?",
    "options": [
      "To read data from a source.",
      "To modify data while it is being streamed.",
      "To write data to a destination.",
      "To pause and resume stream operations."
    ],
    "answer": "To modify data while it is being streamed.",
    "explanation": "Transform Streams allow you to modify or transform data while it is being streamed, such as compressing or encrypting data on the fly.",
    "tags": ["Node.js", "Streams", "Transform Streams"]
  },
  {
    "question": "Which of the following best describes the difference between Buffers and Streams?",
    "options": [
      "Buffers handle small amounts of binary data, while Streams handle large continuous data flows.",
      "Buffers are used for encryption, while Streams are used for file reading.",
      "Buffers store data permanently, while Streams discard data after processing.",
      "There is no difference; they are interchangeable."
    ],
    "answer": "Buffers handle small amounts of binary data, while Streams handle large continuous data flows.",
    "explanation": "Buffers are used for storing and manipulating small binary data, while Streams are designed for efficiently handling large continuous flows of data, such as files or network requests.",
    "tags": ["Node.js", "Buffers", "Streams", "Comparison"]
  },
  {
    "question": "What happens when the `end` event is emitted in a Readable Stream?",
    "options": [
      "The stream starts reading data.",
      "The stream has finished reading all data.",
      "An error occurred during stream processing.",
      "The stream begins writing data."
    ],
    "answer": "The stream has finished reading all data.",
    "explanation": "The `end` event in a Readable Stream is emitted when there is no more data to read, indicating that the stream has completed its operation.",
    "tags": ["Node.js", "Streams", "Readable Streams"]
  },
  {
    "question": "Which of the following is true about piping streams in Node.js?",
    "options": [
      "Piping requires manual handling of each data chunk.",
      "Piping allows direct data transfer between streams without buffering the entire data.",
      "Piping is only used for file operations.",
      "Piping cannot be used with Transform Streams."
    ],
    "answer": "Piping allows direct data transfer between streams without buffering the entire data.",
    "explanation": "Piping connects a Readable Stream to a Writable Stream, enabling efficient data transfer without buffering the entire data in memory.",
    "tags": ["Node.js", "Streams", "Piping"]
  },
  {
    "question": "What is the purpose of the `zlib.createGzip()` method in Node.js?",
    "options": [
      "To create a new file system stream.",
      "To compress data using the Gzip algorithm.",
      "To encrypt data using cryptographic algorithms.",
      "To generate random binary data."
    ],
    "answer": "To compress data using the Gzip algorithm.",
    "explanation": "The `zlib.createGzip()` method creates a Transform Stream that compresses data using the Gzip algorithm, often used for file compression.",
    "tags": ["Node.js", "Streams", "Compression", "zlib"]
  },
  {
    "question": "Which of the following is a benefit of using Streams for file operations?",
    "options": [
      "They load the entire file into memory for faster processing.",
      "They allow processing large files efficiently by handling data in chunks.",
      "They require less code compared to traditional file I/O methods.",
      "They are only suitable for text-based files, not binary files."
    ],
    "answer": "They allow processing large files efficiently by handling data in chunks.",
    "explanation": "Streams enable efficient handling of large files by processing data in smaller chunks, reducing memory usage and improving performance.",
    "tags": ["Node.js", "Streams", "File Operations"]
  },
  {
    "question": "Which Node.js core module is used for reading and writing files?",
    "options": ["path", "fs", "http", "crypto"],
    "answer": "fs",
    "explanation": "The `fs` (File System) module in Node.js provides methods for interacting with the file system, including reading, writing, and manipulating files.",
    "tags": ["Node.js", "Core Modules", "fs"]
  },
  {
    "question": "What is the difference between `fs.readFileSync` and `fs.readFile`?",
    "options": [
      "`fs.readFileSync` is asynchronous, while `fs.readFile` is synchronous.",
      "`fs.readFileSync` blocks the execution, while `fs.readFile` does not.",
      "`fs.readFileSync` is deprecated, while `fs.readFile` is the recommended method.",
      "There is no difference; both methods are identical."
    ],
    "answer": "`fs.readFileSync` blocks the execution, while `fs.readFile` does not.",
    "explanation": "`fs.readFileSync` performs a blocking (synchronous) file read, while `fs.readFile` is non-blocking (asynchronous), allowing other tasks to run while waiting for the operation to complete.",
    "tags": ["Node.js", "fs", "Synchronous vs Asynchronous"]
  },
  {
    "question": "Which Node.js core module is used for handling file paths across different operating systems?",
    "options": ["fs", "path", "os", "url"],
    "answer": "path",
    "explanation": "The `path` module in Node.js provides utilities for working with file and directory paths, ensuring compatibility across different operating systems.",
    "tags": ["Node.js", "Core Modules", "path"]
  },
  {
    "question": "What does the `path.resolve` method do?",
    "options": [
      "It resolves relative paths to absolute paths.",
      "It concatenates multiple path segments.",
      "It retrieves the file extension from a path.",
      "It checks if a path exists on the file system."
    ],
    "answer": "It resolves relative paths to absolute paths.",
    "explanation": "The `path.resolve` method constructs an absolute path from one or more path segments, resolving any relative paths in the process.",
    "tags": ["Node.js", "path", "Path Resolution"]
  },
  {
    "question": "Which Node.js core module is used for creating HTTP servers?",
    "options": ["fs", "path", "http", "net"],
    "answer": "http",
    "explanation": "The `http` module in Node.js allows you to create HTTP servers and clients without relying on external libraries.",
    "tags": ["Node.js", "Core Modules", "http"]
  },
  {
    "question": "What is the purpose of streams in Node.js?",
    "options": [
      "To handle large amounts of data efficiently.",
      "To encrypt and decrypt data.",
      "To manage file system permissions.",
      "To resolve file paths."
    ],
    "answer": "To handle large amounts of data efficiently.",
    "explanation": "Streams in Node.js allow you to process large amounts of data in chunks, making them memory-efficient compared to loading entire files into memory at once.",
    "tags": ["Node.js", "Core Modules", "stream"]
  },
  {
    "question": "Which method is used to create a readable stream for a file in Node.js?",
    "options": [
      "fs.createReadStream",
      "fs.readStream",
      "fs.readFile",
      "fs.openStream"
    ],
    "answer": "fs.createReadStream",
    "explanation": "The `fs.createReadStream` method creates a readable stream for a file, allowing you to process its contents in chunks.",
    "tags": ["Node.js", "fs", "stream"]
  },
  {
    "question": "Which Node.js core module is used for hashing and encryption?",
    "options": ["stream", "crypto", "fs", "path"],
    "answer": "crypto",
    "explanation": "The `crypto` module in Node.js provides cryptographic functions, including hashing, encryption, and decryption.",
    "tags": ["Node.js", "Core Modules", "crypto"]
  },
  {
    "question": "What is the purpose of the `crypto.createHash` method?",
    "options": [
      "To encrypt data using symmetric keys.",
      "To generate a hash value for a given input.",
      "To decrypt data using asymmetric keys.",
      "To verify digital signatures."
    ],
    "answer": "To generate a hash value for a given input.",
    "explanation": "The `crypto.createHash` method generates a hash value for a given input using algorithms like SHA-256, MD5, etc., which is useful for securely storing passwords or verifying data integrity.",
    "tags": ["Node.js", "crypto", "Hashing"]
  },
  {
    "question": "Which of the following is true about the `http` module in Node.js?",
    "options": [
      "It requires external dependencies to create HTTP servers.",
      "It is used exclusively for client-side HTTP requests.",
      "It allows creating both HTTP servers and clients without external libraries.",
      "It cannot handle HTTPS traffic."
    ],
    "answer": "It allows creating both HTTP servers and clients without external libraries.",
    "explanation": "The `http` module in Node.js provides built-in functionality for creating both HTTP servers and clients, eliminating the need for external dependencies.",
    "tags": ["Node.js", "http", "HTTP Servers"]
  },
  {
    "question": "What is the output of `path.basename('/home/user/project/index.js')`?",
    "options": ["/home/user/project", "index.js", ".js", "project"],
    "answer": "index.js",
    "explanation": "The `path.basename` method extracts the last portion of a path, which in this case is the filename `index.js`.",
    "tags": ["Node.js", "path", "Path Manipulation"]
  },
  {
    "question": "Which of the following is a benefit of using streams over `fs.readFile` for large files?",
    "options": [
      "Streams require less code to implement.",
      "Streams are more memory-efficient for large files.",
      "Streams can only read text files.",
      "Streams block the event loop during file operations."
    ],
    "answer": "Streams are more memory-efficient for large files.",
    "explanation": "Streams process data in chunks, making them more memory-efficient for handling large files compared to loading the entire file into memory using `fs.readFile`.",
    "tags": ["Node.js", "stream", "Memory Efficiency"]
  },
  {
    "question": "Which algorithm is commonly used for generating secure hashes in the `crypto` module?",
    "options": ["SHA-256", "Base64", "UTF-8", "JSON.stringify"],
    "answer": "SHA-256",
    "explanation": "The `crypto` module supports various hashing algorithms, with SHA-256 being a widely used and secure choice for generating hash values.",
    "tags": ["Node.js", "crypto", "Hashing"]
  },
  {
    "question": "What is the purpose of the `path.extname` method?",
    "options": [
      "To retrieve the file extension from a path.",
      "To resolve relative paths to absolute paths.",
      "To check if a file exists on the file system.",
      "To create a new file path."
    ],
    "answer": "To retrieve the file extension from a path.",
    "explanation": "The `path.extname` method extracts the extension of a file from a given path, such as `.js` from `index.js`.",
    "tags": ["Node.js", "path", "Path Manipulation"]
  },
  {
    "question": "Which of the following statements is true about the `http` module?",
    "options": [
      "It only supports HTTP/1.1 and not HTTP/2.",
      "It can handle WebSocket connections natively.",
      "It allows creating both HTTP and HTTPS servers.",
      "It requires additional libraries for handling POST requests."
    ],
    "answer": "It allows creating both HTTP and HTTPS servers.",
    "explanation": "The `http` module in Node.js can be used to create both HTTP and HTTPS servers by leveraging the `https` module for secure connections.",
    "tags": ["Node.js", "http", "HTTP Servers"]
  },
  {
    "question": "Which core module would you use to securely store user passwords?",
    "options": ["fs", "path", "crypto", "stream"],
    "answer": "crypto",
    "explanation": "The `crypto` module provides hashing functions like SHA-256, which are ideal for securely storing user passwords by generating hash values instead of storing plain text.",
    "tags": ["Node.js", "crypto", "Password Hashing"]
  },
  {
    "question": "What is the primary advantage of Node.js's event-driven architecture?",
    "options": [
      "It allows synchronous code execution.",
      "It enables efficient handling of multiple connections and events.",
      "It requires blocking I/O operations for file reading.",
      "It uses a multi-threaded model for concurrency."
    ],
    "answer": "It enables efficient handling of multiple connections and events.",
    "explanation": "Node.js's event-driven architecture uses an EventEmitter to handle events efficiently, making it ideal for applications like WebSockets and real-time systems.",
    "tags": ["Node.js", "Event-Driven Architecture", "Concurrency"]
  },
  {
    "question": "Which class in Node.js is used to implement event-driven programming?",
    "options": ["Worker", "Stream", "EventEmitter", "Buffer"],
    "answer": "EventEmitter",
    "explanation": "The `EventEmitter` class in Node.js is used to create objects that can emit and listen for events, enabling event-driven programming.",
    "tags": ["Node.js", "EventEmitter", "Event-Driven Programming"]
  },
  {
    "question": "What does non-blocking I/O in Node.js mean?",
    "options": [
      "Operations block the main thread until completion.",
      "Operations continue running while waiting for I/O tasks to complete.",
      "All I/O operations are performed synchronously.",
      "Node.js uses multiple threads for each I/O operation."
    ],
    "answer": "Operations continue running while waiting for I/O tasks to complete.",
    "explanation": "Non-blocking I/O allows Node.js to perform other tasks while waiting for I/O-bound operations (e.g., file reads or database queries) to complete.",
    "tags": ["Node.js", "Non-Blocking I/O", "Concurrency"]
  },
  {
    "question": "Which of the following demonstrates a blocking (synchronous) file read in Node.js?",
    "options": [
      "fs.readFile('file.txt', 'utf8', callback);",
      "fs.readFileSync('file.txt', 'utf8');",
      "Promise.resolve().then(() => {});",
      "setTimeout(() => {}, 0);"
    ],
    "answer": "fs.readFileSync('file.txt', 'utf8');",
    "explanation": "The `fs.readFileSync` method blocks the execution of subsequent code until the file reading operation completes, making it synchronous.",
    "tags": ["Node.js", "Blocking I/O", "File System"]
  },
  {
    "question": "Which of the following demonstrates a non-blocking (asynchronous) file read in Node.js?",
    "options": [
      "fs.readFileSync('file.txt', 'utf8');",
      "fs.readFile('file.txt', 'utf8', callback);",
      "console.log('Sync Code');",
      "process.nextTick(() => {});"
    ],
    "answer": "fs.readFile('file.txt', 'utf8', callback);",
    "explanation": "The `fs.readFile` method performs a non-blocking file read, allowing other code to execute while waiting for the operation to complete.",
    "tags": ["Node.js", "Non-Blocking I/O", "File System"]
  },
  {
    "question": "In the Node.js event loop, which type of task runs first?",
    "options": [
      "Macrotasks (e.g., setTimeout)",
      "Microtasks (e.g., Promises)",
      "Both run simultaneously.",
      "The order depends on the task duration."
    ],
    "answer": "Microtasks (e.g., Promises)",
    "explanation": "In the Node.js event loop, microtasks (e.g., Promises) are executed before macrotasks (e.g., setTimeout), ensuring async tasks are handled efficiently.",
    "tags": ["Node.js", "Event Loop", "Concurrency"]
  },
  {
    "question": "What happens when the following code is executed in Node.js?",
    "options": [
      "Start  End  Promise  Timeout",
      "Start  End  Timeout  Promise",
      "End  Start  Promise  Timeout",
      "Start  Promise  End  Timeout"
    ],
    "answer": "Start  End  Promise  Timeout",
    "explanation": "Synchronous code (`Start` and `End`) runs first, followed by microtasks (Promises), and finally macrotasks (setTimeout).",
    "tags": ["Node.js", "Event Loop", "Code Execution Order"]
  },
  {
    "question": "Which component in Node.js processes tasks asynchronously?",
    "options": ["Call Stack", "Event Queue", "Worker Threads", "Global Object"],
    "answer": "Event Queue",
    "explanation": "The Event Queue in Node.js holds asynchronous tasks (e.g., callbacks from setTimeout or Promises) and executes them once the Call Stack is empty.",
    "tags": ["Node.js", "Event Loop", "Concurrency"]
  },
  {
    "question": "What is the purpose of Worker Threads in Node.js?",
    "options": [
      "To handle synchronous tasks exclusively.",
      "To manage the Event Queue and Call Stack.",
      "To offload CPU-intensive tasks from the main thread.",
      "To replace the EventEmitter class."
    ],
    "answer": "To offload CPU-intensive tasks from the main thread.",
    "explanation": "Worker Threads in Node.js allow CPU-heavy operations to be offloaded from the main thread, preventing blocking of the event loop.",
    "tags": ["Node.js", "Worker Threads", "Concurrency"]
  },
  {
    "question": "Which of the following best describes the Node.js Event Loop?",
    "options": [
      "A mechanism to process synchronous tasks sequentially.",
      "A loop that waits for all I/O operations to complete before executing any code.",
      "A single-threaded loop that handles asynchronous tasks without blocking the main thread.",
      "A multi-threaded system for parallel execution of tasks."
    ],
    "answer": "A single-threaded loop that handles asynchronous tasks without blocking the main thread.",
    "explanation": "The Node.js Event Loop is a single-threaded mechanism that processes asynchronous tasks efficiently, ensuring non-blocking behavior.",
    "tags": ["Node.js", "Event Loop", "Concurrency"]
  },
  {
    "question": "Why is Node.js well-suited for real-time applications like chat apps or live updates?",
    "options": [
      "Because it uses a multi-threaded model for handling requests.",
      "Because it supports event-driven architecture and non-blocking I/O.",
      "Because it relies on blocking I/O for better performance.",
      "Because it requires heavy computational resources for each connection."
    ],
    "answer": "Because it supports event-driven architecture and non-blocking I/O.",
    "explanation": "Node.js's event-driven architecture and non-blocking I/O make it highly efficient for handling multiple concurrent connections, making it ideal for real-time applications.",
    "tags": ["Node.js", "Real-Time Applications", "Event-Driven Architecture"]
  },
  {
    "question": "Which of the following statements is true about the Node.js event loop?",
    "options": [
      "It processes only one task at a time in the Call Stack.",
      "It can process multiple tasks simultaneously using multi-threading.",
      "It prioritizes synchronous tasks over asynchronous tasks.",
      "It blocks the main thread during I/O operations."
    ],
    "answer": "It processes only one task at a time in the Call Stack.",
    "explanation": "The Node.js event loop processes tasks sequentially in the Call Stack, but it handles asynchronous tasks efficiently using the Event Queue and Worker Threads.",
    "tags": ["Node.js", "Event Loop", "Concurrency"]
  },
  {
    "question": "What is the output of the following Node.js code?",
    "options": [
      "Start  End  Timeout",
      "Start  Timeout  End",
      "Timeout  Start  End",
      "End  Start  Timeout"
    ],
    "answer": "Start  End  Timeout",
    "explanation": "Synchronous code (`Start` and `End`) runs first, followed by macrotasks like `setTimeout`. The output will be: Start  End  Timeout.",
    "tags": ["Node.js", "Event Loop", "Code Execution Order"]
  },
  {
    "question": "What is the primary purpose of unit testing in software development?",
    "options": [
      "To test the entire application flow in a real browser.",
      "To ensure individual units of code (e.g., functions) work as expected.",
      "To verify user interactions with the UI.",
      "To automate deployment processes."
    ],
    "answer": "To ensure individual units of code (e.g., functions) work as expected.",
    "explanation": "Unit testing focuses on verifying that small, isolated units of code (like functions or methods) behave correctly under various conditions.",
    "tags": ["Testing", "Jest", "Unit Testing"]
  },
  {
    "question": "Which testing framework is best suited for unit testing JavaScript functions and logic?",
    "options": ["Cypress", "React Testing Library", "Jest", "Selenium"],
    "answer": "Jest",
    "explanation": "Jest is a popular JavaScript testing framework ideal for unit testing functions, logic, and components due to its fast execution and built-in features like mocking and snapshots.",
    "tags": ["Jest", "Unit Testing", "JavaScript"]
  },
  {
    "question": "What does the `expect` function in Jest do?",
    "options": [
      "Renders a React component for testing.",
      "Simulates user interactions with the UI.",
      "Asserts that a condition or value matches expectations.",
      "Starts the test runner."
    ],
    "answer": "Asserts that a condition or value matches expectations.",
    "explanation": "The `expect` function in Jest is used to make assertions about the output or behavior of the code being tested, ensuring it meets the expected criteria.",
    "tags": ["Jest", "Assertions", "Unit Testing"]
  },
  {
    "question": "Which library is best suited for testing React components' behavior and user interactions?",
    "options": ["Jest", "React Testing Library", "Cypress", "Mocha"],
    "answer": "React Testing Library",
    "explanation": "React Testing Library focuses on testing user interactions and component behavior in React applications, making it ideal for component-level testing.",
    "tags": ["React Testing Library", "Component Testing", "UI Behavior"]
  },
  {
    "question": "What is the purpose of `fireEvent` in React Testing Library?",
    "options": [
      "To render a React component.",
      "To simulate user actions like clicks or key presses.",
      "To mock API responses.",
      "To validate CSS styles."
    ],
    "answer": "To simulate user actions like clicks or key presses.",
    "explanation": "The `fireEvent` utility in React Testing Library simulates user interactions (e.g., clicks, input changes) to test how components respond to these events.",
    "tags": ["React Testing Library", "User Interactions", "Event Simulation"]
  },
  {
    "question": "Which tool is best suited for end-to-end (E2E) testing of web applications?",
    "options": ["Jest", "React Testing Library", "Cypress", "Enzyme"],
    "answer": "Cypress",
    "explanation": "Cypress is designed for end-to-end testing, allowing you to test full user journeys in a real browser environment, including navigation, form submissions, and API interactions.",
    "tags": ["Cypress", "E2E Testing", "Browser Automation"]
  },
  {
    "question": "What is the main advantage of using Cypress over Jest for testing?",
    "options": [
      "Faster test execution for small units of code.",
      "Ability to test full user flows in a real browser.",
      "Support for mocking and snapshots.",
      "Focus on testing React components only."
    ],
    "answer": "Ability to test full user flows in a real browser.",
    "explanation": "Cypress excels at testing end-to-end user flows in a real browser, while Jest is better suited for unit testing and isolated component testing.",
    "tags": ["Cypress", "E2E Testing", "Browser Automation"]
  },
  {
    "question": "Which method is used to render a React component in React Testing Library?",
    "options": ["render()", "visit()", "simulate()", "test()"],
    "answer": "render()",
    "explanation": "The `render()` function in React Testing Library is used to mount and render a React component for testing its behavior and interactions.",
    "tags": ["React Testing Library", "Rendering", "Component Testing"]
  },
  {
    "question": "What is the purpose of `cy.visit()` in Cypress?",
    "options": [
      "To render a React component.",
      "To navigate to a specific URL in the browser.",
      "To simulate user input events.",
      "To mock API responses."
    ],
    "answer": "To navigate to a specific URL in the browser.",
    "explanation": "The `cy.visit()` command in Cypress navigates to a specified URL in the browser, allowing you to test the application's behavior from a user's perspective.",
    "tags": ["Cypress", "E2E Testing", "Navigation"]
  },
  {
    "question": "Which of the following is true about Jest's snapshot testing?",
    "options": [
      "It verifies the visual appearance of a UI component.",
      "It compares the current output of a function or component with a previously saved snapshot.",
      "It tests the performance of an application.",
      "It automates browser interactions."
    ],
    "answer": "It compares the current output of a function or component with a previously saved snapshot.",
    "explanation": "Jest's snapshot testing captures the output of a function or component and compares it to a previously saved snapshot, ensuring consistency across test runs.",
    "tags": ["Jest", "Snapshot Testing", "Consistency"]
  },
  {
    "question": "Which of the following is a benefit of using React Testing Library over traditional enzyme-based testing?",
    "options": [
      "It focuses on implementation details rather than user interactions.",
      "It provides better support for legacy React components.",
      "It encourages testing user-facing behavior rather than internal implementation.",
      "It requires more setup and configuration."
    ],
    "answer": "It encourages testing user-facing behavior rather than internal implementation.",
    "explanation": "React Testing Library emphasizes testing components based on their visible behavior and user interactions, avoiding reliance on internal implementation details.",
    "tags": ["React Testing Library", "Behavior Testing", "User Focus"]
  },
  {
    "question": "What is the main difference between Jest and Cypress?",
    "options": [
      "Jest is used for E2E testing, while Cypress is for unit testing.",
      "Jest is faster but less reliable, while Cypress is slower but more robust.",
      "Jest focuses on unit and integration testing, while Cypress is designed for E2E testing.",
      "Jest requires a real browser, while Cypress runs in a headless environment."
    ],
    "answer": "Jest focuses on unit and integration testing, while Cypress is designed for E2E testing.",
    "explanation": "Jest is primarily used for unit and integration testing, while Cypress is specifically designed for end-to-end testing in a real browser environment.",
    "tags": ["Jest", "Cypress", "Comparison", "Testing Types"]
  },
  {
    "question": "Which library would you choose for testing a login form's user interactions?",
    "options": ["Jest", "React Testing Library", "Cypress", "All of the above"],
    "answer": "React Testing Library",
    "explanation": "React Testing Library is ideal for testing user interactions with components like forms, buttons, and modals, as it focuses on how users interact with the UI.",
    "tags": ["React Testing Library", "Form Testing", "User Interactions"]
  },
  {
    "question": "What is Framer Motion primarily used for in React and Next.js?",
    "options": [
      "State management",
      "Routing and navigation",
      "Animations and gestures",
      "Form handling"
    ],
    "answer": "Animations and gestures",
    "explanation": "Framer Motion is a powerful animation library for React and Next.js, providing tools for creating declarative animations, gestures, and interactive components.",
    "tags": ["Framer Motion", "React", "Animations"]
  },
  {
    "question": "Which method is used to install Framer Motion in a project?",
    "options": [
      "npm install react-motion",
      "npm install framer-motion",
      "npm install motion-framer",
      "npm install @framer/motion"
    ],
    "answer": "npm install framer-motion",
    "explanation": "To use Framer Motion in your project, you can install it using `npm install framer-motion`.",
    "tags": ["Framer Motion", "Installation", "React"]
  },
  {
    "question": "Which property is used to add hover effects in Framer Motion?",
    "options": ["onHover", "hoverEffect", "whileHover", "onMouseEnter"],
    "answer": "whileHover",
    "explanation": "The `whileHover` property in Framer Motion allows you to define animations or styles that are applied when the user hovers over an element.",
    "tags": ["Framer Motion", "Hover Effects", "Animations"]
  },
  {
    "question": "What is the purpose of variants in Framer Motion?",
    "options": [
      "To define reusable animation states and transitions.",
      "To manage state in functional components.",
      "To handle form submissions.",
      "To optimize performance of SVG animations."
    ],
    "answer": "To define reusable animation states and transitions.",
    "explanation": "Variants in Framer Motion allow you to define reusable animation states (e.g., hidden, visible) and apply them to components with properties like `initial`, `animate`, and `exit`.",
    "tags": ["Framer Motion", "Variants", "Reusable Animations"]
  },
  {
    "question": "Which property enables drag functionality in Framer Motion?",
    "options": ["draggable", "drag", "onDrag", "useGesture"],
    "answer": "drag",
    "explanation": "The `drag` property in Framer Motion enables draggable UI elements, allowing users to interactively move components on the screen.",
    "tags": ["Framer Motion", "Gestures", "Draggable Elements"]
  },
  {
    "question": "How do you trigger animations when an element comes into the viewport in Framer Motion?",
    "options": [
      "using the `onScroll` property",
      "using the `whileInView` property",
      "using the `scrollAnimation` property",
      "using the `viewportAnimation` property"
    ],
    "answer": "using the `whileInView` property",
    "explanation": "The `whileInView` property in Framer Motion triggers animations when an element enters the viewport, making it ideal for scroll-based animations.",
    "tags": ["Framer Motion", "Scroll Animations", "Viewport"]
  },
  {
    "question": "Which of the following is true about Framer Motion's performance?",
    "options": [
      "It is not optimized for React applications.",
      "It provides layout animations for smooth transitions.",
      "It requires manual optimization for every animation.",
      "It only supports basic animations like fade-in and fade-out."
    ],
    "answer": "It provides layout animations for smooth transitions.",
    "explanation": "Framer Motion includes layout animations, which ensure smooth transitions when elements change size, position, or layout without requiring manual optimization.",
    "tags": ["Framer Motion", "Performance", "Layout Animations"]
  },
  {
    "question": "What does the `transition` property in Framer Motion control?",
    "options": [
      "The initial state of the animation.",
      "The duration and easing of the animation.",
      "The final state of the animation.",
      "The number of times the animation repeats."
    ],
    "answer": "The duration and easing of the animation.",
    "explanation": "The `transition` property in Framer Motion allows you to customize the duration, easing, and other properties of an animation, giving fine-grained control over its behavior.",
    "tags": ["Framer Motion", "Transitions", "Animation Control"]
  },
  {
    "question": "Which feature makes Framer Motion ideal for SVG animations?",
    "options": [
      "Support for keyframes and path animations.",
      "Built-in drag-and-drop functionality.",
      "Automatic state management.",
      "Predefined utility classes for styling."
    ],
    "answer": "Support for keyframes and path animations.",
    "explanation": "Framer Motion fully supports SVG animations, including keyframes and path animations, making it versatile for complex visual designs.",
    "tags": ["Framer Motion", "SVG Animations", "Keyframes"]
  },
  {
    "question": "Which property ensures that scroll-based animations trigger only once?",
    "options": [
      "once: true",
      "repeat: false",
      "loop: false",
      "scrollOnce: true"
    ],
    "answer": "once: true",
    "explanation": "In Framer Motion, the `viewport` property with `once: true` ensures that scroll-based animations trigger only once when the element comes into view.",
    "tags": ["Framer Motion", "Scroll Animations", "Viewport"]
  },
  {
    "question": "What is the main advantage of using Framer Motion over traditional CSS animations?",
    "options": [
      "It eliminates the need for JavaScript.",
      "It provides a declarative API for animations in React.",
      "It only supports global animations.",
      "It requires writing custom CSS for every animation."
    ],
    "answer": "It provides a declarative API for animations in React.",
    "explanation": "Framer Motion offers a declarative API for creating animations directly in React components, simplifying the process compared to traditional CSS animations.",
    "tags": ["Framer Motion", "Declarative API", "React Animations"]
  },
  {
    "question": "What is NextAuth.js primarily used for in Next.js?",
    "options": [
      "Real-time database management.",
      "Authentication and authorization with OAuth providers.",
      "User interface design.",
      "Mobile app development."
    ],
    "answer": "Authentication and authorization with OAuth providers.",
    "explanation": "NextAuth.js is a built-in authentication solution for Next.js that supports OAuth, JWT, and database authentication, making it ideal for handling logins via providers like Google, GitHub, and more.",
    "tags": ["Next.js", "Authentication", "NextAuth.js"]
  },
  {
    "question": "Which method is used to sign in with GitHub using NextAuth.js?",
    "options": [
      "useSession",
      "signIn('github')",
      "signOut",
      "GoogleAuthProvider"
    ],
    "answer": "signIn('github')",
    "explanation": "The `signIn('github')` method from NextAuth.js allows users to authenticate using their GitHub accounts via OAuth.",
    "tags": ["Next.js", "NextAuth.js", "OAuth"]
  },
  {
    "question": "What does Clerk provide in addition to authentication?",
    "options": [
      "Real-time database services.",
      "Pre-built UI components for login/signup.",
      "Mobile app development tools.",
      "Serverless functions."
    ],
    "answer": "Pre-built UI components for login/signup.",
    "explanation": "Clerk offers fully managed authentication along with pre-built UI components for login, signup, and user management, simplifying the development process.",
    "tags": ["Next.js", "Authentication", "Clerk"]
  },
  {
    "question": "Which of the following is true about Firebase Authentication?",
    "options": [
      "It only supports email/password authentication.",
      "It provides real-time database services alongside authentication.",
      "It requires manual setup for OAuth providers.",
      "It is not suitable for mobile applications."
    ],
    "answer": "It provides real-time database services alongside authentication.",
    "explanation": "Firebase Authentication integrates seamlessly with Firebase's real-time database (Firestore) and other backend services, making it a comprehensive solution for both authentication and data storage.",
    "tags": ["Next.js", "Authentication", "Firebase"]
  },
  {
    "question": "Which library would you choose for advanced user management with pre-built UI components?",
    "options": [
      "NextAuth.js",
      "Clerk",
      "Firebase Authentication",
      "None of the above"
    ],
    "answer": "Clerk",
    "explanation": "Clerk provides advanced user management features, including multi-factor authentication (MFA) and pre-built UI components for login and signup flows.",
    "tags": ["Next.js", "Authentication", "Clerk"]
  },
  {
    "question": "Which feature is supported by all three libraries: NextAuth.js, Clerk, and Firebase Authentication?",
    "options": [
      "Real-time database integration.",
      "Multi-factor authentication (MFA).",
      "OAuth support (e.g., Google, GitHub).",
      "Mobile app development tools."
    ],
    "answer": "OAuth support (e.g., Google, GitHub).",
    "explanation": "All three librariesNextAuth.js, Clerk, and Firebase Authenticationsupport OAuth-based authentication with providers like Google, GitHub, and others.",
    "tags": ["Next.js", "Authentication", "Comparison"]
  },
  {
    "question": "What is the primary advantage of using Firebase Authentication over NextAuth.js?",
    "options": [
      "Simpler OAuth setup.",
      "Built-in real-time database services.",
      "Advanced user management.",
      "Fully managed pre-built UI components."
    ],
    "answer": "Built-in real-time database services.",
    "explanation": "Firebase Authentication is part of the Firebase ecosystem, which includes real-time database services like Firestore, making it an all-in-one solution for both authentication and data storage.",
    "tags": ["Next.js", "Authentication", "Firebase"]
  },
  {
    "question": "Which method is used to sign out a user in NextAuth.js?",
    "options": ["signOut()", "GoogleAuthProvider", "useUser", "SignOutButton"],
    "answer": "signOut()",
    "explanation": "The `signOut()` method from NextAuth.js is used to log out the currently authenticated user.",
    "tags": ["Next.js", "NextAuth.js", "Authentication"]
  },
  {
    "question": "What is the main difference between Clerk and NextAuth.js in terms of user management?",
    "options": [
      "Clerk requires manual database setup.",
      "NextAuth.js provides pre-built UI components.",
      "Clerk offers advanced user management features out of the box.",
      "NextAuth.js supports mobile app development."
    ],
    "answer": "Clerk offers advanced user management features out of the box.",
    "explanation": "Clerk provides advanced user management features, such as multi-factor authentication (MFA) and pre-built UI components, whereas NextAuth.js requires additional setup for similar functionality.",
    "tags": ["Next.js", "Authentication", "Comparison"]
  },
  {
    "question": "Which library would you choose for a project requiring both authentication and real-time database integration?",
    "options": [
      "NextAuth.js",
      "Clerk",
      "Firebase Authentication",
      "All of the above"
    ],
    "answer": "Firebase Authentication",
    "explanation": "Firebase Authentication is the best choice when you need both authentication and real-time database integration, as it is part of the Firebase ecosystem that includes Firestore and other backend services.",
    "tags": ["Next.js", "Authentication", "Firebase"]
  },
  {
    "question": "What is the primary purpose of Middleware in Next.js?",
    "options": [
      "To execute serverless functions at the edge.",
      "To intercept and modify requests before they reach a page.",
      "To regenerate static pages dynamically.",
      "To optimize image loading."
    ],
    "answer": "To intercept and modify requests before they reach a page.",
    "explanation": "Middleware in Next.js allows you to intercept and modify HTTP requests, enabling use cases like authentication, redirects, and custom logic before a request reaches a page.",
    "tags": ["Next.js", "Middleware", "Request Handling"]
  },
  {
    "question": "Which of the following is a common use case for Middleware in Next.js?",
    "options": [
      "Generating static HTML for SEO optimization.",
      "Redirecting users based on authentication status.",
      "Caching API responses for faster access.",
      "Rendering dynamic content on the server."
    ],
    "answer": "Redirecting users based on authentication status.",
    "explanation": "Middleware is often used for tasks like redirecting unauthenticated users to a login page or applying custom logic for A/B testing and feature flags.",
    "tags": ["Next.js", "Middleware", "Use Cases"]
  },
  {
    "question": "What are Edge Functions in Next.js?",
    "options": [
      "Functions that run during the build process to generate static pages.",
      "Serverless functions executed at the edge for ultra-low latency.",
      "Middleware functions that handle request interception.",
      "Functions that regenerate static pages dynamically."
    ],
    "answer": "Serverless functions executed at the edge for ultra-low latency.",
    "explanation": "Edge Functions in Next.js are serverless functions that run at the edge (CDN level), reducing latency and enabling real-time personalization, geolocation, and security checks.",
    "tags": ["Next.js", "Edge Functions", "Performance Optimization"]
  },
  {
    "question": "Which of the following is true about Edge Functions?",
    "options": [
      "They have unlimited runtime and access to all Node.js libraries.",
      "They are ideal for localized content delivery and rate limiting.",
      "They require full-page re-builds for updates.",
      "They are only used for client-side rendering."
    ],
    "answer": "They are ideal for localized content delivery and rate limiting.",
    "explanation": "Edge Functions are designed for low-latency operations like personalized content delivery, geolocation, and security checks. They run at the edge and have limited runtime and library access.",
    "tags": ["Next.js", "Edge Functions", "Use Cases"]
  },
  {
    "question": "What is Incremental Static Regeneration (ISR) in Next.js?",
    "options": [
      "A method to pre-render pages at build time with static content.",
      "A technique to fetch data on every request for dynamic pages.",
      "A way to regenerate static pages dynamically without rebuilding the entire site.",
      "A tool for optimizing images for better performance."
    ],
    "answer": "A way to regenerate static pages dynamically without rebuilding the entire site.",
    "explanation": "Incremental Static Regeneration (ISR) allows static pages to be updated dynamically in the background without requiring a full re-build, making it ideal for frequently updated content like blogs or news sites.",
    "tags": ["Next.js", "ISR", "Dynamic Updates"]
  },
  {
    "question": "Which property in `getStaticProps` enables ISR in Next.js?",
    "options": ["revalidate", "matcher", "middleware", "edge"],
    "answer": "revalidate",
    "explanation": "The `revalidate` property in `getStaticProps` specifies the time interval (in seconds) after which the page should be regenerated in the background, enabling ISR.",
    "tags": ["Next.js", "ISR", "getStaticProps"]
  },
  {
    "question": "Which of the following is a benefit of using ISR over traditional SSG?",
    "options": [
      "It generates static pages at build time without updates.",
      "It provides fresh data without requiring a full re-build.",
      "It requires manual triggering for page updates.",
      "It is slower than Server-Side Rendering (SSR)."
    ],
    "answer": "It provides fresh data without requiring a full re-build.",
    "explanation": "ISR combines the benefits of SSG (fast load times) and SSR (fresh data) by regenerating static pages dynamically in the background when new data is available.",
    "tags": ["Next.js", "ISR", "Comparison"]
  },
  {
    "question": "What is the main advantage of using Middleware over Edge Functions in Next.js?",
    "options": [
      "Middleware runs at the edge for ultra-low latency.",
      "Middleware can modify requests and responses globally.",
      "Middleware has unlimited runtime and access to all libraries.",
      "Middleware is only used for client-side rendering."
    ],
    "answer": "Middleware can modify requests and responses globally.",
    "explanation": "Middleware in Next.js is designed to intercept and modify requests globally, while Edge Functions are route-specific and run at the edge for low-latency operations.",
    "tags": ["Next.js", "Middleware", "Edge Functions", "Comparison"]
  },
  {
    "question": "Which of the following is a limitation of Edge Functions?",
    "options": [
      "They cannot be used for personalization or geolocation.",
      "They have limited runtime and library access.",
      "They require full-page re-builds for updates.",
      "They are only suitable for static content."
    ],
    "answer": "They have limited runtime and library access.",
    "explanation": "Edge Functions have restricted runtime and limited access to certain libraries due to their execution environment at the edge, ensuring low-latency and scalability.",
    "tags": ["Next.js", "Edge Functions", "Limitations"]
  },
  {
    "question": "Which of the following scenarios is best suited for ISR?",
    "options": [
      "A landing page with static content that doesn't change often.",
      "A blog site with frequently updated articles.",
      "A dashboard displaying real-time user-specific data.",
      "An admin panel requiring secure authentication."
    ],
    "answer": "A blog site with frequently updated articles.",
    "explanation": "ISR is ideal for content-heavy sites like blogs or news platforms where pages need to be updated frequently but don't require real-time updates, allowing for fast performance and fresh data.",
    "tags": ["Next.js", "ISR", "Use Cases"]
  },
  {
    "question": "What is Static Site Generation (SSG) in Next.js?",
    "options": [
      "A method to fetch data on every request from the server.",
      "A technique to pre-render pages at build time with static content.",
      "A way to create dynamic user-specific content on each request.",
      "A backend service to handle API requests."
    ],
    "answer": "A technique to pre-render pages at build time with static content.",
    "explanation": "Static Site Generation (SSG) generates HTML at build time, making it ideal for static content like blogs, documentation, or landing pages. It improves performance and SEO.",
    "tags": ["Next.js", "SSG", "Performance Optimization"]
  },
  {
    "question": "Which method is used in Next.js to fetch data for SSG?",
    "options": ["getServerSideProps", "getStaticProps", "useEffect", "fetch"],
    "answer": "getStaticProps",
    "explanation": "`getStaticProps` is used to fetch data at build time for Static Site Generation (SSG). The fetched data is passed as props to the page component.",
    "tags": ["Next.js", "SSG", "getStaticProps"]
  },
  {
    "question": "What is Server-Side Rendering (SSR) in Next.js?",
    "options": [
      "A technique to generate static HTML files during the build process.",
      "A method to fetch data on every request and render pages dynamically.",
      "A way to cache data for faster access.",
      "A tool to optimize images for better performance."
    ],
    "answer": "A method to fetch data on every request and render pages dynamically.",
    "explanation": "Server-Side Rendering (SSR) fetches data on each request and renders pages dynamically, ensuring fresh and up-to-date content for dynamic or user-specific pages.",
    "tags": ["Next.js", "SSR", "Dynamic Content"]
  },
  {
    "question": "Which method is used in Next.js to fetch data for SSR?",
    "options": [
      "getStaticProps",
      "getServerSideProps",
      "useState",
      "useReducer"
    ],
    "answer": "getServerSideProps",
    "explanation": "`getServerSideProps` is used to fetch data on each request for Server-Side Rendering (SSR). The fetched data is passed as props to the page component.",
    "tags": ["Next.js", "SSR", "getServerSideProps"]
  },
  {
    "question": "What are API Routes in Next.js?",
    "options": [
      "Endpoints for handling client-side logic.",
      "Backend endpoints created inside the `pages/api` directory.",
      "Pre-rendered static pages for SEO optimization.",
      "Tools for optimizing image loading."
    ],
    "answer": "Backend endpoints created inside the `pages/api` directory.",
    "explanation": "API Routes allow you to create backend functionality within Next.js by defining endpoints in the `pages/api` directory. These routes can handle form submissions, interact with databases, or secure sensitive operations.",
    "tags": ["Next.js", "API Routes", "Backend"]
  },
  {
    "question": "Which of the following is a use case for Static Site Generation (SSG)?",
    "options": [
      "User dashboards with real-time updates.",
      "Landing pages with static content that doesn't change often.",
      "Handling form submissions securely.",
      "Interacting with external APIs on every request."
    ],
    "answer": "Landing pages with static content that doesn't change often.",
    "explanation": "SSG is best suited for pages with static content, such as blogs, documentation, or landing pages, where the content doesn't change frequently.",
    "tags": ["Next.js", "SSG", "Use Cases"]
  },
  {
    "question": "Which of the following is a use case for Server-Side Rendering (SSR)?",
    "options": [
      "Pre-rendering blog posts at build time.",
      "Generating static HTML for SEO purposes.",
      "Displaying user-specific content like a dashboard.",
      "Caching data for faster access."
    ],
    "answer": "Displaying user-specific content like a dashboard.",
    "explanation": "SSR is ideal for rendering dynamic, user-specific content like dashboards or pages that require fresh data on every request.",
    "tags": ["Next.js", "SSR", "Use Cases"]
  },
  {
    "question": "What is the main advantage of using API Routes in Next.js?",
    "options": [
      "They improve SEO by pre-rendering pages.",
      "They reduce the initial load time of the application.",
      "They allow you to handle backend logic without setting up a separate server.",
      "They enable client-side state management."
    ],
    "answer": "They allow you to handle backend logic without setting up a separate server.",
    "explanation": "API Routes let you create backend endpoints directly within your Next.js application, eliminating the need for a separate server for tasks like handling form submissions or interacting with databases.",
    "tags": ["Next.js", "API Routes", "Backend"]
  },
  {
    "question": "Which of the following is true about SSG vs SSR in Next.js?",
    "options": [
      "SSG is slower than SSR because it requires building pages at runtime.",
      "SSR is better suited for static content that doesn't change often.",
      "SSG provides faster load times for public-facing pages with static content.",
      "SSR pre-renders pages at build time, while SSG fetches data on every request."
    ],
    "answer": "SSG provides faster load times for public-facing pages with static content.",
    "explanation": "SSG generates pages at build time, resulting in faster load times for static content, while SSR fetches data on every request, making it suitable for dynamic content.",
    "tags": ["Next.js", "SSG", "SSR", "Comparison"]
  },
  {
    "question": "What is the purpose of the `pages/api` directory in Next.js?",
    "options": [
      "To store static assets like images and stylesheets.",
      "To define backend API endpoints for handling server-side logic.",
      "To configure global state management for the application.",
      "To manage client-side routing and navigation."
    ],
    "answer": "To define backend API endpoints for handling server-side logic.",
    "explanation": "The `pages/api` directory in Next.js is used to define API routes, which serve as backend endpoints for handling server-side logic like form submissions, database interactions, or securing sensitive operations.",
    "tags": ["Next.js", "API Routes", "Backend"]
  },
  {
    "question": "Which state management approach is best suited for managing local component state in React?",
    "options": ["useState", "Redux Toolkit", "Zustand", "Recoil"],
    "answer": "useState",
    "explanation": "The `useState` hook is designed for managing local state within individual components, making it the most appropriate choice for this use case.",
    "tags": ["React", "State Management", "useState"]
  },
  {
    "question": "What is the primary advantage of using `useReducer` over `useState`?",
    "options": [
      "It simplifies state updates for small components.",
      "It provides better performance for all types of state.",
      "It handles complex state logic with multiple sub-values more effectively.",
      "It eliminates the need for global state management."
    ],
    "answer": "It handles complex state logic with multiple sub-values more effectively.",
    "explanation": "`useReducer` is ideal for managing complex state logic, especially when dealing with multiple sub-values or state transitions that depend on previous states.",
    "tags": ["React", "State Management", "useReducer"]
  },
  {
    "question": "Which state management library is known for its lightweight and simple API, avoiding boilerplate?",
    "options": ["Redux Toolkit", "Zustand", "Recoil", "Jotai"],
    "answer": "Zustand",
    "explanation": "Zustand is a lightweight state management library with a minimal API, making it easy to set up and use without excessive boilerplate.",
    "tags": ["React", "State Management", "Zustand"]
  },
  {
    "question": "What is the main advantage of Redux Toolkit over traditional Redux?",
    "options": [
      "It requires more boilerplate code.",
      "It simplifies the setup process with built-in features like immer.js.",
      "It does not support DevTools integration.",
      "It is less scalable than traditional Redux."
    ],
    "answer": "It simplifies the setup process with built-in features like immer.js.",
    "explanation": "Redux Toolkit reduces boilerplate by providing utilities like `createSlice` and integrating `immer.js` for immutable updates, while still offering strong DevTools support.",
    "tags": ["React", "State Management", "Redux Toolkit"]
  },
  {
    "question": "Which state management library introduces atoms for fine-grained state updates?",
    "options": ["Zustand", "Redux Toolkit", "Recoil", "Jotai"],
    "answer": "Recoil",
    "explanation": "Recoil uses atoms to manage state, allowing for fine-grained updates and reactivity. Atoms represent individual pieces of state that can be shared across components.",
    "tags": ["React", "State Management", "Recoil"]
  },
  {
    "question": "What is the key feature of Jotai that makes it stand out from other state management libraries?",
    "options": [
      "It has a large number of dependencies.",
      "It follows an atomic model similar to Recoil but with less boilerplate.",
      "It is only suitable for large-scale applications.",
      "It does not support asynchronous operations."
    ],
    "answer": "It follows an atomic model similar to Recoil but with less boilerplate.",
    "explanation": "Jotai provides a minimalist alternative to Recoil, focusing on simplicity and ease of use while maintaining the atomic model for state management.",
    "tags": ["React", "State Management", "Jotai"]
  },
  {
    "question": "Which state management library is best suited for enterprise-level applications requiring structured state management?",
    "options": ["Zustand", "Redux Toolkit", "Recoil", "Jotai"],
    "answer": "Redux Toolkit",
    "explanation": "Redux Toolkit is designed for scalability and structure, making it the preferred choice for large-scale or enterprise-level applications.",
    "tags": ["React", "State Management", "Redux Toolkit"]
  },
  {
    "question": "What is the purpose of `createSlice` in Redux Toolkit?",
    "options": [
      "To create a new React component.",
      "To define a piece of state and its reducers in a single place.",
      "To generate boilerplate code for Zustand.",
      "To manage local state within a functional component."
    ],
    "answer": "To define a piece of state and its reducers in a single place.",
    "explanation": "`createSlice` simplifies the process of defining state and reducers by combining them into a single configuration object.",
    "tags": ["React", "State Management", "Redux Toolkit", "createSlice"]
  },
  {
    "question": "Which state management library focuses on minimal re-renders by updating only the components using the state?",
    "options": ["useState", "Zustand", "Recoil", "Context API"],
    "answer": "Recoil",
    "explanation": "Recoil ensures minimal re-renders by updating only the components that subscribe to specific atoms, improving performance in larger applications.",
    "tags": ["React", "State Management", "Recoil"]
  },
  {
    "question": "When should you prefer using Context API over external state management libraries?",
    "options": [
      "For managing global state in large applications.",
      "For sharing state across multiple components in smaller applications.",
      "When you need advanced features like DevTools integration.",
      "When working with legacy class components exclusively."
    ],
    "answer": "For sharing state across multiple components in smaller applications.",
    "explanation": "The Context API is ideal for smaller applications where global state needs to be shared across multiple components without the overhead of external libraries.",
    "tags": ["React", "State Management", "Context API"]
  },
  {
    "question": "What is the primary purpose of code splitting in React?",
    "options": [
      "To improve performance by reducing initial load time.",
      "To increase the size of the JavaScript bundle.",
      "To enhance the user interface design.",
      "To manage state in functional components."
    ],
    "answer": "To improve performance by reducing initial load time.",
    "explanation": "Code splitting breaks down large JavaScript bundles into smaller chunks, allowing only necessary code to be loaded initially, which improves performance and reduces load times.",
    "tags": ["React", "Code Splitting", "Performance Optimization"]
  },
  {
    "question": "Which React feature allows dynamic imports for lazy loading components?",
    "options": ["useEffect", "React.lazy()", "useState", "useMemo"],
    "answer": "React.lazy()",
    "explanation": "React.lazy() enables dynamic imports for components, allowing them to be loaded only when needed, improving performance and reducing initial bundle size.",
    "tags": ["React", "Lazy Loading", "React.lazy"]
  },
  {
    "question": "What is the role of Suspense in lazy loading?",
    "options": [
      "It dynamically imports components.",
      "It provides a fallback UI while waiting for a component to load.",
      "It manages state in functional components.",
      "It handles errors during component loading."
    ],
    "answer": "It provides a fallback UI while waiting for a component to load.",
    "explanation": "Suspense works with React.lazy() to provide a fallback UI (e.g., a loading spinner) while a component is being loaded asynchronously.",
    "tags": ["React", "Suspense", "Lazy Loading"]
  },
  {
    "question": "Which of the following is a good use case for lazy loading?",
    "options": [
      "Loading small utility functions.",
      "Loading heavy components like charts or maps only when needed.",
      "Loading all routes of an application upfront.",
      "Managing state in functional components."
    ],
    "answer": "Loading heavy components like charts or maps only when needed.",
    "explanation": "Lazy loading is ideal for large components or routes that are not required immediately, such as heavy libraries or infrequently used pages.",
    "tags": ["React", "Lazy Loading", "Use Cases"]
  },
  {
    "question": "How does React Router benefit from code splitting?",
    "options": [
      "It allows all routes to be preloaded at once.",
      "It increases the size of the initial bundle for better performance.",
      "It loads only the necessary route components when users navigate to them.",
      "It eliminates the need for Suspense."
    ],
    "answer": "It loads only the necessary route components when users navigate to them.",
    "explanation": "By combining React Router with lazy loading and Suspense, routes can be loaded on demand, reducing the initial bundle size and improving performance.",
    "tags": ["React", "React Router", "Code Splitting"]
  },
  {
    "question": "What happens if an error occurs during lazy loading?",
    "options": [
      "The entire app crashes without recovery.",
      "The fallback UI provided by Suspense continues to display indefinitely.",
      "An Error Boundary can catch the error and display a fallback UI.",
      "React automatically retries loading the component."
    ],
    "answer": "An Error Boundary can catch the error and display a fallback UI.",
    "explanation": "To handle errors during lazy loading, you can wrap the Suspense component with an Error Boundary, which catches the error and displays a fallback UI instead of crashing the app.",
    "tags": ["React", "Error Boundaries", "Suspense", "Lazy Loading"]
  },
  {
    "question": "Which of the following best describes dynamic imports in React?",
    "options": [
      "They load all components at once during the initial page load.",
      "They allow components to be loaded only when they are needed.",
      "They replace the need for React.lazy() and Suspense.",
      "They are used exclusively for managing state in functional components."
    ],
    "answer": "They allow components to be loaded only when they are needed.",
    "explanation": "Dynamic imports enable components to be loaded on demand, reducing the initial bundle size and improving performance. This is often used with React.lazy() and Suspense.",
    "tags": ["React", "Dynamic Imports", "Lazy Loading"]
  },
  {
    "question": "What is the correct syntax for using React.lazy()?",
    "options": [
      "const Component = lazy(() => import('./Component'))",
      "const Component = React.lazy(() => import('./Component'))",
      "Both A and B are correct.",
      "const Component = lazy(import('./Component'))"
    ],
    "answer": "Both A and B are correct.",
    "explanation": "You can use either `const Component = lazy(() => import('./Component'))` or `const Component = React.lazy(() => import('./Component'))` to implement lazy loading in React.",
    "tags": ["React", "React.lazy", "Syntax"]
  },
  {
    "question": "Which Webpack feature supports code splitting in React applications?",
    "options": [
      "Webpack's built-in support for dynamic imports.",
      "Webpack's optimization.splitChunks configuration.",
      "Webpack's HtmlWebpackPlugin plugin.",
      "Webpack's mini-css-extract-plugin."
    ],
    "answer": "Webpack's built-in support for dynamic imports.",
    "explanation": "Webpack automatically supports code splitting when dynamic imports (e.g., `import()` statements) are used in your React application, breaking the bundle into smaller chunks.",
    "tags": ["React", "Webpack", "Code Splitting"]
  },
  {
    "question": "What is the best practice for implementing code splitting and lazy loading in React?",
    "options": [
      "Load all components upfront to simplify the codebase.",
      "Use lazy loading for large components and routes to reduce initial load time.",
      "Avoid using Suspense to prevent unnecessary fallback UIs.",
      "Combine lazy loading with useEffect to manage side effects."
    ],
    "answer": "Use lazy loading for large components and routes to reduce initial load time.",
    "explanation": "Best practices include using lazy loading for large components or routes, combining it with Suspense for fallback UIs, and leveraging Error Boundaries to handle potential errors during loading.",
    "tags": ["React", "Code Splitting", "Lazy Loading", "Best Practices"]
  },
  {
    "question": "What is the primary purpose of an Error Boundary in React?",
    "options": [
      "To optimize performance by lazy loading components.",
      "To catch runtime errors in child components and prevent app crashes.",
      "To handle asynchronous data fetching.",
      "To manage state in functional components."
    ],
    "answer": "To catch runtime errors in child components and prevent app crashes.",
    "explanation": "An Error Boundary is a special React component that catches JavaScript errors in its child component tree during rendering, lifecycle methods, or event handlers (in class components) and prevents the entire application from crashing.",
    "tags": ["React", "Error Boundaries", "Error Handling"]
  },
  {
    "question": "Which lifecycle method must be implemented in an Error Boundary?",
    "options": [
      "componentDidMount",
      "getDerivedStateFromError",
      "componentDidUpdate",
      "shouldComponentUpdate"
    ],
    "answer": "getDerivedStateFromError",
    "explanation": "The `getDerivedStateFromError` static method is required in an Error Boundary to update the state when an error occurs, allowing the fallback UI to be displayed.",
    "tags": ["React", "Error Boundaries", "Lifecycle Methods"]
  },
  {
    "question": "What does the `componentDidCatch` method do in an Error Boundary?",
    "options": [
      "It logs the error details for debugging purposes.",
      "It updates the state to display the fallback UI.",
      "It prevents the app from rendering any further components.",
      "It handles asynchronous data fetching."
    ],
    "answer": "It logs the error details for debugging purposes.",
    "explanation": "The `componentDidCatch` method is used to log error information for debugging. It does not directly affect the UI but can be useful for tracking and reporting errors.",
    "tags": ["React", "Error Boundaries", "Debugging"]
  },
  {
    "question": "Which type of errors are NOT caught by Error Boundaries?",
    "options": [
      "Errors in the render phase of child components.",
      "Errors in lifecycle methods like componentDidMount.",
      "Errors in event handlers in class components.",
      "Asynchronous errors like those in setTimeout or Promises."
    ],
    "answer": "Asynchronous errors like those in setTimeout or Promises.",
    "explanation": "Error Boundaries do not catch errors in asynchronous code, such as those occurring inside `setTimeout`, Promises, or event handlers outside the React component tree.",
    "tags": ["React", "Error Boundaries", "Limitations"]
  },
  {
    "question": "What is the purpose of React's Suspense API?",
    "options": [
      "To catch runtime errors in components.",
      "To pause rendering while waiting for something to load (e.g., lazy-loaded components or data).",
      "To optimize performance by memoizing expensive computations.",
      "To manage state in functional components."
    ],
    "answer": "To pause rendering while waiting for something to load (e.g., lazy-loaded components or data).",
    "explanation": "Suspense allows you to declaratively specify how your application should behave while waiting for resources like lazy-loaded components or fetched data.",
    "tags": ["React", "Suspense API", "Asynchronous Rendering"]
  },
  {
    "question": "Which of the following is true about Suspense?",
    "options": [
      "It can be used to catch runtime errors in components.",
      "It works seamlessly with event handlers to handle asynchronous operations.",
      "It provides a fallback UI while waiting for lazy-loaded components or data.",
      "It replaces Error Boundaries entirely."
    ],
    "answer": "It provides a fallback UI while waiting for lazy-loaded components or data.",
    "explanation": "Suspense allows you to define a fallback UI (e.g., a loading spinner) while waiting for asynchronous operations like lazy-loaded components or data fetching to complete.",
    "tags": ["React", "Suspense API", "Fallback UI"]
  },
  {
    "question": "How do you implement lazy loading of components using Suspense?",
    "options": [
      "By wrapping the component with an Error Boundary.",
      "By using React.lazy and wrapping it with <Suspense>.",
      "By using the useMemo hook to cache the component.",
      "By using the useEffect hook to dynamically import the component."
    ],
    "answer": "By using React.lazy and wrapping it with <Suspense>.",
    "explanation": "You can use `React.lazy` to dynamically import components and wrap them with `<Suspense>` to provide a fallback UI while the component is being loaded.",
    "tags": ["React", "Suspense API", "Lazy Loading"]
  },
  {
    "question": "Which of the following is a limitation of Error Boundaries?",
    "options": [
      "They cannot catch errors in asynchronous code like Promises or setTimeout.",
      "They cannot display a fallback UI when an error occurs.",
      "They cannot log error details for debugging.",
      "They cannot be used with functional components."
    ],
    "answer": "They cannot catch errors in asynchronous code like Promises or setTimeout.",
    "explanation": "Error Boundaries only catch errors during the render phase, lifecycle methods, and event handlers in class components. They do not catch errors in asynchronous code like Promises or `setTimeout`.",
    "tags": ["React", "Error Boundaries", "Limitations"]
  },
  {
    "question": "When should you use Suspense instead of an Error Boundary?",
    "options": [
      "When you need to catch runtime errors in components.",
      "When you want to display a fallback UI while waiting for asynchronous operations to complete.",
      "When you need to log error details for debugging.",
      "When you want to manage state in functional components."
    ],
    "answer": "When you want to display a fallback UI while waiting for asynchronous operations to complete.",
    "explanation": "Suspense is designed for handling asynchronous operations like lazy loading components or data fetching, whereas Error Boundaries are used for catching runtime errors.",
    "tags": ["React", "Suspense API", "Error Boundaries", "Comparison"]
  },
  {
    "question": "Which of the following best describes the difference between Error Boundaries and Suspense?",
    "options": [
      "Error Boundaries handle asynchronous operations, while Suspense catches runtime errors.",
      "Error Boundaries catch runtime errors, while Suspense handles asynchronous operations.",
      "Error Boundaries and Suspense both handle asynchronous operations but differ in implementation.",
      "Error Boundaries and Suspense both catch runtime errors but differ in scope."
    ],
    "answer": "Error Boundaries catch runtime errors, while Suspense handles asynchronous operations.",
    "explanation": "Error Boundaries are designed to catch runtime errors in components, while Suspense is used to handle asynchronous operations like lazy loading and data fetching.",
    "tags": ["React", "Error Boundaries", "Suspense API", "Comparison"]
  },
  {
    "question": "What is a Custom Hook in React?",
    "options": [
      "A function that starts with 'use' and encapsulates reusable logic.",
      "A component that wraps other components.",
      "A lifecycle method used to manage side effects.",
      "A tool for optimizing performance."
    ],
    "answer": "A function that starts with 'use' and encapsulates reusable logic.",
    "explanation": "Custom Hooks are JavaScript functions that start with 'use' and allow developers to reuse logic across multiple components while keeping them clean and maintainable.",
    "tags": ["React", "Custom Hooks", "Reusability"]
  },
  {
    "question": "Which of the following is true about Custom Hooks?",
    "options": [
      "They can only be used for managing state.",
      "They must always return JSX.",
      "They can encapsulate complex logic like API calls or local storage management.",
      "They replace Higher-Order Components entirely."
    ],
    "answer": "They can encapsulate complex logic like API calls or local storage management.",
    "explanation": "Custom Hooks are versatile and can encapsulate any type of logic, including API calls, local storage management, and more.",
    "tags": ["React", "Custom Hooks", "Logic Encapsulation"]
  },
  {
    "question": "What does the `useCounter` custom hook typically provide?",
    "options": [
      "A counter value and methods to increment, decrement, and reset it.",
      "A list of fetched data from an API.",
      "A logging mechanism for components.",
      "A loading indicator for asynchronous operations."
    ],
    "answer": "A counter value and methods to increment, decrement, and reset it.",
    "explanation": "The `useCounter` custom hook manages a counter value and provides methods to manipulate it, such as increment, decrement, and reset.",
    "tags": ["React", "Custom Hooks", "useCounter"]
  },
  {
    "question": "What is the purpose of the `useFetch` custom hook?",
    "options": [
      "To log when a component mounts.",
      "To fetch data from an API and handle loading/error states.",
      "To wrap components with additional functionality.",
      "To memoize expensive computations."
    ],
    "answer": "To fetch data from an API and handle loading/error states.",
    "explanation": "The `useFetch` custom hook simplifies fetching data from APIs by handling loading, error, and data states in a reusable manner.",
    "tags": ["React", "Custom Hooks", "useFetch", "API Calls"]
  },
  {
    "question": "What is a Higher-Order Component (HOC) in React?",
    "options": [
      "A function that takes a component and returns a new component with enhanced functionality.",
      "A lifecycle method used to manage side effects.",
      "A custom hook that encapsulates logic.",
      "A tool for lazy loading components."
    ],
    "answer": "A function that takes a component and returns a new component with enhanced functionality.",
    "explanation": "An HOC is a function that accepts a component as input and returns a new component with additional functionality, such as logging, authentication, or data fetching.",
    "tags": ["React", "Higher-Order Components", "HOCs"]
  },
  {
    "question": "Which of the following is a common use case for HOCs?",
    "options": [
      "Managing state in functional components.",
      "Adding logging or authentication functionality to components.",
      "Encapsulating API calls.",
      "Optimizing performance with useMemo."
    ],
    "answer": "Adding logging or authentication functionality to components.",
    "explanation": "HOCs are often used to add cross-cutting concerns like logging, authentication, or data fetching to components without altering their original logic.",
    "tags": ["React", "Higher-Order Components", "HOCs", "Use Cases"]
  },
  {
    "question": "What is the difference between Custom Hooks and HOCs?",
    "options": [
      "Custom Hooks reuse logic, while HOCs wrap components.",
      "Custom Hooks are deprecated, while HOCs are modern.",
      "Custom Hooks manage state, while HOCs manage props.",
      "There is no difference; they are interchangeable."
    ],
    "answer": "Custom Hooks reuse logic, while HOCs wrap components.",
    "explanation": "Custom Hooks focus on reusing logic, while HOCs focus on wrapping components to enhance their behavior or functionality.",
    "tags": ["React", "Custom Hooks", "Higher-Order Components", "Comparison"]
  },
  {
    "question": "Which of the following is true about `withLogger`, an example HOC?",
    "options": [
      "It fetches data from an API.",
      "It logs when a component mounts.",
      "It displays a loading spinner.",
      "It manages state in functional components."
    ],
    "answer": "It logs when a component mounts.",
    "explanation": "The `withLogger` HOC is used to log when a component mounts, making it useful for debugging or tracking component lifecycles.",
    "tags": ["React", "Higher-Order Components", "HOCs", "withLogger"]
  },
  {
    "question": "What is the purpose of the `withLoading` HOC?",
    "options": [
      "To log when a component mounts.",
      "To display a loading indicator while data is being fetched.",
      "To manage state in functional components.",
      "To memoize expensive computations."
    ],
    "answer": "To display a loading indicator while data is being fetched.",
    "explanation": "The `withLoading` HOC is used to display a loading indicator until data fetching or some asynchronous operation is complete.",
    "tags": ["React", "Higher-Order Components", "HOCs", "withLoading"]
  },
  {
    "question": "When should you prefer Custom Hooks over HOCs?",
    "options": [
      "When you need to wrap components with additional functionality.",
      "When you want to share logic across multiple components without wrapping them.",
      "When you need to manage state in class components.",
      "When you want to optimize performance with code splitting."
    ],
    "answer": "When you want to share logic across multiple components without wrapping them.",
    "explanation": "Custom Hooks are preferred for sharing logic across components, while HOCs are better suited for wrapping components with additional functionality.",
    "tags": [
      "React",
      "Custom Hooks",
      "Higher-Order Components",
      "Best Practices"
    ]
  },
  {
    "question": "What is the purpose of `React.memo`?",
    "options": [
      "To optimize expensive computations.",
      "To prevent unnecessary re-renders of functional components.",
      "To memoize functions and avoid re-creation.",
      "To load components on demand."
    ],
    "answer": "To prevent unnecessary re-renders of functional components.",
    "explanation": "`React.memo` is a higher-order component that prevents a functional compoentn from re-rendering if its props have not changed.",
    "tags": ["React", "Performance Optimization", "React.memo"]
  },
  {
    "question": "Which hook is used to cache the result of an expensive computation?",
    "options": ["useCallback", "useState", "useMemo", "useReducer"],
    "answer": "useMemo",
    "explanation": "The `useMemo` hook is used to memoize values, ensuring that expensive computations are only re-executed when their dependencies change.",
    "tags": ["React", "Performance Optimization", "useMemo"]
  },
  {
    "question": "When should you use `useCallback`?",
    "options": [
      "When you need to optimize expensive computations.",
      "When you want to prevent unnecessary re-renders caused by function re-creation.",
      "When you want to load components lazily.",
      "When you need to manage state in a functional component."
    ],
    "answer": "When you want to prevent unnecessary re-renders caused by function re-creation.",
    "explanation": "`useCallback` is used to memoize functions, preventing them from being re-created unnecessarily during re-renders, which can help optimize child components wrapped with `React.memo`.",
    "tags": ["React", "Performance Optimization", "useCallback"]
  },
  {
    "question": "What is lazy loading in React?",
    "options": [
      "A technique to prevent unnecessary re-renders.",
      "A method to memoize expensive computations.",
      "A way to load components only when they are needed.",
      "A tool to optimize function creation."
    ],
    "answer": "A way to load components only when they are needed.",
    "explanation": "Lazy loading (using `React.lazy` and `Suspense`) allows components to be loaded on demand, improving the initial load time of an application.",
    "tags": ["React", "Performance Optimization", "Lazy Loading"]
  },
  {
    "question": "Which component is used as a fallback while lazy-loaded components are being loaded?",
    "options": ["React.memo", "useMemo", "Suspense", "useCallback"],
    "answer": "Suspense",
    "explanation": "The `Suspense` component provides a fallback UI (e.g., a loading indicator) while lazy-loaded components are being loaded.",
    "tags": ["React", "Performance Optimization", "Suspense", "Lazy Loading"]
  },
  {
    "question": "What happens if you pass a new function reference as a prop to a child component wrapped with `React.memo`?",
    "options": [
      "The child component will re-render because the function reference has changed.",
      "The child component will not re-render because of `React.memo`.",
      "The child component will throw an error.",
      "The child component will ignore the prop change."
    ],
    "answer": "The child component will re-render because the function reference has changed.",
    "explanation": "If a new function reference is passed as a prop, the child component wrapped with `React.memo` will detect the prop change and re-render. To avoid this, use `useCallback` to memoize the function.",
    "tags": ["React", "Performance Optimization", "React.memo", "useCallback"]
  },
  {
    "question": "Which of the following is true about `useMemo`?",
    "options": [
      "It guarantees that the computation will never run again.",
      "It re-runs the computation whenever any prop changes.",
      "It re-runs the computation only when its dependency array changes.",
      "It is used to manage state in functional components."
    ],
    "answer": "It re-runs the computation only when its dependency array changes.",
    "explanation": "`useMemo` caches the result of a computation and only re-runs it when the values in its dependency array change.",
    "tags": ["React", "Performance Optimization", "useMemo"]
  },
  {
    "question": "What is the main benefit of using `React.lazy`?",
    "options": [
      "It reduces the number of re-renders in the application.",
      "It improves the performance of expensive computations.",
      "It loads components only when they are needed, reducing the initial bundle size.",
      "It prevents unnecessary function re-creation."
    ],
    "answer": "It loads components only when they are needed, reducing the initial bundle size.",
    "explanation": "`React.lazy` enables code splitting and lazy loading, which helps reduce the initial bundle size by loading components on demand.",
    "tags": ["React", "Performance Optimization", "Lazy Loading"]
  },
  {
    "question": "Which hook ensures that a memoized function does not change between re-renders unless its dependencies change?",
    "options": ["useMemo", "useCallback", "useState", "useEffect"],
    "answer": "useCallback",
    "explanation": "`useCallback` returns a memoized version of the callback function that only changes if one of its dependencies changes.",
    "tags": ["React", "Performance Optimization", "useCallback"]
  },
  {
    "question": "What is the correct syntax for implementing lazy loading in React?",
    "options": [
      "const Component = lazy(() => import('./Component'))",
      "const Component = React.lazy(() => import('./Component'))",
      "const Component = lazy(import('./Component'))",
      "Both A and B are correct."
    ],
    "answer": "Both A and B are correct.",
    "explanation": "You can implement lazy loading using either `const Component = lazy(() => import('./Component'))` or `const Component = React.lazy(() => import('./Component'))`. Both are valid syntaxes.",
    "tags": ["React", "Performance Optimization", "Lazy Loading"]
  },
  {
    "question": "What is the correct syntax for handling a button click in React?",
    "options": [
      "onClick='handleClick()'",
      "onClick={handleClick}",
      "onclick={handleClick()}",
      "onClick={handleClick()}"
    ],
    "answer": "onClick={handleClick}",
    "explanation": "In React, event handlers use camelCase syntax and pass a function reference (e.g., `onClick={handleClick}`) rather than a string or immediately invoked function.",
    "tags": ["React", "Event Handling", "onClick"]
  },
  {
    "question": "How do you pass arguments to an event handler in React?",
    "options": [
      "Using arrow functions: onClick={() => handleClick(arg)}",
      "Directly passing the argument: onClick={handleClick(arg)}",
      "Using bind: onClick={handleClick.bind(this, arg)}",
      "Both A and C are correct."
    ],
    "answer": "Both A and C are correct.",
    "explanation": "You can pass arguments to an event handler using either arrow functions (`onClick={() => handleClick(arg)}`) or `.bind()` (`onClick={handleClick.bind(this, arg)}`) to prevent immediate execution.",
    "tags": ["React", "Event Handling", "Arguments"]
  },
  {
    "question": "What does React's SyntheticEvent provide?",
    "options": [
      "A wrapper for native DOM events to ensure cross-browser consistency.",
      "A way to directly access the DOM element.",
      "A method to prevent default browser behavior.",
      "A tool for optimizing performance."
    ],
    "answer": "A wrapper for native DOM events to ensure cross-browser consistency.",
    "explanation": "React's SyntheticEvent normalizes browser-specific behavior, providing a consistent API across all browsers.",
    "tags": ["React", "SyntheticEvent", "Cross-Browser"]
  },
  {
    "question": "Which of the following best describes a controlled component in React?",
    "options": [
      "A component where the DOM manages the form state.",
      "A component where React manages the form state using state variables.",
      "A component that does not handle user input.",
      "A component that uses refs to manage form data."
    ],
    "answer": "A component where React manages the form state using state variables.",
    "explanation": "In a controlled component, React controls the form state by managing it in the component's state (using hooks like `useState`).",
    "tags": ["React", "Form Management", "Controlled Components"]
  },
  {
    "question": "What is the purpose of `useRef` in uncontrolled components?",
    "options": [
      "To store form values in the component's state.",
      "To directly access DOM elements and their values.",
      "To handle events in a declarative manner.",
      "To optimize rendering performance."
    ],
    "answer": "To directly access DOM elements and their values.",
    "explanation": "In uncontrolled components, `useRef` is used to access DOM elements and retrieve their values directly without managing them in React's state.",
    "tags": ["React", "Form Management", "Uncontrolled Components", "useRef"]
  },
  {
    "question": "How do you handle multiple inputs in a React form efficiently?",
    "options": [
      "By creating separate state variables for each input.",
      "By using a single state object and updating it dynamically with the input name as the key.",
      "By using refs for all inputs.",
      "By avoiding state management entirely."
    ],
    "answer": "By using a single state object and updating it dynamically with the input name as the key.",
    "explanation": "For multiple inputs, you can use a single state object and update it dynamically using the `name` attribute of the input fields as keys.",
    "tags": ["React", "Form Management", "Multiple Inputs", "Dynamic State"]
  },
  {
    "question": "What is the correct way to manage checkbox state in React?",
    "options": [
      "Using the `value` attribute.",
      "Using the `checked` attribute with state.",
      "Using refs to track the checkbox state.",
      "Both A and B are correct."
    ],
    "answer": "Using the `checked` attribute with state.",
    "explanation": "Checkboxes in React are managed using the `checked` attribute, which is tied to a boolean state variable.",
    "tags": ["React", "Form Management", "Checkbox", "State"]
  },
  {
    "question": "How do you handle a select dropdown in a controlled component?",
    "options": [
      "By using the `value` attribute and updating it with state.",
      "By using refs to track the selected option.",
      "By avoiding state management and letting the DOM handle it.",
      "By using the `selected` attribute on each option."
    ],
    "answer": "By using the `value` attribute and updating it with state.",
    "explanation": "In a controlled component, the `value` attribute of the `<select>` element is managed by React's state, and changes are handled via an `onChange` event.",
    "tags": [
      "React",
      "Form Management",
      "Select Dropdown",
      "Controlled Components"
    ]
  },
  {
    "question": "What is the difference between `event.preventDefault()` and `return false` in React forms?",
    "options": [
      "`event.preventDefault()` stops the default form submission behavior, while `return false` does not.",
      "`event.preventDefault()` prevents page reload, while `return false` only stops propagation.",
      "`event.preventDefault()` is used for event handling, while `return false` is used for state management.",
      "There is no difference; both achieve the same result."
    ],
    "answer": "`event.preventDefault()` stops the default form submission behavior, while `return false` does not.",
    "explanation": "`event.preventDefault()` explicitly prevents the default action (e.g., form submission), whereas `return false` does not stop the default behavior in React.",
    "tags": ["React", "Form Management", "Event Handling", "Prevent Default"]
  },
  {
    "question": "Which of the following is true about uncontrolled components in React?",
    "options": [
      "They use `useState` to manage form data.",
      "They rely on the DOM to manage form data using `useRef`.",
      "They are less efficient than controlled components.",
      "They cannot handle user input."
    ],
    "answer": "They rely on the DOM to manage form data using `useRef`.",
    "explanation": "Uncontrolled components delegate form state management to the DOM and use `useRef` to access input values directly.",
    "tags": ["React", "Form Management", "Uncontrolled Components", "useRef"]
  },
  {
    "question": "What problem does the React Context API solve?",
    "options": [
      "It optimizes component rendering.",
      "It eliminates the need for state management libraries.",
      "It avoids prop drilling by providing a global state.",
      "It simplifies styling in React applications."
    ],
    "answer": "It avoids prop drilling by providing a global state.",
    "explanation": "The React Context API allows components to share state globally without passing props through intermediate components, solving the issue of prop drilling.",
    "tags": ["React", "Context API", "Global State Management"]
  },
  {
    "question": "Which hook is used to consume context in functional components?",
    "options": ["useState", "useEffect", "useContext", "useReducer"],
    "answer": "useContext",
    "explanation": "The useContext hook allows functional components to access the value of a context without needing a Consumer component.",
    "tags": ["React", "Hooks", "useContext"]
  },
  {
    "question": "What is the purpose of the `Provider` in React Context?",
    "options": [
      "To define a new state variable.",
      "To provide context values to child components.",
      "To consume context values in a component.",
      "To handle side effects in components."
    ],
    "answer": "To provide context values to child components.",
    "explanation": "The Provider component from React Context is used to pass the context value down to all child components that are wrapped by it.",
    "tags": ["React", "Context API", "Provider"]
  },
  {
    "question": "How do you programmatically navigate in React Router?",
    "options": [
      "Using the Link component.",
      "Using the useNavigate hook.",
      "Using the useState hook.",
      "Using the useEffect hook."
    ],
    "answer": "Using the useNavigate hook.",
    "explanation": "The useNavigate hook from React Router allows you to navigate programmatically, such as inside event handlers or asynchronous operations.",
    "tags": ["React", "React Router", "useNavigate"]
  },
  {
    "question": "Which component is used to define routes in React Router?",
    "options": ["Route", "Router", "Switch", "Link"],
    "answer": "Route",
    "explanation": "The Route component in React Router defines the mapping between a URL path and a component to render when that path is visited.",
    "tags": ["React", "React Router", "Routing"]
  },
  {
    "question": "What is the purpose of the `BrowserRouter` in React Router?",
    "options": [
      "To manage global state.",
      "To wrap the entire application for routing.",
      "To handle form submissions.",
      "To optimize component performance."
    ],
    "answer": "To wrap the entire application for routing.",
    "explanation": "The BrowserRouter component is used to enable client-side routing in React applications by wrapping the app and managing navigation history.",
    "tags": ["React", "React Router", "BrowserRouter"]
  },
  {
    "question": "Which component replaces traditional `<a>` tags in React Router?",
    "options": ["Route", "Link", "NavLink", "Router"],
    "answer": "Link",
    "explanation": "The Link component in React Router is used to create navigational links within the application, replacing traditional HTML `<a>` tags.",
    "tags": ["React", "React Router", "Link"]
  },
  {
    "question": "What is the difference between `useNavigate` and `Link` in React Router?",
    "options": [
      "There is no difference; they are interchangeable.",
      "useNavigate is used for programmatic navigation, while Link is used for declarative navigation.",
      "useNavigate is for external links, while Link is for internal links.",
      "useNavigate reloads the page, while Link does not."
    ],
    "answer": "useNavigate is used for programmatic navigation, while Link is used for declarative navigation.",
    "explanation": "The useNavigate hook is used for navigation triggered by code (e.g., inside event handlers), while the Link component is used for declarative navigation (e.g., in menus).",
    "tags": ["React", "React Router", "Navigation"]
  },
  {
    "question": "Which of the following is true about React Context?",
    "options": [
      "It can only be used with class components.",
      "It eliminates the need for state management libraries like Redux.",
      "It requires a third-party library to function.",
      "It allows sharing data across components without prop drilling."
    ],
    "answer": "It allows sharing data across components without prop drilling.",
    "explanation": "React Context enables sharing data (like theme, authentication state, etc.) across components without manually passing props through intermediate components.",
    "tags": ["React", "Context API", "State Management"]
  },
  {
    "question": "What happens when you call `navigate()` using the `useNavigate` hook?",
    "options": [
      "The browser performs a full page reload.",
      "The component re-renders with the new route.",
      "The current route is added to the browser's history stack.",
      "The application crashes if the route does not exist."
    ],
    "answer": "The component re-renders with the new route.",
    "explanation": "When you call `navigate()` using the `useNavigate` hook, React Router updates the current route and triggers a re-render of the relevant components without reloading the page.",
    "tags": ["React", "React Router", "useNavigate"]
  },
  {
    "question": "What is JSX in React?",
    "options": [
      "A JavaScript library for managing state.",
      "A syntax extension that allows writing HTML-like code inside JavaScript.",
      "A tool for optimizing React components.",
      "A database for storing component data."
    ],
    "answer": "A syntax extension that allows writing HTML-like code inside JavaScript.",
    "explanation": "JSX (JavaScript XML) is a syntax extension that lets you write HTML-like code directly inside JavaScript, making it easier to build UIs in React.",
    "tags": ["React", "JSX", "Syntax"]
  },
  {
    "question": "Which of the following is true about self-closing tags in JSX?",
    "options": [
      "Self-closing tags do not need a slash: <img src='image.jpg'>",
      "Self-closing tags must include a slash: <img src='image.jpg' />",
      "Self-closing tags are not allowed in JSX.",
      "Self-closing tags are only used for text elements."
    ],
    "answer": "Self-closing tags must include a slash: <img src='image.jpg' />",
    "explanation": "In JSX, self-closing tags like <img /> or <br /> must include a slash at the end to comply with XML standards.",
    "tags": ["React", "JSX", "Syntax Rules"]
  },
  {
    "question": "What is the modern approach to creating components in React?",
    "options": [
      "Class-based components",
      "Functional components with hooks",
      "HTML templates",
      "Native JavaScript classes"
    ],
    "answer": "Functional components with hooks",
    "explanation": "Functional components are the modern approach in React, especially when combined with hooks, which allow state and side effects without needing a class.",
    "tags": ["React", "Components", "Functional Components"]
  },
  {
    "question": "What are props in React?",
    "options": [
      "A way to manage state in components.",
      "A mechanism for passing data between components.",
      "A tool for styling components.",
      "A method for handling events."
    ],
    "answer": "A mechanism for passing data between components.",
    "explanation": "Props (short for properties) are used to pass data from a parent component to a child component. They are read-only and cannot be modified inside the child component.",
    "tags": ["React", "Props", "Data Passing"]
  },
  {
    "question": "Which hook is used to manage state in functional components?",
    "options": ["useEffect", "useState", "useContext", "useReducer"],
    "answer": "useState",
    "explanation": "The useState hook allows functional components to have local state by defining state variables and their update functions.",
    "tags": ["React", "Hooks", "useState"]
  },
  {
    "question": "What happens when the state of a component is updated?",
    "options": [
      "The component is unmounted from the DOM.",
      "The component re-renders automatically.",
      "The component's props are updated.",
      "The component's event listeners are removed."
    ],
    "answer": "The component re-renders automatically.",
    "explanation": "When the state of a component is updated using setState, React automatically triggers a re-render of the component to reflect the changes.",
    "tags": ["React", "State", "Re-rendering"]
  },
  {
    "question": "Which hook is used to run side effects in functional components?",
    "options": ["useState", "useEffect", "useContext", "useRef"],
    "answer": "useEffect",
    "explanation": "The useEffect hook is used to perform side effects in functional components, such as fetching data, setting up subscriptions, or manually changing the DOM.",
    "tags": ["React", "Hooks", "useEffect"]
  },
  {
    "question": "What does the dependency array in useEffect control?",
    "options": [
      "The initial state of the component.",
      "The number of times the effect runs.",
      "The props passed to the component.",
      "The style of the component."
    ],
    "answer": "The number of times the effect runs.",
    "explanation": "The dependency array in useEffect determines when the effect should run. If the array is empty, the effect runs only once after the initial render. If it contains values, the effect runs whenever those values change.",
    "tags": ["React", "Hooks", "useEffect"]
  },
  {
    "question": "Which hook is used to share state between components?",
    "options": ["useState", "useEffect", "useContext", "useReducer"],
    "answer": "useContext",
    "explanation": "The useContext hook allows components to access shared state (context) without having to pass props through intermediate components.",
    "tags": ["React", "Hooks", "useContext"]
  },
  {
    "question": "What is the purpose of the useRef hook?",
    "options": [
      "To manage component state.",
      "To directly access DOM elements.",
      "To handle asynchronous operations.",
      "To define component styles."
    ],
    "answer": "To directly access DOM elements.",
    "explanation": "The useRef hook provides a mutable reference object that persists across renders. It is commonly used to access DOM elements directly or store values that don't trigger re-renders.",
    "tags": ["React", "Hooks", "useRef"]
  },
  {
    "question": "What is a singly linked list?",
    "options": [
      "A static data structure where each node points to both the next and previous nodes.",
      "A dynamic data structure where each node points to the next node.",
      "A circular data structure where the last node points back to the first node.",
      "A hierarchical data structure where each node has two children."
    ],
    "answer": "A dynamic data structure where each node points to the next node.",
    "explanation": "A singly linked list is a dynamic data structure where each node contains a value and a pointer to the next node in the sequence.",
    "tags": ["Linked List", "Data Structures", "Dynamic Data Structure"]
  },
  {
    "question": "In a doubly linked list, what does each node contain?",
    "options": [
      "Only a pointer to the next node.",
      "Pointers to both the next and previous nodes.",
      "A pointer to the previous node only.",
      "No pointers; it stores values directly."
    ],
    "answer": "Pointers to both the next and previous nodes.",
    "explanation": "Each node in a doubly linked list contains three components: a value, a pointer to the next node, and a pointer to the previous node.",
    "tags": ["Doubly Linked List", "Data Structures", "Pointers"]
  },
  {
    "question": "Which of the following is true about a circular linked list?",
    "options": [
      "The last node points back to the first node.",
      "Each node contains three pointers: next, prev, and head.",
      "It is not a dynamic data structure.",
      "It cannot store integers."
    ],
    "answer": "The last node points back to the first node.",
    "explanation": "In a circular linked list, the last node's 'next' pointer points back to the first node, forming a loop.",
    "tags": [
      "Circular Linked List",
      "Data Structures",
      "Dynamic Data Structure"
    ]
  },
  {
    "question": "What is a binary search tree (BST)?",
    "options": [
      "A tree where each node has exactly two children.",
      "A tree where the left child is always greater than the parent.",
      "A tree where the left child is less than the parent, and the right child is greater.",
      "A tree where all nodes are connected in a straight line."
    ],
    "answer": "A tree where the left child is less than the parent, and the right child is greater.",
    "explanation": "A binary search tree (BST) is a binary tree where the left subtree contains nodes with values less than the root, and the right subtree contains nodes with values greater than the root.",
    "tags": ["Binary Search Tree", "Trees", "Data Structures"]
  },
  {
    "question": "Which traversal method visits nodes in the order: left  root  right?",
    "options": [
      "Pre-order traversal",
      "In-order traversal",
      "Post-order traversal",
      "Level-order traversal"
    ],
    "answer": "In-order traversal",
    "explanation": "In-order traversal processes nodes in the order: left subtree  root  right subtree, which is commonly used for BSTs to retrieve elements in sorted order.",
    "tags": ["Tree Traversal", "Binary Search Tree", "Data Structures"]
  },
  {
    "question": "Which graph representation uses a 2D array to store connections between nodes?",
    "options": ["Adjacency List", "Adjacency Matrix", "Edge List", "Node List"],
    "answer": "Adjacency Matrix",
    "explanation": "An adjacency matrix is a 2D array where rows and columns represent nodes, and the values indicate whether an edge exists between them.",
    "tags": ["Graph Representation", "Adjacency Matrix", "Data Structures"]
  },
  {
    "question": "What is recursion?",
    "options": [
      "A function that calls itself to solve smaller subproblems.",
      "A loop that iterates over a fixed range.",
      "A technique for storing data in a stack.",
      "A method for optimizing loops."
    ],
    "answer": "A function that calls itself to solve smaller subproblems.",
    "explanation": "Recursion is a programming technique where a function calls itself to break down a problem into smaller subproblems.",
    "tags": ["Recursion", "Algorithms", "Function Calls"]
  },
  {
    "question": "What is dynamic programming?",
    "options": [
      "A technique for solving problems by breaking them into overlapping subproblems and storing results.",
      "A method for writing recursive functions without base cases.",
      "A way to optimize loops by reducing iterations.",
      "A data structure used to store large datasets."
    ],
    "answer": "A technique for solving problems by breaking them into overlapping subproblems and storing results.",
    "explanation": "Dynamic programming optimizes recursive solutions by storing intermediate results (memoization) or using tabulation to avoid redundant calculations.",
    "tags": ["Dynamic Programming", "Optimization", "Algorithms"]
  },
  {
    "question": "What is hashing?",
    "options": [
      "A technique for encrypting data.",
      "A method for storing and retrieving data efficiently using hash functions.",
      "A data structure for representing graphs.",
      "A way to implement recursion."
    ],
    "answer": "A method for storing and retrieving data efficiently using hash functions.",
    "explanation": "Hashing uses hash functions to map keys to indices in an array, enabling fast data retrieval.",
    "tags": ["Hashing", "Data Structures", "Efficient Lookup"]
  },
  {
    "question": "What does TypeScript compile to?",
    "options": ["Java", "C++", "Plain JavaScript", "Python"],
    "answer": "Plain JavaScript",
    "explanation": "TypeScript is a superset of JavaScript, so it compiles down to plain JavaScript that runs in any environment that supports JavaScript.",
    "tags": ["TypeScript", "Compilation", "JavaScript"]
  },
  {
    "question": "Which TypeScript strict mode option enforces stricter null and undefined checks?",
    "options": [
      "noImplicitAny",
      "strictNullChecks",
      "strictFunctionTypes",
      "strictPropertyInitialization"
    ],
    "answer": "strictNullChecks",
    "explanation": "The 'strictNullChecks' option ensures that 'null' and 'undefined' are not assignable to other types unless explicitly defined.",
    "tags": ["TypeScript", "Strict Mode", "Null Safety"]
  },
  {
    "question": "Which of the following is NOT a benefit of using TypeScript in React and Node.js?",
    "options": [
      "Error detection at compile time",
      "Better tooling and autocompletion",
      "Slower execution speed",
      "Improved documentation"
    ],
    "answer": "Slower execution speed",
    "explanation": "TypeScript is a superset of JavaScript and does not affect the execution speed, as it compiles to JavaScript which is then executed by the JavaScript engine.",
    "tags": ["TypeScript", "React", "Node.js", "Performance"]
  },
  {
    "question": "How do you define a functional component with props in TypeScript?",
    "options": [
      "const Component = (props: Props) => {...}",
      "const Component: React.FC<Props> = ({}) => {...}",
      "const Component: Props = () => {...}",
      "const Component<Props> = () => {...}"
    ],
    "answer": "const Component: React.FC<Props> = ({}) => {...}",
    "explanation": "The correct way to define a functional component in TypeScript is by using the 'React.FC<Props>' type to ensure the props are typed correctly.",
    "tags": ["TypeScript", "React", "Functional Components", "Typing"]
  },
  {
    "question": "In a React component, how do you specify the type for useState?",
    "options": [
      "const [state, setState] = useState({ count: 0 })",
      "const [state, setState] = useState<CounterState>({ count: 0 })",
      "const [state: CounterState, setState] = useState({ count: 0 })",
      "const state: useState<CounterState> = { count: 0 }"
    ],
    "answer": "const [state, setState] = useState<CounterState>({ count: 0 })",
    "explanation": "You can specify the type of state in React with TypeScript by using the 'useState<Type>' generic, as shown in the second option.",
    "tags": ["TypeScript", "React", "useState", "Typing"]
  },
  {
    "question": "Which package provides TypeScript types for Express request and response objects?",
    "options": [
      "@types/node",
      "@types/express",
      "express-ts",
      "express-typings"
    ],
    "answer": "@types/express",
    "explanation": "'@types/express' is the package that provides TypeScript type definitions for Express, allowing for proper type checking in request and response objects.",
    "tags": ["TypeScript", "Express", "Types"]
  },
  {
    "question": "What TypeScript type ensures that all required fields are initialized in a class constructor?",
    "options": [
      "strictNullChecks",
      "strictPropertyInitialization",
      "noImplicitAny",
      "strictFunctionTypes"
    ],
    "answer": "strictPropertyInitialization",
    "explanation": "The 'strictPropertyInitialization' option ensures that all class properties are properly initialized in the constructor before they are used.",
    "tags": ["TypeScript", "Classes", "Strict Mode"]
  },
  {
    "question": "What TypeScript type would you use to define an object structure like { id: number, name: string, email: string }?",
    "options": ["Array", "Interface", "Enum", "Tuple"],
    "answer": "Interface",
    "explanation": "To define an object structure, you would use an 'Interface', which is specifically designed for this purpose in TypeScript.",
    "tags": ["TypeScript", "Interface", "Object Types"]
  },
  {
    "question": "Which TypeScript configuration option enables all strict mode features?",
    "options": [
      "strict",
      "noImplicitAny",
      "strictNullChecks",
      "moduleResolution"
    ],
    "answer": "strict",
    "explanation": "The 'strict' option enables all the strict mode features in TypeScript, ensuring more thorough type checking throughout the code.",
    "tags": ["TypeScript", "Configuration", "Strict Mode"]
  },
  {
    "question": "What is the benefit of using TypeScript in a Node.js Express application?",
    "options": [
      "It replaces the need for middleware",
      "It enforces strict typing, reducing runtime errors",
      "It makes the app faster",
      "It removes the need for error handling"
    ],
    "answer": "It enforces strict typing, reducing runtime errors",
    "explanation": "TypeScripts strict typing helps catch errors during development, reducing potential runtime errors in a Node.js Express application.",
    "tags": ["TypeScript", "Node.js", "Express", "Error Prevention"]
  },
  {
    "question": "What is TypeScript?",
    "options": [
      "A dynamically typed superset of JavaScript",
      "A strongly typed superset of JavaScript",
      "A JavaScript framework",
      "A database query language"
    ],
    "answer": "A strongly typed superset of JavaScript",
    "explanation": "TypeScript extends JavaScript by adding static typing, making code more predictable and easier to debug.",
    "tags": ["TypeScript", "Basics"]
  },
  {
    "question": "Which TypeScript feature ensures variables have explicit types?",
    "options": ["Interfaces", "Generics", "Type Annotations", "Utility Types"],
    "answer": "Type Annotations",
    "explanation": "Type annotations explicitly define the type of a variable, function parameter, or return value.",
    "tags": ["TypeScript", "Type Annotations"]
  },
  {
    "question": "How do you define an interface in TypeScript?",
    "options": [
      "Using the 'class' keyword",
      "Using the 'interface' keyword",
      "Using the 'type' keyword",
      "Using the 'struct' keyword"
    ],
    "answer": "Using the 'interface' keyword",
    "explanation": "Interfaces in TypeScript define the structure of an object, ensuring type safety.",
    "tags": ["TypeScript", "Interfaces"]
  },
  {
    "question": "What is the purpose of generics in TypeScript?",
    "options": [
      "To create functions and components with flexible types",
      "To enforce strict data types",
      "To define object properties",
      "To handle asynchronous operations"
    ],
    "answer": "To create functions and components with flexible types",
    "explanation": "Generics allow reusable and type-safe components by defining a placeholder type <T>.",
    "tags": ["TypeScript", "Generics"]
  },
  {
    "question": "Which utility type makes all properties optional?",
    "options": ["Required<T>", "Readonly<T>", "Partial<T>", "Omit<T, K>"],
    "answer": "Partial<T>",
    "explanation": "The Partial utility type makes all properties of a given type optional.",
    "tags": ["TypeScript", "Utility Types"]
  },
  {
    "question": "How does TypeScript help catch errors early?",
    "options": [
      "By running the code before compilation",
      "By enforcing static typing",
      "By automatically fixing syntax errors",
      "By replacing JavaScript's runtime"
    ],
    "answer": "By enforcing static typing",
    "explanation": "TypeScript catches errors at compile time by enforcing static typing, reducing runtime errors.",
    "tags": ["TypeScript", "Error Handling"]
  },
  {
    "question": "What is a key characteristic of Functional Programming (FP)?",
    "options": [
      "Functions are treated as first-class citizens",
      "Data is always mutable",
      "Objects encapsulate state and behavior",
      "Code is organized into hierarchical classes"
    ],
    "answer": "Functions are treated as first-class citizens",
    "explanation": "In FP, functions can be assigned to variables, passed as arguments, and returned from other functions.",
    "tags": ["Functional Programming", "First-Class Functions"]
  },
  {
    "question": "Which principle is NOT part of Functional Programming?",
    "options": [
      "Encapsulation",
      "Pure Functions",
      "Immutability",
      "Function Composition"
    ],
    "answer": "Encapsulation",
    "explanation": "Encapsulation is a principle of OOP, whereas FP focuses on pure functions and immutability.",
    "tags": ["Functional Programming", "OOP"]
  },
  {
    "question": "What does the term 'immutability' mean in FP?",
    "options": [
      "Data cannot be modified once created",
      "Variables can be reassigned freely",
      "Objects manage their own state",
      "Data is shared across multiple instances"
    ],
    "answer": "Data cannot be modified once created",
    "explanation": "Immutability ensures that data is not changed directly but rather new copies are created.",
    "tags": ["Functional Programming", "Immutability"]
  },
  {
    "question": "Which of the following is an example of a higher-order function?",
    "options": [
      "A function that returns another function",
      "A function that modifies object properties",
      "A function that stores data in private fields",
      "A function that only operates on primitive data types"
    ],
    "answer": "A function that returns another function",
    "explanation": "Higher-order functions either take functions as arguments or return functions as results.",
    "tags": ["Functional Programming", "Higher-Order Functions"]
  },
  {
    "question": "Which concept is NOT a core principle of Object-Oriented Programming?",
    "options": [
      "Function Composition",
      "Encapsulation",
      "Inheritance",
      "Polymorphism"
    ],
    "answer": "Function Composition",
    "explanation": "Function composition is a technique in FP, whereas OOP emphasizes encapsulation, inheritance, and polymorphism.",
    "tags": ["OOP", "Functional Programming"]
  },
  {
    "question": "Which feature allows child classes to inherit properties and methods from a parent class?",
    "options": [
      "Inheritance",
      "Encapsulation",
      "Function Composition",
      "Polymorphism"
    ],
    "answer": "Inheritance",
    "explanation": "Inheritance enables a child class to acquire the behavior and attributes of a parent class, promoting code reuse.",
    "tags": ["OOP", "Inheritance"]
  },
  {
    "question": "What is the primary goal of Encapsulation in OOP?",
    "options": [
      "To restrict direct access to certain object properties",
      "To allow free modification of object properties",
      "To increase code redundancy",
      "To make all class attributes publicly accessible"
    ],
    "answer": "To restrict direct access to certain object properties",
    "explanation": "Encapsulation hides implementation details, allowing controlled access via public methods.",
    "tags": ["OOP", "Encapsulation"]
  },
  {
    "question": "Which of the following best describes Polymorphism in OOP?",
    "options": [
      "Allowing different classes to use the same method name but with different implementations",
      "Restricting object properties to private access only",
      "Encapsulating multiple functions within a single class",
      "Breaking a large function into smaller functions"
    ],
    "answer": "Allowing different classes to use the same method name but with different implementations",
    "explanation": "Polymorphism allows objects of different classes to be treated as instances of the same class through method overriding.",
    "tags": ["OOP", "Polymorphism"]
  },
  {
    "question": "What is a major advantage of Functional Programming?",
    "options": [
      "Code is more predictable and easier to debug",
      "It allows modifying global variables freely",
      "It uses objects to encapsulate state",
      "It enforces strict class hierarchies"
    ],
    "answer": "Code is more predictable and easier to debug",
    "explanation": "FP minimizes side effects and mutations, making it easier to reason about the behavior of functions.",
    "tags": ["Functional Programming", "Advantages"]
  },
  {
    "question": "Which paradigm is best suited for building large-scale applications with complex relationships between entities?",
    "options": [
      "Object-Oriented Programming",
      "Functional Programming",
      "Procedural Programming",
      "Declarative Programming"
    ],
    "answer": "Object-Oriented Programming",
    "explanation": "OOP is effective for structuring large applications by organizing code into reusable objects with relationships.",
    "tags": ["OOP", "Scalability"]
  },
  {
    "question": "What data structure does the JavaScript call stack follow?",
    "options": [
      "FIFO (First In, First Out)",
      "LIFO (Last In, First Out)",
      "Queue",
      "Heap"
    ],
    "answer": "LIFO (Last In, First Out)",
    "explanation": "The call stack in JavaScript follows a LIFO structure, meaning the last function called is the first to be executed completely and removed from the stack.",
    "tags": ["Call Stack", "JavaScript", "Execution"]
  },
  {
    "question": "What happens when a function is called in JavaScript?",
    "options": [
      "It is added to the call stack.",
      "It is sent to the Web API queue.",
      "It is immediately executed asynchronously.",
      "It waits in the event loop."
    ],
    "answer": "It is added to the call stack.",
    "explanation": "When a function is invoked, it is pushed onto the call stack and executed synchronously.",
    "tags": ["Call Stack", "Execution", "JavaScript"]
  },
  {
    "question": "What is the main role of the JavaScript event loop?",
    "options": [
      "To handle asynchronous operations.",
      "To store function calls.",
      "To manage memory allocation.",
      "To execute JavaScript code in order."
    ],
    "answer": "To handle asynchronous operations.",
    "explanation": "The event loop continuously checks if the call stack is empty and moves pending asynchronous callbacks from the task queue to the call stack.",
    "tags": ["Event Loop", "Asynchronous", "JavaScript"]
  },
  {
    "question": "Why does `setTimeout(fn, 0)` not execute immediately?",
    "options": [
      "It gets blocked by the call stack.",
      "It has a minimum delay of 1ms.",
      "It is placed in the callback queue and waits for the call stack to be empty.",
      "JavaScript executes `setTimeout` synchronously."
    ],
    "answer": "It is placed in the callback queue and waits for the call stack to be empty.",
    "explanation": "Even with a delay of 0ms, `setTimeout` callbacks are placed in the callback queue and executed only when the call stack is empty.",
    "tags": ["Event Loop", "setTimeout", "Asynchronous"]
  },
  {
    "question": "Which memory type is used to store objects in JavaScript?",
    "options": ["Stack", "Heap", "Queue", "Cache"],
    "answer": "Heap",
    "explanation": "Objects in JavaScript are stored in heap memory, while primitive values are stored in the stack.",
    "tags": ["Memory Management", "Heap", "JavaScript"]
  },
  {
    "question": "What is the purpose of JavaScript's garbage collection?",
    "options": [
      "To automatically free unused memory.",
      "To optimize the execution speed of JavaScript.",
      "To manually manage memory allocation.",
      "To store temporary data for faster access."
    ],
    "answer": "To automatically free unused memory.",
    "explanation": "Garbage collection in JavaScript uses the Mark-and-Sweep algorithm to automatically reclaim memory occupied by unreachable objects.",
    "tags": ["Garbage Collection", "Memory Management", "Optimization"]
  },
  {
    "question": "What is a common cause of memory leaks in JavaScript?",
    "options": [
      "Using `const` instead of `let`.",
      "Not using `setTimeout`.",
      "Not removing event listeners from elements.",
      "Declaring functions inside loops."
    ],
    "answer": "Not removing event listeners from elements.",
    "explanation": "Event listeners keep a reference to elements, preventing them from being garbage collected if not removed properly.",
    "tags": ["Memory Leaks", "Garbage Collection", "Optimization"]
  },
  {
    "question": "Which ES6+ feature allows writing asynchronous code in a synchronous style?",
    "options": ["Closures", "Generators", "Async/Await", "Destructuring"],
    "answer": "Async/Await",
    "explanation": "Async/Await allows handling asynchronous operations in a more readable and synchronous-like manner.",
    "tags": [
      "JavaScript",
      "ES6",
      "Asynchronous Programming",
      "Fullstack Development"
    ]
  },
  {
    "question": "What does the 'useMemo' hook do in React?",
    "options": [
      "Prevents unnecessary re-rendering by memoizing expensive calculations.",
      "Allows function components to use state.",
      "Handles side effects in functional components.",
      "Manages asynchronous state updates."
    ],
    "answer": "Prevents unnecessary re-rendering by memoizing expensive calculations.",
    "explanation": "useMemo optimizes performance by caching the result of a computation and recomputing it only when dependencies change.",
    "tags": ["React", "Performance Optimization", "Hooks"]
  },
  {
    "question": "Which state management library is known for being lightweight and easy to use compared to Redux?",
    "options": ["Recoil", "Zustand", "Jotai", "Context API"],
    "answer": "Zustand",
    "explanation": "Zustand is a simple, scalable, and less boilerplate-heavy state management library compared to Redux.",
    "tags": ["React", "State Management", "Frontend Development"]
  },
  {
    "question": "Which database type is best suited for handling hierarchical relationships efficiently?",
    "options": ["MySQL", "PostgreSQL", "MongoDB", "Redis"],
    "answer": "MongoDB",
    "explanation": "MongoDB, a NoSQL database, is document-based and handles hierarchical relationships using nested documents efficiently.",
    "tags": ["Databases", "MongoDB", "Backend Development"]
  },
  {
    "question": "What is the primary purpose of Prisma in a Node.js application?",
    "options": [
      "To create REST APIs",
      "To manage server-side authentication",
      "To handle Object-Relational Mapping (ORM)",
      "To implement caching mechanisms"
    ],
    "answer": "To handle Object-Relational Mapping (ORM)",
    "explanation": "Prisma is an ORM that simplifies database access and management in Node.js applications.",
    "tags": ["Node.js", "ORM", "Databases", "Backend Development"]
  },
  {
    "question": "Which authentication method involves exchanging a token rather than session-based authentication?",
    "options": ["OAuth", "JWT", "SSO", "Passport.js"],
    "answer": "JWT",
    "explanation": "JWT (JSON Web Token) is a stateless authentication mechanism where tokens are exchanged instead of using sessions.",
    "tags": ["Authentication", "Security", "Backend Development"]
  },
  {
    "question": "Which caching strategy involves storing frequently accessed data to improve performance?",
    "options": ["Rate Limiting", "Pagination", "Throttling", "Redis Caching"],
    "answer": "Redis Caching",
    "explanation": "Redis caching stores frequently accessed data in memory to improve performance and reduce database load.",
    "tags": ["Caching", "Redis", "Performance Optimization"]
  },
  {
    "question": "Which protocol is best suited for high-performance microservice communication?",
    "options": ["HTTP", "WebSockets", "gRPC", "GraphQL"],
    "answer": "gRPC",
    "explanation": "gRPC is optimized for high-performance, low-latency communication between microservices using Protocol Buffers.",
    "tags": ["Microservices", "gRPC", "Backend Development"]
  },
  {
    "question": "What is the main advantage of using Next.js over React for production applications?",
    "options": [
      "It eliminates the need for JSX.",
      "It provides built-in routing and server-side rendering (SSR).",
      "It replaces React hooks with custom state management.",
      "It is a backend framework for API development."
    ],
    "answer": "It provides built-in routing and server-side rendering (SSR).",
    "explanation": "Next.js enhances React by adding SSR, static site generation (SSG), and API routes for better performance and SEO.",
    "tags": ["Next.js", "SSR", "Fullstack Development"]
  },
  {
    "question": "What is the primary purpose of CI/CD in DevOps?",
    "options": [
      "To automate testing and deployment processes.",
      "To replace the need for a database.",
      "To manage frontend state effectively.",
      "To handle server-side authentication."
    ],
    "answer": "To automate testing and deployment processes.",
    "explanation": "CI/CD (Continuous Integration & Continuous Deployment) automates software building, testing, and deployment to improve reliability and speed.",
    "tags": ["DevOps", "CI/CD", "Automation"]
  },
  {
    "question": "Which testing library is commonly used for React component testing?",
    "options": ["Mocha", "Jest", "Supertest", "Selenium"],
    "answer": "Jest",
    "explanation": "Jest is widely used for unit and integration testing in React applications.",
    "tags": ["Testing", "Jest", "React"]
  },
  {
    "question": "Which tool helps in real-time bidirectional communication in a Node.js application?",
    "options": ["RabbitMQ", "Kafka", "Socket.io", "Express.js"],
    "answer": "Socket.io",
    "explanation": "Socket.io enables real-time, bidirectional communication between clients and servers using WebSockets.",
    "tags": ["Real-time Applications", "WebSockets", "Node.js"]
  },
  {
    "question": "What is the primary benefit of using Docker in a full-stack application?",
    "options": [
      "It eliminates the need for databases.",
      "It provides consistent environments across different machines.",
      "It replaces JavaScript with TypeScript.",
      "It improves the UI performance of React applications."
    ],
    "answer": "It provides consistent environments across different machines.",
    "explanation": "Docker ensures applications run in the same environment across development, testing, and production.",
    "tags": ["DevOps", "Docker", "CI/CD"]
  },
  {
    "question": "Which architecture is best suited for building scalable distributed applications?",
    "options": [
      "Monolithic Architecture",
      "Microservices Architecture",
      "Serverless Architecture",
      "Event-Driven Architecture"
    ],
    "answer": "Microservices Architecture",
    "explanation": "Microservices allow applications to scale efficiently by breaking down services into independently deployable units.",
    "tags": ["System Design", "Microservices", "Scalability"]
  },
  {
    "question": "What is the primary use of Redux in React applications?",
    "options": [
      "Handling UI animations.",
      "Managing global state across components.",
      "Styling components dynamically.",
      "Routing between different pages."
    ],
    "answer": "Managing global state across components.",
    "explanation": "Redux is a state management library used to store and manage global state in React applications.",
    "tags": ["React", "State Management", "Frontend Development"]
  },
  {
    "question": "What is Node.js, and how does it work?",
    "options": [
      "A frontend framework for building SPAs",
      "A JavaScript runtime using Chromes V8 engine to execute code outside the browser",
      "A database management system",
      "A CSS preprocessor"
    ],
    "answer": "A JavaScript runtime using Chromes V8 engine to execute code outside the browser",
    "explanation": "Node.js enables server-side JavaScript execution with non-blocking I/O and an event-driven architecture.",
    "tags": ["Node.js", "JavaScript Runtime"]
  },
  {
    "question": "Explain the difference between JavaScript in the browser and in Node.js.",
    "options": [
      "Browser JS manipulates the DOM; Node.js accesses the filesystem and handles servers",
      "Node.js uses Python syntax; browser JS uses Java",
      "No differencethey are identical",
      "Browser JS is asynchronous; Node.js is synchronous"
    ],
    "answer": "Browser JS manipulates the DOM; Node.js accesses the filesystem and handles servers",
    "explanation": "Node.js extends JavaScript to server-side tasks (e.g., file I/O, HTTP servers), while browser JS focuses on DOM interaction.",
    "tags": ["Node.js", "JavaScript"]
  },
  {
    "question": "What is the event loop in Node.js, and how does it work?",
    "options": [
      "A loop that blocks the main thread for synchronous tasks",
      "A mechanism for handling asynchronous operations by offloading tasks and processing callbacks",
      "A tool for parsing JSON data",
      "A testing framework"
    ],
    "answer": "A mechanism for handling asynchronous operations by offloading tasks and processing callbacks",
    "explanation": "The event loop allows Node.js to perform non-blocking I/O operations, handling callbacks when tasks complete.",
    "tags": ["Node.js", "Event Loop"]
  },
  {
    "question": "What are the core modules in Node.js? Provide examples.",
    "options": [
      "Lodash and React",
      "fs, http, path, and events",
      "Angular and Vue",
      "MySQL and MongoDB"
    ],
    "answer": "fs, http, path, and events",
    "explanation": "Core modules like fs (file system) and http (HTTP server) are built into Node.js and require no installation.",
    "tags": ["Node.js", "Core Modules"]
  },
  {
    "question": "How do you handle asynchronous operations in Node.js?",
    "options": [
      "Using synchronous loops",
      "Callbacks, promises, and async/await",
      "Only with jQuery",
      "Python threads"
    ],
    "answer": "Callbacks, promises, and async/await",
    "explanation": "Node.js uses async patterns like callbacks for non-blocking operations. Promises and async/await improve readability.",
    "tags": ["Node.js", "Asynchronous"]
  },
  {
    "question": "What is the purpose of npm?",
    "options": [
      "A Node.js runtime",
      "A package manager for installing and managing dependencies",
      "A testing framework",
      "A database ORM"
    ],
    "answer": "A package manager for installing and managing dependencies",
    "explanation": "npm (Node Package Manager) manages packages listed in package.json and installs modules from the registry.",
    "tags": ["Node.js", "npm"]
  },
  {
    "question": "What is a callback, and how is it used in Node.js?",
    "options": [
      "A CSS animation",
      "A function passed as an argument to handle async results",
      "A type of HTTP request",
      "A database schema"
    ],
    "answer": "A function passed as an argument to handle async results",
    "explanation": "Callbacks execute after async operations (e.g., fs.readFile) complete, passing results or errors.",
    "tags": ["Node.js", "Callbacks"]
  },
  {
    "question": "How do you create a simple HTTP server in Node.js?",
    "options": [
      "Using express.json()",
      "With the http modules createServer method",
      "With MongoDBs createServer()",
      "Using Angular CLI"
    ],
    "answer": "With the http modules createServer method",
    "explanation": "Example: http.createServer((req, res) => { ... }).listen(3000);",
    "tags": ["Node.js", "HTTP Server"]
  },
  {
    "question": "Explain the concept of middleware in Node.js.",
    "options": [
      "Functions that process requests and responses in Express.js",
      "A database ORM",
      "A frontend framework",
      "A type of CSS preprocessor"
    ],
    "answer": "Functions that process requests and responses in Express.js",
    "explanation": "Middleware like morgan (logging) or cors (CORS) modifies requests/responses before reaching routes.",
    "tags": ["Node.js", "Express.js", "Middleware"]
  },
  {
    "question": "What is the difference between require and import?",
    "options": [
      "require is CommonJS (Node.js); import is ES6 (browsers)",
      "import is used for CSS files",
      "No differencethey are interchangeable",
      "require is asynchronous; import is synchronous"
    ],
    "answer": "require is CommonJS (Node.js); import is ES6 (browsers)",
    "explanation": "require dynamically loads modules, while import is static. Node.js uses require by default.",
    "tags": ["Node.js", "Modules"]
  },
  {
    "question": "What are streams in Node.js, and how are they used?",
    "options": [
      "A way to handle data in chunks (e.g., large files)",
      "A type of HTTP request",
      "A database migration tool",
      "A testing framework"
    ],
    "answer": "A way to handle data in chunks (e.g., large files)",
    "explanation": "Streams (Readable, Writable) process data incrementally, reducing memory usage for large files.",
    "tags": ["Node.js", "Streams"]
  },
  {
    "question": "How does the cluster module improve performance in Node.js?",
    "options": [
      "By creating multiple worker processes to utilize CPU cores",
      "By compressing HTTP responses",
      "By caching database queries",
      "By minifying JavaScript code"
    ],
    "answer": "By creating multiple worker processes to utilize CPU cores",
    "explanation": "The cluster module forks worker processes to handle load across CPUs, scaling Node.js apps.",
    "tags": ["Node.js", "Performance"]
  },
  {
    "question": "What is middleware in Express.js? Provide examples.",
    "options": [
      "A frontend component library",
      "Functions like morgan (logging) or cors (CORS) that process requests/responses",
      "A database schema",
      "A type of CSS framework"
    ],
    "answer": "Functions like morgan (logging) or cors (CORS) that process requests/responses",
    "explanation": "Middleware executes between receiving a request and sending a response. Examples: body-parser, helmet.",
    "tags": ["Node.js", "Express.js", "Middleware"]
  },
  {
    "question": "What are some common ways to handle errors in Node.js applications?",
    "options": [
      "Using try/catch, error-first callbacks, and Express error middleware",
      "Reloading the server",
      "Ignoring errors",
      "Using CSS animations"
    ],
    "answer": "Using try/catch, error-first callbacks, and Express error middleware",
    "explanation": "Centralized error handling with middleware ensures consistent responses for API errors.",
    "tags": ["Node.js", "Error Handling"]
  },
  {
    "question": "What is the difference between process.nextTick() and setImmediate()?",
    "options": [
      "nextTick runs before the next event loop phase; setImmediate runs after",
      "setImmediate is faster than nextTick",
      "They are identical",
      "nextTick is used for HTTP requests"
    ],
    "answer": "nextTick runs before the next event loop phase; setImmediate runs after",
    "explanation": "nextTick queues a callback immediately after the current operation; setImmediate queues it for the next iteration.",
    "tags": ["Node.js", "Event Loop"]
  },
  {
    "question": "How do you work with file systems in Node.js? Provide examples.",
    "options": [
      "Using the fs modules readFile and writeFile methods",
      "With MongoDB queries",
      "Using Angular services",
      "With CSS preprocessors"
    ],
    "answer": "Using the fs modules readFile and writeFile methods",
    "explanation": "Example: fs.readFile('file.txt', (err, data) => { ... }) reads a file asynchronously.",
    "tags": ["Node.js", "File System"]
  },
  {
    "question": "What is the difference between readFile and createReadStream?",
    "options": [
      "readFile loads the entire file into memory; createReadStream processes chunks",
      "createReadStream is slower",
      "readFile is for HTTP requests",
      "No difference"
    ],
    "answer": "readFile loads the entire file into memory; createReadStream processes chunks",
    "explanation": "createReadStream is memory-efficient for large files; readFile is simpler for small files.",
    "tags": ["Node.js", "File System"]
  },
  {
    "question": "Explain how you would handle authentication and authorization in a Node.js app.",
    "options": [
      "Using JWT, sessions, or OAuth with Passport.js",
      "Hardcoding credentials in the code",
      "Using CSS animations",
      "Reloading the page for each request"
    ],
    "answer": "Using JWT, sessions, or OAuth with Passport.js",
    "explanation": "Passport.js supports strategies like JWT or OAuth. JWTs are issued upon login and verified in middleware.",
    "tags": ["Node.js", "Authentication"]
  },
  {
    "question": "What is the role of package.json in a Node.js project?",
    "options": [
      "Stores project metadata, dependencies, and scripts",
      "A CSS stylesheet",
      "A database schema",
      "A frontend template"
    ],
    "answer": "Stores project metadata, dependencies, and scripts",
    "explanation": "package.json defines dependencies, scripts (e.g., start, test), and project details like name/version.",
    "tags": ["Node.js", "npm"]
  },
  {
    "question": "How do you debug a Node.js application?",
    "options": [
      "Using console.log, Chrome DevTools, or VS Codes debugger",
      "By restarting the server repeatedly",
      "Using CSS breakpoints",
      "By ignoring errors"
    ],
    "answer": "Using console.log, Chrome DevTools, or VS Codes debugger",
    "explanation": "Node.js supports --inspect flag for Chrome DevTools. VS Codes debugger attaches to running processes.",
    "tags": ["Node.js", "Debugging"]
  },
  {
    "question": "How does Node.js handle scalability?",
    "options": [
      "Using clustering, load balancers, and stateless architecture",
      "By increasing RAM allocation",
      "Using CSS optimizations",
      "By blocking the event loop"
    ],
    "answer": "Using clustering, load balancers, and stateless architecture",
    "explanation": "Clustering spins up worker processes; stateless apps scale horizontally across servers.",
    "tags": ["Node.js", "Scalability"]
  },
  {
    "question": "What is an event emitter in Node.js, and how do you use it?",
    "options": [
      "A class to create/capture custom events using the events module",
      "A database ORM",
      "A frontend animation tool",
      "A type of HTTP request"
    ],
    "answer": "A class to create/capture custom events using the events module",
    "explanation": "Example: const emitter = new EventEmitter(); emitter.on('event', () => { ... }); emitter.emit('event');",
    "tags": ["Node.js", "Event Emitter"]
  },
  {
    "question": "How do you implement caching in a Node.js application?",
    "options": [
      "Using Redis or in-memory caching",
      "By reloading the server",
      "Using CSS variables",
      "By disabling the event loop"
    ],
    "answer": "Using Redis or in-memory caching",
    "explanation": "Caching stores frequent queries (e.g., API responses) to reduce database/API load.",
    "tags": ["Node.js", "Caching"]
  },
  {
    "question": "What are worker threads in Node.js, and when would you use them?",
    "options": [
      "For CPU-intensive tasks to avoid blocking the event loop",
      "For handling HTTP requests",
      "For CSS preprocessing",
      "For database migrations"
    ],
    "answer": "For CPU-intensive tasks to avoid blocking the event loop",
    "explanation": "Worker threads run heavy computations (e.g., image processing) in parallel without blocking the main thread.",
    "tags": ["Node.js", "Worker Threads"]
  },
  {
    "question": "How do you secure a Node.js application?",
    "options": [
      "Using HTTPS, Helmet, and input sanitization",
      "By exposing database credentials",
      "Using CSS encryption",
      "By disabling all middleware"
    ],
    "answer": "Using HTTPS, Helmet, and input sanitization",
    "explanation": "Helmet sets secure HTTP headers; input sanitization prevents SQL injection/XSS.",
    "tags": ["Node.js", "Security"]
  },
  {
    "question": "What is the difference between blocking and non-blocking code in Node.js?",
    "options": [
      "Blocking halts execution; non-blocking uses callbacks",
      "Non-blocking is slower",
      "They are identical",
      "Blocking is used for async operations"
    ],
    "answer": "Blocking halts execution; non-blocking uses callbacks",
    "explanation": "Blocking code (e.g., sync file reads) stalls the event loop; non-blocking uses async patterns.",
    "tags": ["Node.js", "Asynchronous"]
  },
  {
    "question": "Explain the concept of streams and buffers in Node.js.",
    "options": [
      "Streams process data in chunks; buffers handle binary data",
      "Buffers are for CSS animations",
      "Streams are synchronous",
      "Buffers replace the event loop"
    ],
    "answer": "Streams process data in chunks; buffers handle binary data",
    "explanation": "Buffers store raw binary data; streams read/write data incrementally (e.g., video streaming).",
    "tags": ["Node.js", "Streams", "Buffers"]
  },
  {
    "question": "How would you deploy a Node.js application in a production environment?",
    "options": [
      "Using PM2, Docker, or cloud platforms like AWS",
      "By running npm start manually",
      "Using CSS frameworks",
      "By disabling all security"
    ],
    "answer": "Using PM2, Docker, or cloud platforms like AWS",
    "explanation": "PM2 manages processes; Docker containerizes the app; AWS ECS/EKS handles scaling.",
    "tags": ["Node.js", "Deployment"]
  },
  {
    "question": "How do you test a Node.js application?",
    "options": [
      "Using frameworks like Mocha, Chai, or Jest",
      "By manually checking logs",
      "Using CSS validators",
      "By avoiding tests"
    ],
    "answer": "Using frameworks like Mocha, Chai, or Jest",
    "explanation": "Mocha/Chai handle unit/integration tests; Jest offers snapshot testing.",
    "tags": ["Node.js", "Testing"]
  },
  {
    "question": "Explain the concepts of microservices and how youd build them with Node.js.",
    "options": [
      "Small, independent services communicating via APIs; built with Express.js and Docker",
      "A monolithic architecture",
      "A frontend design pattern",
      "A database sharding technique"
    ],
    "answer": "Small, independent services communicating via APIs; built with Express.js and Docker",
    "explanation": "Microservices split apps into modular components (e.g., auth service, payment service).",
    "tags": ["Node.js", "Microservices"]
  },
  {
    "question": "How would you handle a large file upload in a Node.js API?",
    "options": [
      "Use blocking synchronous file writes",
      "Stream the file using fs.createReadStream() and handle chunks asynchronously",
      "Store the entire file in memory before processing",
      "Use Angular directives to compress the file"
    ],
    "answer": "Stream the file using fs.createReadStream() and handle chunks asynchronously",
    "explanation": "Streaming avoids memory overload by processing files in chunks. Libraries like multer can handle multipart uploads.",
    "tags": ["Node.js", "File Handling", "Performance"]
  },
  {
    "question": "How do you optimize an Angular frontend consuming a Node.js backend for better performance?",
    "options": [
      "Disable lazy loading and AOT compilation",
      "Use lazy loading, Ahead-of-Time (AOT) compilation, and caching in Node.js",
      "Store all data in localStorage",
      "Use jQuery for DOM manipulation"
    ],
    "answer": "Use lazy loading, Ahead-of-Time (AOT) compilation, and caching in Node.js",
    "explanation": "Lazy loading reduces initial load time, AOT improves runtime performance, and Node.js caching (e.g., Redis) reduces backend load.",
    "tags": ["Angular", "Node.js", "Performance"]
  },
  {
    "question": "Describe how you would implement a real-time chat application using Angular and Node.js.",
    "options": [
      "Use WebSockets (Socket.io) for bidirectional communication",
      "Reload the page every second",
      "Use CSS animations only",
      "Store messages in localStorage"
    ],
    "answer": "Use WebSockets (Socket.io) for bidirectional communication",
    "explanation": "Socket.io enables real-time messaging between Angular (client) and Node.js (server).",
    "tags": ["Angular", "Node.js", "WebSockets"]
  },
  {
    "question": "How would you integrate third-party authentication providers (e.g., Google, Facebook) in an Angular-Node.js stack?",
    "options": [
      "Use OAuth 2.0 with Passport.js in Node.js and Angular for frontend redirects",
      "Hardcode credentials in Angular",
      "Use CSS for authentication",
      "Disable authentication"
    ],
    "answer": "Use OAuth 2.0 with Passport.js in Node.js and Angular for frontend redirects",
    "explanation": "Passport.js strategies (e.g., passport-google-oauth20) handle OAuth flows; Angular manages login UI.",
    "tags": ["Angular", "Node.js", "OAuth"]
  },
  {
    "question": "How would you structure a Node.js API to support Angular lazy-loaded modules?",
    "options": [
      "Create separate API endpoints for each lazy-loaded modules data",
      "Use a single endpoint for all data",
      "Store all data in cookies",
      "Disable lazy loading"
    ],
    "answer": "Create separate API endpoints for each lazy-loaded modules data",
    "explanation": "Modular API endpoints ensure data is fetched on-demand when lazy-loaded modules are accessed.",
    "tags": ["Angular", "Node.js", "Lazy Loading"]
  },
  {
    "question": "What is Angular, and how does it differ from AngularJS?",
    "options": [
      "A framework for building server-side apps using JavaScript",
      "A component-based framework using TypeScript, unlike AngularJS which uses directives and scopes",
      "A database management system",
      "A testing library for JavaScript"
    ],
    "answer": "A component-based framework using TypeScript, unlike AngularJS which uses directives and scopes",
    "explanation": "Angular (v2+) is a modern framework using TypeScript, components, and a modular architecture, while AngularJS (v1.x) relies on directives and two-way data binding with JavaScript.",
    "tags": ["Angular", "AngularJS", "Framework Comparison"]
  },
  {
    "question": "Explain the architecture of an Angular application.",
    "options": [
      "Built around controllers and $scope",
      "Uses components, modules, services, and dependency injection",
      "Relies on vanilla JavaScript without a structured architecture",
      "Follows a monolithic design without modularity"
    ],
    "answer": "Uses components, modules, services, and dependency injection",
    "explanation": "Angular apps are structured with components (UI building blocks), modules (grouping logic), services (reusable business logic), and dependency injection (managing dependencies).",
    "tags": ["Angular", "Architecture"]
  },
  {
    "question": "What are components in Angular?",
    "options": [
      "CSS styling sheets",
      "Reusable UI elements with TypeScript logic and HTML templates",
      "Database query handlers",
      "Tools for HTTP routing"
    ],
    "answer": "Reusable UI elements with TypeScript logic and HTML templates",
    "explanation": "Components are the building blocks of Angular apps, combining a template (HTML), logic (TypeScript), and styles (CSS).",
    "tags": ["Angular", "Components"]
  },
  {
    "question": "What is a directive? Name the types of directives in Angular.",
    "options": [
      "A tool for API calls; types include GET and POST",
      "A class that adds behavior to DOM elements; types include component, structural, and attribute directives",
      "A testing framework; types include unit and integration",
      "A database schema; types include SQL and NoSQL"
    ],
    "answer": "A class that adds behavior to DOM elements; types include component, structural, and attribute directives",
    "explanation": "Directives modify the DOM. Component directives define UI, structural directives (e.g., *ngIf) alter layout, and attribute directives (e.g., ngStyle) change element appearance.",
    "tags": ["Angular", "Directives"]
  },
  {
    "question": "How does data binding work in Angular?",
    "options": [
      "Only one-way binding from component to template",
      "Two-way binding using [(ngModel)], one-way binding with {{}} and []",
      "No built-in data binding; requires external libraries",
      "Uses jQuery for DOM manipulation"
    ],
    "answer": "Two-way binding using [(ngModel)], one-way binding with {{}} and []",
    "explanation": "Angular supports two-way binding (sync between component and template) and one-way binding (template interpolation or property binding).",
    "tags": ["Angular", "Data Binding"]
  },
  {
    "question": "Explain the concept of Angular modules.",
    "options": [
      "A way to group JavaScript files for compression",
      "Containers for components, services, and other code organized into cohesive blocks",
      "Tools for database migration",
      "A type of CSS framework"
    ],
    "answer": "Containers for components, services, and other code organized into cohesive blocks",
    "explanation": "Modules (decorated with @NgModule) bundle components, directives, services, and dependencies to modularize the app.",
    "tags": ["Angular", "Modules"]
  },
  {
    "question": "What are templates in Angular?",
    "options": [
      "Pre-built database schemas",
      "HTML files with Angular-specific syntax to define the UI",
      "Tools for API testing",
      "JavaScript libraries for animations"
    ],
    "answer": "HTML files with Angular-specific syntax to define the UI",
    "explanation": "Templates use Angular syntax like *ngFor or {{}} to dynamically render data and handle events.",
    "tags": ["Angular", "Templates"]
  },
  {
    "question": "What is the purpose of services in Angular?",
    "options": [
      "To style components",
      "To handle HTTP requests, business logic, or data sharing between components",
      "To define routing paths",
      "To create animations"
    ],
    "answer": "To handle HTTP requests, business logic, or data sharing between components",
    "explanation": "Services are injectable classes that encapsulate reusable logic (e.g., API calls) and promote separation of concerns.",
    "tags": ["Angular", "Services"]
  },
  {
    "question": "What is dependency injection, and how is it implemented in Angular?",
    "options": [
      "A design pattern where dependencies are hardcoded into classes",
      "A way to inject services or objects into components via constructors",
      "A tool for minifying JavaScript code",
      "A method for handling CSS animations"
    ],
    "answer": "A way to inject services or objects into components via constructors",
    "explanation": "Angulars DI system provides dependencies (e.g., services) to components through constructor parameters, improving modularity and testability.",
    "tags": ["Angular", "Dependency Injection"]
  },
  {
    "question": "What is Angular CLI, and how does it help in development?",
    "options": [
      "A cloud-based IDE for Angular",
      "A command-line tool for scaffolding, building, and testing Angular apps",
      "A database migration tool",
      "A browser extension for debugging"
    ],
    "answer": "A command-line tool for scaffolding, building, and testing Angular apps",
    "explanation": "Angular CLI automates tasks like generating components, services, and running development servers.",
    "tags": ["Angular", "Angular CLI"]
  },
  {
    "question": "What are lifecycle hooks in Angular? List some common hooks.",
    "options": [
      "Tools for HTTP requests; examples include GET and POST",
      "Methods like ngOnInit(), ngOnDestroy() that execute at specific stages of a components lifecycle",
      "CSS animations for UI transitions",
      "Database migration scripts"
    ],
    "answer": "Methods like ngOnInit(), ngOnDestroy() that execute at specific stages of a components lifecycle",
    "explanation": "Lifecycle hooks (e.g., ngOnInit, ngOnDestroy) allow developers to tap into key moments in a components lifecycle, such as initialization or destruction.",
    "tags": ["Angular", "Lifecycle Hooks"]
  },
  {
    "question": "Explain the difference between ViewChild and ContentChild.",
    "options": [
      "ViewChild accesses DOM elements in the components view; ContentChild accesses projected content",
      "Both are used for HTTP requests",
      "ViewChild handles CSS, ContentChild handles TypeScript",
      "They are identical in functionality"
    ],
    "answer": "ViewChild accesses DOM elements in the components view; ContentChild accesses projected content",
    "explanation": "ViewChild queries elements in the components template, while ContentChild queries content projected via <ng-content>.",
    "tags": ["Angular", "ViewChild", "ContentChild"]
  },
  {
    "question": "How do observables work in Angular? Explain RxJS.",
    "options": [
      "Synchronous data handlers for static values",
      "A pattern for handling asynchronous data streams using RxJS operators like map and filter",
      "A tool for generating random numbers",
      "A CSS preprocessor"
    ],
    "answer": "A pattern for handling asynchronous data streams using RxJS operators like map and filter",
    "explanation": "RxJS (Reactive Extensions) provides observables to manage asynchronous operations (e.g., HTTP requests) with operators for transforming data streams.",
    "tags": ["Angular", "RxJS", "Observables"]
  },
  {
    "question": "What are pipes in Angular? Provide examples of built-in and custom pipes.",
    "options": [
      "Tools for HTTP routing",
      "Functions that transform displayed data (e.g., date, currency formatting)",
      "CSS animation libraries",
      "Database connection handlers"
    ],
    "answer": "Functions that transform displayed data (e.g., date, currency formatting)",
    "explanation": "Pipes format data in templates (e.g., {{ value | date }}). Built-in pipes include DatePipe, CurrencyPipe; custom pipes can be created for specific logic.",
    "tags": ["Angular", "Pipes"]
  },
  {
    "question": "How do you optimize an Angular applications performance?",
    "options": [
      "Use jQuery for DOM manipulation",
      "Enable AOT compilation, lazy loading, and OnPush change detection",
      "Disable all caching mechanisms",
      "Use synchronous HTTP calls"
    ],
    "answer": "Enable AOT compilation, lazy loading, and OnPush change detection",
    "explanation": "AOT compiles templates early, lazy loading reduces bundle size, and OnPush minimizes unnecessary change detection cycles.",
    "tags": ["Angular", "Performance"]
  },
  {
    "question": "What is lazy loading, and how do you implement it in Angular?",
    "options": [
      "Loading all modules at startup; implemented via eager loading",
      "Loading feature modules on demand using loadChildren in routing",
      "A technique for database indexing",
      "A CSS optimization strategy"
    ],
    "answer": "Loading feature modules on demand using loadChildren in routing",
    "explanation": "Lazy loading defers module loading until needed, reducing initial load time. Implemented with loadChildren: () => import('./module').then(m => m.Module).",
    "tags": ["Angular", "Lazy Loading"]
  },
  {
    "question": "Explain how routing works in Angular.",
    "options": [
      "Uses server-side rendering exclusively",
      "Defines URL paths mapped to components using the RouterModule",
      "Relies on href links without dynamic navigation",
      "A tool for database queries"
    ],
    "answer": "Defines URL paths mapped to components using the RouterModule",
    "explanation": "Angular Router enables navigation between components based on URL changes. Routes are configured with path and component mappings.",
    "tags": ["Angular", "Routing"]
  },
  {
    "question": "How do you handle forms in Angular? Compare template-driven and reactive forms.",
    "options": [
      "Template-driven: Form logic in HTML; Reactive: Form logic in TypeScript",
      "Both are identical in implementation",
      "Template-driven uses only TypeScript; Reactive uses HTML",
      "Reactive forms are deprecated"
    ],
    "answer": "Template-driven: Form logic in HTML; Reactive: Form logic in TypeScript",
    "explanation": "Template-driven forms rely on directives (e.g., ngModel) in templates, while reactive forms use FormControl/FormGroup in TypeScript for more control.",
    "tags": ["Angular", "Forms"]
  },
  {
    "question": "What are Angular animations, and how do you implement them?",
    "options": [
      "A tool for database synchronization",
      "A way to animate DOM elements using @trigger syntax and the BrowserAnimationsModule",
      "A CSS framework replacement",
      "A method for HTTP caching"
    ],
    "answer": "A way to animate DOM elements using @trigger syntax and the BrowserAnimationsModule",
    "explanation": "Angular animations use @Component animations or a separate file with triggers, states, and transitions.",
    "tags": ["Angular", "Animations"]
  },
  {
    "question": "What is an Angular resolver?",
    "options": [
      "A tool for resolving CSS conflicts",
      "A service that fetches data before a route is activated",
      "A type of HTTP interceptor",
      "A database migration script"
    ],
    "answer": "A service that fetches data before a route is activated",
    "explanation": "Resolvers ensure data is loaded before navigating to a route, preventing blank UI states.",
    "tags": ["Angular", "Routing", "Resolvers"]
  },
  {
    "question": "How does change detection work in Angular?",
    "options": [
      "Manually triggered via component methods",
      "Automatically tracks changes to data and updates the DOM using Zone.js",
      "Only works with server-side rendering",
      "Relies on jQuery for DOM updates"
    ],
    "answer": "Automatically tracks changes to data and updates the DOM using Zone.js",
    "explanation": "Angulars change detection uses Zone.js to monitor async operations and update the DOM when data changes.",
    "tags": ["Angular", "Change Detection"]
  },
  {
    "question": "What is the difference between Angulars template-driven forms and reactive forms? Which would you choose and why?",
    "options": [
      "Template-driven: simpler for small forms; Reactive: better for complex, dynamic forms",
      "Both are identical; no difference",
      "Reactive forms are deprecated",
      "Template-driven forms use TypeScript exclusively"
    ],
    "answer": "Template-driven: simpler for small forms; Reactive: better for complex, dynamic forms",
    "explanation": "Reactive forms offer more control (e.g., dynamic fields, custom validators), while template-driven forms are quicker to set up for simple cases.",
    "tags": ["Angular", "Forms"]
  },
  {
    "question": "How would you implement state management in Angular? Discuss NgRx or other libraries.",
    "options": [
      "Use local variables in components",
      "Implement NgRx (Redux pattern) for centralized state management",
      "Reload the page to reset state",
      "Use CSS variables for state"
    ],
    "answer": "Implement NgRx (Redux pattern) for centralized state management",
    "explanation": "NgRx uses stores, actions, and reducers to manage complex state in large apps. Alternatives include Akita or NGXS.",
    "tags": ["Angular", "State Management", "NgRx"]
  },
  {
    "question": "What is AOT (Ahead-of-Time) compilation, and why is it beneficial?",
    "options": [
      "Compiles templates at runtime; improves debugging",
      "Compiles templates during build time; improves performance and security",
      "A tool for database optimization",
      "A CSS preprocessing technique"
    ],
    "answer": "Compiles templates during build time; improves performance and security",
    "explanation": "AOT converts Angular HTML/templates into JavaScript during build, reducing runtime overhead and detecting template errors early.",
    "tags": ["Angular", "AOT Compilation"]
  },
  {
    "question": "Explain the differences between Subject, BehaviorSubject, ReplaySubject, and AsyncSubject.",
    "options": [
      "All are identical in behavior",
      "Subject: No initial value; BehaviorSubject: Has initial value; ReplaySubject: Replays old values; AsyncSubject: Emits last value on completion",
      "All are used for CSS animations",
      "Subject: HTTP handler; BehaviorSubject: Database tool"
    ],
    "answer": "Subject: No initial value; BehaviorSubject: Has initial value; ReplaySubject: Replays old values; AsyncSubject: Emits last value on completion",
    "explanation": "Subjects are RxJS observable types with varying behaviors for emitting values to subscribers.",
    "tags": ["Angular", "RxJS", "Subjects"]
  },
  {
    "question": "What are Angular interceptors, and how do you use them for HTTP requests?",
    "options": [
      "Tools for CSS animations",
      "Middleware that modifies HTTP requests/responses globally (e.g., adding headers)",
      "A type of database index",
      "A replacement for Angular services"
    ],
    "answer": "Middleware that modifies HTTP requests/responses globally (e.g., adding headers)",
    "explanation": "Interceptors can add tokens to headers, log requests, or handle errors across all HTTP calls.",
    "tags": ["Angular", "HTTP Interceptors"]
  },
  {
    "question": "What are guards in Angular, and how are they used in routing?",
    "options": [
      "CSS selectors for styling",
      "Services that protect routes based on conditions (e.g., authentication)",
      "Tools for database encryption",
      "A type of Angular directive"
    ],
    "answer": "Services that protect routes based on conditions (e.g., authentication)",
    "explanation": "Guards (CanActivate, CanDeactivate) control route access. For example, AuthGuard checks login status before allowing navigation.",
    "tags": ["Angular", "Routing", "Guards"]
  },
  {
    "question": "How does Angular handle security, such as XSS and CSRF?",
    "options": [
      "Ignores security risks",
      "Sanitizes HTML by default and supports CSRF tokens via HttpClient",
      "Relies on third-party libraries exclusively",
      "Uses CSS to prevent attacks"
    ],
    "answer": "Sanitizes HTML by default and supports CSRF tokens via HttpClient",
    "explanation": "Angular automatically sanitizes user input to prevent XSS. HttpClient supports CSRF token integration for POST requests.",
    "tags": ["Angular", "Security"]
  },
  {
    "question": "Discuss the Ivy renderer in Angular.",
    "options": [
      "A deprecated rendering engine",
      "A new rendering engine that improves performance, bundle size, and debugging",
      "A database query optimizer",
      "A CSS framework"
    ],
    "answer": "A new rendering engine that improves performance, bundle size, and debugging",
    "explanation": "Ivy, Angulars latest renderer, offers faster compilation, smaller bundles, and better error messages.",
    "tags": ["Angular", "Ivy Renderer"]
  },
  {
    "question": "What is the primary purpose of JWT in this authentication flow?",
    "options": [
      "Encrypt user passwords",
      "Store user sessions in cookies",
      "Enable stateless authentication with tokens",
      "Generate API keys"
    ],
    "answer": "Enable stateless authentication with tokens",
    "explanation": "JWT (JSON Web Token) allows stateless authentication by encoding user data into a token. The server doesnt need to store session data, making it scalable for distributed systems.",
    "tags": ["JWT", "Authentication"]
  },
  {
    "question": "In the Express backend, what does `bcryptjs` primarily handle?",
    "options": [
      "Token generation",
      "Password hashing and validation",
      "HTTP request routing",
      "CORS configuration"
    ],
    "answer": "Password hashing and validation",
    "explanation": "`bcryptjs` securely hashes passwords before storing them in the database and compares hashed passwords during login to validate credentials.",
    "tags": ["bcryptjs", "Password Hashing"]
  },
  {
    "question": "Which Angular feature is used to automatically attach the JWT to outgoing HTTP requests?",
    "options": ["Guards", "HTTP Interceptor", "Services", "Directives"],
    "answer": "HTTP Interceptor",
    "explanation": "Angulars HTTP Interceptors modify outgoing requests. Here, it injects the JWT into the `Authorization` header for authenticated API calls.",
    "tags": ["Angular", "HTTP Interceptor"]
  },
  {
    "question": "What is the purpose of the `AuthGuard` in Angular?",
    "options": [
      "Hash user passwords",
      "Restrict access to routes for unauthenticated users",
      "Generate JWT tokens",
      "Handle HTTP errors"
    ],
    "answer": "Restrict access to routes for unauthenticated users",
    "explanation": "The `AuthGuard` checks if a user is authenticated before allowing access to protected routes. If not, it redirects to the login page.",
    "tags": ["Angular", "Route Guards"]
  },
  {
    "question": "Why is `localStorage` used in the Angular `AuthService`?",
    "options": [
      "To store hashed passwords",
      "To persist the JWT token across sessions",
      "To encrypt API responses",
      "To manage CORS policies"
    ],
    "answer": "To persist the JWT token across sessions",
    "explanation": "`localStorage` retains the JWT even after closing/reopening the browser, allowing users to stay logged in between sessions. **Note**: This has security trade-offs (e.g., XSS risks).",
    "tags": ["localStorage", "JWT"]
  },
  {
    "question": "What security risk is associated with storing JWT tokens in `localStorage`?",
    "options": [
      "Token expiration",
      "XSS (Cross-Site Scripting) attacks",
      "CSRF (Cross-Site Request Forgery)",
      "SQL injection"
    ],
    "answer": "XSS (Cross-Site Scripting) attacks",
    "explanation": "`localStorage` is accessible via JavaScript, making it vulnerable to XSS attacks where malicious scripts can steal tokens. Use HttpOnly cookies for better security.",
    "tags": ["Security", "JWT", "localStorage"]
  },
  {
    "question": "In Express, what does the `authMiddleware` do?",
    "options": [
      "Hashes user passwords",
      "Validates JWT tokens and attaches user data to requests",
      "Configures CORS policies",
      "Generates refresh tokens"
    ],
    "answer": "Validates JWT tokens and attaches user data to requests",
    "explanation": "The middleware extracts the JWT from the request header, verifies its validity, and attaches the decoded user data (e.g., user ID) to `req.user`.",
    "tags": ["Express.js", "Middleware", "JWT"]
  },
  {
    "question": "Which HTTP status code is returned by the Express backend for an invalid token?",
    "options": ["200 OK", "201 Created", "401 Unauthorized", "404 Not Found"],
    "answer": "401 Unauthorized",
    "explanation": "`401 Unauthorized` indicates the request lacks valid authentication credentials (e.g., an invalid/expired token).",
    "tags": ["HTTP Status Codes", "Authentication"]
  },
  {
    "question": "What is the purpose of `passport-jwt` in the Express backend?",
    "options": [
      "Encrypt database connections",
      "Simplify JWT validation and authentication strategies",
      "Hash user passwords",
      "Manage Angular routing"
    ],
    "answer": "Simplify JWT validation and authentication strategies",
    "explanation": "`passport-jwt` is a middleware that streamlines JWT extraction, validation, and user authentication in Express routes.",
    "tags": ["Express.js", "Passport.js", "JWT"]
  },
  {
    "question": "Which part of the Angular app ensures authenticated users stay logged in after a page refresh?",
    "options": [
      "HTTP Interceptor",
      "`localStorage` persistence of the token",
      "Route Guards",
      "Login Component"
    ],
    "answer": "`localStorage` persistence of the token",
    "explanation": "Storing the JWT in `localStorage` allows it to survive page reloads, enabling automatic re-authentication.",
    "tags": ["Angular", "localStorage", "JWT"]
  },
  {
    "question": "How is token expiration configured in the JWT setup?",
    "options": [
      "Using `bcryptjs`",
      "Via the `expiresIn` option in `jwt.sign()`",
      "By setting Angular route guards",
      "Through CORS middleware"
    ],
    "answer": "Via the `expiresIn` option in `jwt.sign()`",
    "explanation": "The `expiresIn` option in `jwt.sign()` sets the tokens lifespan (e.g., `1h` for 1 hour), after which it becomes invalid.",
    "tags": ["JWT", "Security"]
  },
  {
    "question": "What security practice is recommended for production environments?",
    "options": [
      "Disable token expiration",
      "Use HTTPS instead of HTTP",
      "Store tokens in Angular services",
      "Disable CORS"
    ],
    "answer": "Use HTTPS instead of HTTP",
    "explanation": "HTTPS encrypts data in transit, preventing man-in-the-middle attacks from intercepting JWTs or sensitive user data.",
    "tags": ["Security", "HTTPS"]
  },
  {
    "question": "Which Express middleware is used to parse incoming JSON request bodies?",
    "options": [
      "`cors()`",
      "`express.json()`",
      "`passport.authenticate()`",
      "`bcrypt.compare()`"
    ],
    "answer": "`express.json()`",
    "explanation": "`express.json()` parses incoming JSON payloads (e.g., login credentials) into `req.body` for backend processing.",
    "tags": ["Express.js", "Middleware"]
  },
  {
    "question": "What does the `cors` middleware in Express handle?",
    "options": [
      "Password hashing",
      "Cross-Origin Resource Sharing (CORS) policies",
      "JWT token validation",
      "HTTP request routing"
    ],
    "answer": "Cross-Origin Resource Sharing (CORS) policies",
    "explanation": "The `cors` middleware configures which domains/clients (e.g., Angular app) are allowed to access the Express API.",
    "tags": ["Express.js", "CORS"]
  },
  {
    "question": "In the JWT payload, which user data is typically included?",
    "options": [
      "Plaintext password",
      "User ID and email",
      "IP address",
      "API endpoints"
    ],
    "answer": "User ID and email",
    "explanation": "The JWT payload contains non-sensitive user identifiers (e.g., ID, email) to avoid exposing secrets like passwords.",
    "tags": ["JWT", "Authentication"]
  },
  {
    "question": "Which of the following best describes an API?",
    "options": [
      "A small, independent service that performs a specific business function",
      "A set of protocols and tools that allows different software applications to communicate with each other",
      "An architectural style that structures an application as a collection of loosely coupled services",
      "A database management system for microservices"
    ],
    "answer": "A set of protocols and tools that allows different software applications to communicate with each other",
    "explanation": "An API (Application Programming Interface) defines the methods and data formats that applications can use to request and exchange information.",
    "tags": ["API", "Software Communication"]
  },
  {
    "question": "What is a microservice in software architecture?",
    "options": [
      "A monolithic application that handles all business functions",
      "A large-scale service that manages multiple applications",
      "A small, independent service that performs a specific business function",
      "A user interface component in web applications"
    ],
    "answer": "A small, independent service that performs a specific business function",
    "explanation": "A microservice is an architectural style that structures an application as a collection of loosely coupled services, each responsible for a specific business function.",
    "tags": ["Microservices", "Software Architecture"]
  },
  {
    "question": "How do microservices typically communicate with each other?",
    "options": [
      "Through direct database access",
      "Via APIs",
      "Using shared memory",
      "Through a centralized monolithic controller"
    ],
    "answer": "Via APIs",
    "explanation": "Microservices communicate with each other via APIs, exposing their functionalities to enable interaction between services.",
    "tags": ["Microservices", "API", "Inter-Service Communication"]
  },
  {
    "question": "Which of the following statements is true regarding APIs and microservices?",
    "options": [
      "APIs are always implemented using microservices.",
      "Microservices must use APIs to communicate with external systems.",
      "An API is an architectural style, while microservices are communication protocols.",
      "Microservices are an architectural style, and APIs are communication protocols used within that architecture."
    ],
    "answer": "Microservices are an architectural style, and APIs are communication protocols used within that architecture.",
    "explanation": "Microservices structure an application as a collection of loosely coupled services, while APIs define the communication protocols enabling interaction between these services.",
    "tags": ["API", "Microservices", "Software Architecture"]
  },
  {
    "question": "In the context of microservices, what role does an API Gateway play?",
    "options": [
      "It serves as a database for all microservices.",
      "It acts as a single entry point for client requests, routing them to the appropriate microservice.",
      "It combines all microservices into a monolithic application.",
      "It directly manages the business logic of each microservice."
    ],
    "answer": "It acts as a single entry point for client requests, routing them to the appropriate microservice.",
    "explanation": "An API Gateway handles tasks such as routing client requests to the appropriate microservice, authentication, rate limiting, and load balancing.",
    "tags": ["API", "Microservices", "API Gateway"]
  },
  {
    "question": "Which of the following is NOT a characteristic of microservices architecture?",
    "options": [
      "Independent deployability",
      "Centralized data management",
      "Loosely coupled services",
      "Scalability"
    ],
    "answer": "Centralized data management",
    "explanation": "Microservices architecture typically features decentralized data management, with each service managing its own data.",
    "tags": ["Microservices", "Software Architecture"]
  },
  {
    "question": "How does an API differ from a microservice?",
    "options": [
      "An API is a self-contained unit of functionality, while a microservice is a communication interface.",
      "An API defines how software components should interact, whereas a microservice is an independent service performing a specific business function.",
      "An API is always a large, monolithic application, while a microservice is always small and simple.",
      "An API and a microservice are the same, with the terms used interchangeably."
    ],
    "answer": "An API defines how software components should interact, whereas a microservice is an independent service performing a specific business function.",
    "explanation": "An API specifies the methods and data formats for communication, while a microservice is a self-contained unit of functionality within an application.",
    "tags": ["API", "Microservices", "Software Development"]
  },
  {
    "question": "What is the primary benefit of using microservices over a monolithic architecture?",
    "options": [
      "Simplified deployment process",
      "Improved scalability and maintainability",
      "Centralized control over all components",
      "Reduced need for inter-service communication"
    ],
    "answer": "Improved scalability and maintainability",
    "explanation": "Microservices allow each service to be developed, deployed, and scaled independently, enhancing scalability and maintainability.",
    "tags": [
      "Microservices",
      "Monolithic Architecture",
      "Scalability",
      "Maintainability"
    ]
  },
  {
    "question": "Can an API exist without microservices?",
    "options": [
      "No, APIs are exclusive to microservices architectures.",
      "Yes, APIs can be used in monolithic applications as well.",
      "No, APIs and microservices are always implemented together.",
      "Yes, but they are ineffective without microservices."
    ],
    "answer": "Yes, APIs can be used in monolithic applications as well.",
    "explanation": "APIs are commonly used in monolithic applications to enable communication between different parts of the application or with external systems.",
    "tags": ["API", "Monolithic Architecture", "Software Development"]
  },
  {
    "question": "In a microservices architecture, how is data typically managed?",
    "options": [
      "All services share a single centralized database.",
      "Each service manages its own database.",
      "Data is stored in a global cache accessible to all services.",
      "Data management is outsourced to a third-party service."
    ],
    "answer": "Each service manages its own database.",
    "explanation": "In microservices architecture, each service typically manages its own database to ensure independence and encapsulation.",
    "tags": ["Microservices", "Data Management", "Software Architecture"]
  },
  {
    "question": "What is an example of the Controller's role in an MVC-based blog application?",
    "options": [
      "It stores the blog post data like title and content.",
      "It renders the HTML templates for displaying blog posts.",
      "It handles HTTP requests and retrieves data from the database.",
      "It formats the data for user-friendly presentation."
    ],
    "answer": "It handles HTTP requests and retrieves data from the database.",
    "explanation": "In MVC, the Controller processes user inputs (like HTTP requests), interacts with the Model to fetch or modify data, and determines what View to render.",
    "tags": [
      "Software Architecture",
      "MVC",
      "Backend Development",
      "Web Applications"
    ]
  },
  {
    "question": "In an MVVM-based weather app, what is the primary role of the ViewModel?",
    "options": [
      "To provide a visually appealing user interface.",
      "To fetch data from the backend API and bind it to the View.",
      "To store the weather data in a database.",
      "To define the layout and style of the weather display."
    ],
    "answer": "To fetch data from the backend API and bind it to the View.",
    "explanation": "In MVVM, the ViewModel acts as a mediator between the Model and the View by fetching data, formatting it, and ensuring it is bound to the UI for dynamic updates.",
    "tags": [
      "Software Architecture",
      "MVVM",
      "Frontend Development",
      "Mobile Applications"
    ]
  },
  {
    "question": "Which framework is commonly used for implementing the MVC architecture in a blog application?",
    "options": ["Angular", "Django", "React", "Vue.js"],
    "answer": "Django",
    "explanation": "Django is a popular web framework that follows the MVC pattern, using models for data, views for presentation, and controllers to handle requests.",
    "tags": [
      "Software Architecture",
      "MVC",
      "Web Frameworks",
      "Fullstack Development"
    ]
  },
  {
    "question": "Why is MVVM preferred for dynamic and frequently updated UIs like in a weather app?",
    "options": [
      "Because it uses HTML templates to display data.",
      "Because it allows direct interaction between the Model and View.",
      "Because it provides two-way data binding for real-time updates.",
      "Because it focuses on handling HTTP requests efficiently."
    ],
    "answer": "Because it provides two-way data binding for real-time updates.",
    "explanation": "MVVM enables the ViewModel to synchronize data changes automatically between the Model and View, making it ideal for dynamic applications with frequent updates.",
    "tags": [
      "Software Architecture",
      "MVVM",
      "Frontend Development",
      "Dynamic UIs"
    ]
  },
  {
    "question": "What is the role of the Model in both MVC and MVVM architectures?",
    "options": [
      "To store and manage application data and business logic.",
      "To format data for the user interface.",
      "To handle user inputs and requests.",
      "To bind data to the user interface."
    ],
    "answer": "To store and manage application data and business logic.",
    "explanation": "The Model is responsible for managing the application's data, business rules, and logic in both MVC and MVVM architectures.",
    "tags": [
      "Software Architecture",
      "Model",
      "Backend Development",
      "Fullstack Development"
    ]
  },
  {
    "question": "What is the primary role of the Controller in the MVC architecture?",
    "options": [
      "To directly manage the user interface.",
      "To mediate between the Model and the View.",
      "To store and manage data.",
      "To transform data for presentation."
    ],
    "answer": "To mediate between the Model and the View.",
    "explanation": "The Controller acts as the intermediary between the Model (data/business logic) and the View (UI), ensuring that user inputs update the Model and the updated data is reflected in the View.",
    "tags": [
      "Software Architecture",
      "MVC",
      "Backend Development",
      "Fullstack Development"
    ]
  },
  {
    "question": "In the MVVM architecture, which component handles two-way data binding?",
    "options": ["Model", "View", "ViewModel", "Controller"],
    "answer": "ViewModel",
    "explanation": "The ViewModel facilitates two-way data binding by synchronizing the data between the Model and the View, allowing the UI to update automatically when the Model changes and vice versa.",
    "tags": [
      "Software Architecture",
      "MVVM",
      "Frontend Development",
      "Fullstack Development"
    ]
  },
  {
    "question": "Which of the following best describes the 'Model' in both MVC and MVVM architectures?",
    "options": [
      "It contains UI logic and handles user interactions.",
      "It stores and manages application data and business logic.",
      "It transforms data to make it suitable for presentation.",
      "It provides data bindings to the View."
    ],
    "answer": "It stores and manages application data and business logic.",
    "explanation": "The Model is the core component responsible for managing the applications data, rules, and logic in both MVC and MVVM.",
    "tags": [
      "Software Architecture",
      "Model",
      "Backend Development",
      "Fullstack Development"
    ]
  },
  {
    "question": "What is React primarily used for?",
    "options": [
      "Server-side development",
      "Database management",
      "Building user interfaces",
      "Mobile application development"
    ],
    "answer": "Building user interfaces",
    "explanation": "React is a JavaScript library for building dynamic and interactive user interfaces, primarily for web applications.",
    "tags": ["Frontend Development", "JavaScript Frameworks"]
  },
  {
    "question": "What is the virtual DOM in React?",
    "options": [
      "A browser feature to improve performance",
      "A lightweight copy of the actual DOM",
      "A debugging tool for React",
      "A data structure for storing app data"
    ],
    "answer": "A lightweight copy of the actual DOM",
    "explanation": "The virtual DOM is a concept used in React to improve performance by updating only the parts of the DOM that change, instead of re-rendering the entire DOM.",
    "tags": ["Frontend Development", "Performance Optimization"]
  },
  {
    "question": "Which method is used to update the state in a React class component?",
    "options": [
      "updateState()",
      "changeState()",
      "this.setState()",
      "modifyState()"
    ],
    "answer": "this.setState()",
    "explanation": "In class components, the `this.setState()` method is used to update the component's state and trigger a re-render.",
    "tags": ["Frontend Development", "React Basics"]
  },
  {
    "question": "What is the purpose of the `useEffect` hook in React?",
    "options": [
      "To manage state",
      "To fetch data and handle side effects",
      "To create context",
      "To manipulate DOM directly"
    ],
    "answer": "To fetch data and handle side effects",
    "explanation": "The `useEffect` hook allows you to perform side effects in function components, such as fetching data, subscribing to events, or updating the DOM.",
    "tags": ["Frontend Development", "React Hooks"]
  },
  {
    "question": "What is JSX in React?",
    "options": [
      "A JavaScript framework",
      "A syntax extension for JavaScript",
      "A CSS-in-JS library",
      "A templating engine"
    ],
    "answer": "A syntax extension for JavaScript",
    "explanation": "JSX is a syntax extension that allows you to write HTML-like code within JavaScript, making it easier to create React components.",
    "tags": ["Frontend Development", "JavaScript Syntax"]
  },
  {
    "question": "Which of the following is true about React props?",
    "options": [
      "Props are mutable",
      "Props are used to pass data from parent to child components",
      "Props can only hold primitive data types",
      "Props are only accessible in functional components"
    ],
    "answer": "Props are used to pass data from parent to child components",
    "explanation": "Props in React are immutable and allow data to be passed from a parent component to its child components as read-only values.",
    "tags": ["Frontend Development", "React Props"]
  },
  {
    "question": "How does React identify which items have changed in a list?",
    "options": [
      "By comparing indexes",
      "By using the `key` attribute",
      "By comparing component names",
      "By using a hash function"
    ],
    "answer": "By using the `key` attribute",
    "explanation": "React uses the `key` attribute to uniquely identify items in a list, helping it efficiently update or re-render only the items that have changed.",
    "tags": ["Frontend Development", "React Performance"]
  },
  {
    "question": "What is a React fragment?",
    "options": [
      "A new component type",
      "A wrapper element to avoid adding extra nodes to the DOM",
      "A lifecycle method",
      "A debugging tool"
    ],
    "answer": "A wrapper element to avoid adding extra nodes to the DOM",
    "explanation": "React fragments (`<React.Fragment>` or shorthand `<>`) let you group multiple elements without introducing an additional DOM node.",
    "tags": ["Frontend Development", "React Basics"]
  },
  {
    "question": "Which command is used to create a new React app using Create React App?",
    "options": [
      "react-create-app my-app",
      "npm create-react-app my-app",
      "npx create-react-app my-app",
      "npm install react"
    ],
    "answer": "npx create-react-app my-app",
    "explanation": "The `npx create-react-app my-app` command is the standard way to bootstrap a new React application using the Create React App tool.",
    "tags": ["Frontend Development", "React CLI"]
  },
  {
    "question": "What is the purpose of `ReactDOM.render()`?",
    "options": [
      "To create a new React app",
      "To compile JSX into JavaScript",
      "To render a React component into the DOM",
      "To execute React lifecycle methods"
    ],
    "answer": "To render a React component into the DOM",
    "explanation": "The `ReactDOM.render()` method is used to render React components into a specified DOM node.",
    "tags": ["Frontend Development", "React Basics"]
  },
  {
    "question": "What is Angular primarily used for?",
    "options": [
      "Backend development",
      "Building server applications",
      "Creating dynamic, single-page web applications",
      "File storage"
    ],
    "answer": "Creating dynamic, single-page web applications",
    "explanation": "Angular is a front-end framework developed by Google, designed for building scalable and interactive single-page applications (SPAs).",
    "tags": ["Frontend Development", "JavaScript Frameworks"]
  },
  {
    "question": "What is the primary architecture pattern used in Angular?",
    "options": [
      "Model-View-Controller (MVC)",
      "Model-View-ViewModel (MVVM)",
      "Flux",
      "Event-driven"
    ],
    "answer": "Model-View-ViewModel (MVVM)",
    "explanation": "Angular follows the MVVM pattern, where the ViewModel acts as the binding layer between the Model (data) and the View (UI).",
    "tags": ["Frontend Development", "Software Architecture"]
  },
  {
    "question": "Which package manager is commonly used to install Node.js dependencies?",
    "options": ["Maven", "pip", "npm", "Composer"],
    "answer": "npm",
    "explanation": "Node.js uses the Node Package Manager (npm) to install, manage, and update packages and dependencies.",
    "tags": ["Backend Development", "Package Management"]
  },
  {
    "question": "What is the purpose of the `package.json` file in a Node.js project?",
    "options": [
      "To store the source code",
      "To list project dependencies and metadata",
      "To define server configurations",
      "To store user authentication details"
    ],
    "answer": "To list project dependencies and metadata",
    "explanation": "The `package.json` file includes project metadata, scripts, and a list of dependencies required for the Node.js application.",
    "tags": ["Backend Development", "Package Management"]
  },
  {
    "question": "In Angular, which decorator is used to define a component?",
    "options": ["@Directive", "@Service", "@NgModule", "@Component"],
    "answer": "@Component",
    "explanation": "The `@Component` decorator is used in Angular to define a component, including its metadata like the selector, template, and styles.",
    "tags": ["Frontend Development", "Angular Basics"]
  },
  {
    "question": "What does the `res.send()` function do in Node.js with Express?",
    "options": [
      "Sends a file to the client",
      "Sends an HTTP response with data to the client",
      "Ends the server process",
      "Logs a message to the console"
    ],
    "answer": "Sends an HTTP response with data to the client",
    "explanation": "In Express.js, `res.send()` is used to send a response back to the client. It can send strings, objects, or JSON data.",
    "tags": ["Backend Development", "Express.js"]
  },
  {
    "question": "How are Angular modules defined in the application?",
    "options": [
      "Using the @NgModel decorator",
      "Using the @NgModule decorator",
      "Using the @Module decorator",
      "Using the @Service decorator"
    ],
    "answer": "Using the @NgModule decorator",
    "explanation": "Angular modules are defined using the `@NgModule` decorator, which organizes components, directives, pipes, and services into cohesive blocks.",
    "tags": ["Frontend Development", "Angular Basics"]
  },
  {
    "question": "What is middleware in Node.js?",
    "options": [
      "Code that connects databases to servers",
      "Functions that execute during the request-response cycle",
      "A built-in module in Node.js",
      "A method to handle authentication"
    ],
    "answer": "Functions that execute during the request-response cycle",
    "explanation": "Middleware in Node.js, particularly with frameworks like Express.js, are functions that process requests and responses before they reach the final handler.",
    "tags": ["Backend Development", "Express.js"]
  },
  {
    "question": "Which Angular CLI command is used to create a new component?",
    "options": [
      "ng add component",
      "ng generate component",
      "ng create component",
      "ng make component"
    ],
    "answer": "ng generate component",
    "explanation": "The `ng generate component` command is used to create a new component in Angular, along with its associated files like HTML, CSS, and TypeScript.",
    "tags": ["Frontend Development", "Angular CLI"]
  },
  {
    "question": "Which Node.js module is used to create a web server?",
    "options": ["fs", "os", "http", "path"],
    "answer": "http",
    "explanation": "The `http` module in Node.js is used to create a server and handle incoming HTTP requests and responses.",
    "tags": ["Backend Development", "Node.js Basics"]
  },
  {
    "question": "What is Traefik primarily used for?",
    "options": [
      "Database management",
      "Load balancing and reverse proxying",
      "Code deployment",
      "File storage"
    ],
    "answer": "Load balancing and reverse proxying",
    "explanation": "Traefik is an edge router and reverse proxy designed to distribute traffic among backend services and efficiently handle HTTP, TCP, and TLS requests.",
    "tags": ["Networking", "DevOps"]
  },
  {
    "question": "Which file format is typically used to configure Traefik?",
    "options": ["JSON", "YAML", "XML", "INI"],
    "answer": "YAML",
    "explanation": "Traefik configurations are commonly written in YAML or TOML files. YAML is preferred for its readability and compatibility with modern tools.",
    "tags": ["Configuration Management", "DevOps"]
  },
  {
    "question": "How does Traefik dynamically discover backend services in Docker?",
    "options": [
      "By scanning exposed ports manually",
      "Through Docker labels",
      "Using environment variables",
      "By hardcoding service configurations"
    ],
    "answer": "Through Docker labels",
    "explanation": "Traefik uses Docker labels to dynamically discover services and configure routes without manual intervention.",
    "tags": ["Docker", "Orchestration"]
  },
  {
    "question": "What feature of Traefik allows automatic HTTPS setup using Let's Encrypt?",
    "options": [
      "EntryPoints",
      "Middleware",
      "CertificatesResolvers",
      "DockerProvider"
    ],
    "answer": "CertificatesResolvers",
    "explanation": "The certificatesResolvers configuration in Traefik enables integration with Let's Encrypt for automated certificate generation and renewal.",
    "tags": ["Security", "Networking"]
  },
  {
    "question": "Which of the following allows you to monitor Traefik's routing and services?",
    "options": [
      "Traefik's Dashboard",
      "Prometheus Exporter",
      "Logs",
      "All of the above"
    ],
    "answer": "All of the above",
    "explanation": "Traefik provides a dashboard to view routes and services, integrates with monitoring tools like Prometheus for detailed metrics, and offers logs for debugging and monitoring.",
    "tags": ["Monitoring", "DevOps"]
  },
  {
    "question": "What does the term 'entryPoints' in Traefik refer to?",
    "options": [
      "Rules for routing specific services",
      "Ports on which Traefik listens for incoming requests",
      "Middleware configuration",
      "API endpoints"
    ],
    "answer": "Ports on which Traefik listens for incoming requests",
    "explanation": "An entryPoint in Traefik defines the network port and protocol (HTTP or TCP) on which Traefik listens for incoming traffic.",
    "tags": ["Networking", "DevOps"]
  },
  {
    "question": "What is the default port for the Traefik dashboard?",
    "options": ["80", "8080", "443", "3000"],
    "answer": "8080",
    "explanation": "Traefik's dashboard is served on port 8080 by default, but this can be configured as needed.",
    "tags": ["Networking", "Monitoring"]
  },
  {
    "question": "Which middleware is used to redirect HTTP traffic to HTTPS in Traefik?",
    "options": ["StripPrefix", "RateLimit", "RedirectScheme", "CircuitBreaker"],
    "answer": "RedirectScheme",
    "explanation": "The RedirectScheme middleware is used to redirect requests from one scheme (e.g., HTTP) to another (e.g., HTTPS), ensuring secure connections.",
    "tags": ["Security", "Networking"]
  },
  {
    "question": "In Traefik, how are rules defined to route traffic to specific services?",
    "options": ["EntryPoints", "CertificatesResolvers", "Labels", "Routes"],
    "answer": "Labels",
    "explanation": "Routing rules for services in Traefik are defined using labels in Docker or Kubernetes annotations, specifying conditions like hostnames or paths.",
    "tags": ["Networking", "Orchestration"]
  },
  {
    "question": "Which Traefik feature allows limiting the number of requests sent to backend services?",
    "options": [
      "Middleware",
      "EntryPoints",
      "CertificatesResolvers",
      "Static Configuration"
    ],
    "answer": "Middleware",
    "explanation": "Middleware in Traefik, like RateLimit, enables advanced request handling such as limiting the number of requests sent to a backend service.",
    "tags": ["Networking", "Performance Optimization"]
  },
  {
    "question": "What is Docker primarily used for?",
    "options": [
      "A) Virtualizing physical servers",
      "B) Managing databases",
      "C) Packaging and running applications in containers",
      "D) Managing cloud infrastructure"
    ],
    "answer": "C) Packaging and running applications in containers",
    "explanation": "Docker is designed to package applications and their dependencies into containers, enabling consistent execution across environments.",
    "tags": ["Containers", "Docker"]
  },
  {
    "question": "Which command is used to create a new Docker container?",
    "options": [
      "A) docker build",
      "B) docker run",
      "C) docker create",
      "D) docker start"
    ],
    "answer": "B) docker run",
    "explanation": "The `docker run` command creates and starts a new container from a specified image.",
    "tags": ["Containers", "Docker"]
  },
  {
    "question": "What is the default Docker network driver?",
    "options": ["A) Host", "B) Bridge", "C) Overlay", "D) None"],
    "answer": "B) Bridge",
    "explanation": "The `bridge` driver is the default network driver, allowing containers to communicate within the same host while isolating them from the external network.",
    "tags": ["Networking", "Docker"]
  },
  {
    "question": "Which directive in a Dockerfile is used to specify the base image?",
    "options": ["A) CMD", "B) FROM", "C) RUN", "D) COPY"],
    "answer": "B) FROM",
    "explanation": "The `FROM` directive specifies the base image to be used for building the new image.",
    "tags": ["Dockerfile", "Docker"]
  },
  {
    "question": "What does the `COPY` command do in a Dockerfile?",
    "options": [
      "A) Copies files from one container to another",
      "B) Copies files from the host to the image",
      "C) Creates a new layer in the image",
      "D) Copies files from the image to the host"
    ],
    "answer": "B) Copies files from the host to the image",
    "explanation": "The `COPY` command transfers files or directories from the host to the image during the build process.",
    "tags": ["Dockerfile", "Docker"]
  },
  {
    "question": "What is the purpose of the `EXPOSE` instruction in a Dockerfile?",
    "options": [
      "A) Start a service on a specific port",
      "B) Specify which ports the container listens on at runtime",
      "C) Forward traffic from the host to the container",
      "D) Automatically open ports in the firewall"
    ],
    "answer": "B) Specify which ports the container listens on at runtime",
    "explanation": "The `EXPOSE` instruction informs Docker about the ports on which the container will listen for connections.",
    "tags": ["Dockerfile", "Docker"]
  },
  {
    "question": "What is the purpose of Docker Compose?",
    "options": [
      "A) To build Docker images",
      "B) To manage multiple containers as a single application",
      "C) To debug Docker containers",
      "D) To monitor container performance"
    ],
    "answer": "B) To manage multiple containers as a single application",
    "explanation": "Docker Compose allows you to define and manage multi-container Docker applications using a `docker-compose.yml` file.",
    "tags": ["Docker Compose", "Containers"]
  },
  {
    "question": "Which file format is used for Docker Compose configurations?",
    "options": ["A) JSON", "B) YAML", "C) XML", "D) INI"],
    "answer": "B) YAML",
    "explanation": "Docker Compose uses the YAML format to define services, networks, and volumes in its configuration file.",
    "tags": ["Docker Compose", "Configuration"]
  },
  {
    "question": "How do you start services defined in a `docker-compose.yml` file?",
    "options": [
      "A) docker start services.yml",
      "B) docker-compose run",
      "C) docker-compose up",
      "D) docker run compose.yml"
    ],
    "answer": "C) docker-compose up",
    "explanation": "The `docker-compose up` command starts all the services defined in the `docker-compose.yml` file.",
    "tags": ["Docker Compose", "Containers"]
  },
  {
    "question": "What is the function of the `depends_on` keyword in a `docker-compose.yml` file?",
    "options": [
      "A) Defines the startup order of services",
      "B) Links services together for communication",
      "C) Mounts volumes between services",
      "D) Ensures services share the same network"
    ],
    "answer": "A) Defines the startup order of services",
    "explanation": "The `depends_on` keyword specifies the dependency order, ensuring certain services start before others.",
    "tags": ["Docker Compose", "Containers"]
  },
  {
    "question": "What is the primary purpose of a proxy server?",
    "options": [
      "A) To act on behalf of the client",
      "B) To distribute traffic across multiple servers",
      "C) To terminate SSL connections",
      "D) To hide the servers IP address"
    ],
    "answer": "A) To act on behalf of the client",
    "explanation": "A proxy server primarily acts as an intermediary for clients, forwarding their requests to servers. It can provide anonymity, caching, and content filtering for client-side operations.",
    "tags": ["Networking", "Proxy"]
  },
  {
    "question": "Which of the following is a key function of a reverse proxy?",
    "options": [
      "A) Caching responses for faster client requests",
      "B) Hiding the clients IP address",
      "C) Encrypting outbound client requests",
      "D) Blocking access to certain websites"
    ],
    "answer": "A) Caching responses for faster client requests",
    "explanation": "A reverse proxy caches server responses to improve response times for clients. It also helps manage load balancing and security for backend servers.",
    "tags": ["Networking", "Reverse Proxy"]
  },
  {
    "question": "How does a reverse proxy enhance server security?",
    "options": [
      "A) By encrypting client-side requests",
      "B) By hiding backend server details from clients",
      "C) By filtering client-side requests",
      "D) By directly interacting with databases"
    ],
    "answer": "B) By hiding backend server details from clients",
    "explanation": "A reverse proxy masks the identity of backend servers, preventing clients from directly interacting with them, thus improving security by reducing exposure to attacks.",
    "tags": ["Networking", "Security", "Reverse Proxy"]
  },
  {
    "question": "Which of the following is an example of a reverse proxy?",
    "options": ["A) Squid", "B) Nginx", "C) Privoxy", "D) TOR"],
    "answer": "B) Nginx",
    "explanation": "Nginx is commonly used as a reverse proxy for load balancing, SSL termination, and caching. Squid and Privoxy are forward proxies, while TOR is an anonymity network.",
    "tags": ["Networking", "Reverse Proxy", "Software"]
  },
  {
    "question": "What is the main difference between a proxy and a reverse proxy?",
    "options": [
      "A) A proxy works for the server, while a reverse proxy works for the client",
      "B) A proxy works for the client, while a reverse proxy works for the server",
      "C) A proxy encrypts traffic, while a reverse proxy does not",
      "D) A reverse proxy blocks content, while a proxy does not"
    ],
    "answer": "B) A proxy works for the client, while a reverse proxy works for the server",
    "explanation": "A proxy acts on behalf of the client by forwarding their requests to servers, while a reverse proxy acts on behalf of the server by handling requests from clients and routing them to the appropriate backend.",
    "tags": ["Networking", "Proxy", "Reverse Proxy"]
  },
  {
    "question": "Which of the following tasks is not typically handled by a reverse proxy?",
    "options": [
      "A) Load balancing",
      "B) SSL termination",
      "C) Content filtering for clients",
      "D) Routing requests to backend servers"
    ],
    "answer": "C) Content filtering for clients",
    "explanation": "Content filtering for clients is typically a task performed by forward proxies, not reverse proxies. Reverse proxies focus on assisting the server with tasks like load balancing and routing.",
    "tags": ["Networking", "Reverse Proxy", "Forward Proxy"]
  },
  {
    "question": "What does the term 'SSL termination' mean in the context of a reverse proxy?",
    "options": [
      "A) Blocking insecure connections from clients",
      "B) Encrypting server responses for clients",
      "C) Decrypting SSL/TLS traffic at the proxy server",
      "D) Terminating server connections during high traffic"
    ],
    "answer": "C) Decrypting SSL/TLS traffic at the proxy server",
    "explanation": "SSL termination refers to the reverse proxy handling SSL/TLS decryption, so the backend servers receive plain HTTP traffic, reducing their computational load.",
    "tags": ["Networking", "Reverse Proxy", "Security"]
  }
]
